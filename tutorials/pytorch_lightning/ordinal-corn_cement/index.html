
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="coral_pytorch is a package implementing the CORAL PyTorch utilities.">
      
      
        <meta name="author" content="Sebastian Raschka">
      
      
        <link rel="canonical" href="http://raschka-research-group.github.io/coral_pytorch/tutorials/pytorch_lightning/ordinal-corn_cement/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.9">
    
    
      
        <title>CORN multilayer perceptron for tabular data (Cement dataset) - coral_pytorch</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2b4465f4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#a-multilayer-perceptron-for-ordinal-regression-using-corn-cement-dataset" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="coral_pytorch" class="md-header__button md-logo" aria-label="coral_pytorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            coral_pytorch
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CORN multilayer perceptron for tabular data (Cement dataset)
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/raschka-research-group/coral_pytorch/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="coral_pytorch" class="md-nav__button md-logo" aria-label="coral_pytorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    coral_pytorch
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/raschka-research-group/coral_pytorch/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          PyTorch Lightning Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="PyTorch Lightning Examples" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch Lightning Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-coral_cement/" class="md-nav__link">
        CORAL multilayer perceptron for tabular data (Cement dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-coral_mnist/" class="md-nav__link">
        CORAL convolutional neural net for image data (MNIST dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-coral_tripadvisor/" class="md-nav__link">
        CORAL recurrent neural net for text data (TripAdvisor dataset)
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          CORN multilayer perceptron for tabular data (Cement dataset)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        CORN multilayer perceptron for tabular data (Cement dataset)
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#general-settings-and-hyperparameters" class="md-nav__link">
    General settings and hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#converting-a-regular-classifier-into-a-corn-ordinal-regression-model" class="md-nav__link">
    Converting a regular classifier into a CORN ordinal regression model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementing-a-multilayerperceptron-using-pytorch-lightnings-lightningmodule" class="md-nav__link">
    Implementing a MultiLayerPerceptron using PyTorch Lightning's LightningModule
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setting-up-the-dataset" class="md-nav__link">
    Setting up the dataset
  </a>
  
    <nav class="md-nav" aria-label="Setting up the dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inspecting-the-dataset" class="md-nav__link">
    Inspecting the dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-baseline" class="md-nav__link">
    Performance baseline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-a-dataset-class" class="md-nav__link">
    Creating a Dataset class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setting-up-a-datamodule" class="md-nav__link">
    Setting up a DataModule
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-the-model-using-the-pytorch-lightning-trainer-class" class="md-nav__link">
    Training the model using the PyTorch Lightning Trainer class
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating-the-model" class="md-nav__link">
    Evaluating the model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predicting-labels-of-new-data" class="md-nav__link">
    Predicting labels of new data
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-corn_mnist/" class="md-nav__link">
        CORN convolutional neural net for image data (MNIST dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-corn_tripadvisor/" class="md-nav__link">
        CORN recurrent neural net for text data (TripAdvisor dataset)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          Pure PyTorch Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Pure PyTorch Examples" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          Pure PyTorch Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORAL_mnist/" class="md-nav__link">
        CORAL CNN model for image data (MNIST dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORAL_cement/" class="md-nav__link">
        CORAL MLP model for tabular data (Cement dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORN_mnist/" class="md-nav__link">
        CORN CNN model for image data (MNIST dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORN_cement/" class="md-nav__link">
        CORN MLP model for tabular data (Cement dataset)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../api_subpackages/coral_pytorch.dataset.md" class="md-nav__link">
        coral_pytorch.dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../api_subpackages/coral_pytorch.layers.md" class="md-nav__link">
        coral_pytorch.layers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../api_subpackages/coral_pytorch.losses.md" class="md-nav__link">
        coral_pytorch.losses
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/" class="md-nav__link">
        Installation
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../CHANGELOG/" class="md-nav__link">
        Changelog
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../citing/" class="md-nav__link">
        Citing
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../license/" class="md-nav__link">
        License
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#general-settings-and-hyperparameters" class="md-nav__link">
    General settings and hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#converting-a-regular-classifier-into-a-corn-ordinal-regression-model" class="md-nav__link">
    Converting a regular classifier into a CORN ordinal regression model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementing-a-multilayerperceptron-using-pytorch-lightnings-lightningmodule" class="md-nav__link">
    Implementing a MultiLayerPerceptron using PyTorch Lightning's LightningModule
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setting-up-the-dataset" class="md-nav__link">
    Setting up the dataset
  </a>
  
    <nav class="md-nav" aria-label="Setting up the dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inspecting-the-dataset" class="md-nav__link">
    Inspecting the dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-baseline" class="md-nav__link">
    Performance baseline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-a-dataset-class" class="md-nav__link">
    Creating a Dataset class
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setting-up-a-datamodule" class="md-nav__link">
    Setting up a DataModule
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-the-model-using-the-pytorch-lightning-trainer-class" class="md-nav__link">
    Training the model using the PyTorch Lightning Trainer class
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating-the-model" class="md-nav__link">
    Evaluating the model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predicting-labels-of-new-data" class="md-nav__link">
    Predicting labels of new data
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="https://github.com/raschka-research-group/coral_pytorch/edit/master/docs/tutorials/pytorch_lightning/ordinal-corn_cement.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>


<h1 id="a-multilayer-perceptron-for-ordinal-regression-using-corn-cement-dataset">A Multilayer Perceptron for Ordinal Regression using CORN -- Cement Dataset</h1>
<p>In this tutorial, we implement a multilayer perceptron for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint:</p>
<ul>
<li>Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint;  <a href="https://arxiv.org/abs/2111.08851">https://arxiv.org/abs/2111.08851</a></li>
</ul>
<h2 id="general-settings-and-hyperparameters">General settings and hyperparameters</h2>
<ul>
<li>Here, we specify some general hyperparameter values and general settings</li>
<li>Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">DATA_BASEPATH</span> <span class="o">=</span> <span class="s2">&quot;./data&quot;</span>
</code></pre></div>
<h2 id="converting-a-regular-classifier-into-a-corn-ordinal-regression-model">Converting a regular classifier into a CORN ordinal regression model</h2>
<p>Changing a classifier to a CORN model for ordinal regression is actually really simple and only requires a few changes:</p>
<p><strong>1)</strong></p>
<p>Consider the following output layer used by a neural network classifier:</p>
<div class="highlight"><pre><span></span><code><span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">)</span>
</code></pre></div>
<p>In CORN we reduce the number of classes by 1:</p>
<div class="highlight"><pre><span></span><code><span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p><strong>2)</strong> </p>
<p>We swap the cross entropy loss from PyTorch,</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
</code></pre></div>
<p>with the CORN loss (also provided via <code>coral_pytorch</code>):</p>
<div class="highlight"><pre><span></span><code><span class="n">loss</span> <span class="o">=</span> <span class="n">corn_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span>
                 <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
</code></pre></div>
<p>Note that we pass <code>num_classes</code> instead of <code>num_classes-1</code> 
to the <code>corn_loss</code> as it takes care of the rest internally.</p>
<p><strong>3)</strong></p>
<p>In a regular classifier, we usually obtain the predicted class labels as follows:</p>
<div class="highlight"><pre><span></span><code><span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p>In CORN, w replace this with the following code to convert the predicted probabilities into the predicted labels:</p>
<div class="highlight"><pre><span></span><code><span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">corn_label_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</code></pre></div>
<h2 id="implementing-a-multilayerperceptron-using-pytorch-lightnings-lightningmodule">Implementing a <code>MultiLayerPerceptron</code> using PyTorch Lightning's <code>LightningModule</code></h2>
<ul>
<li>In this section, we set up the main model architecture using the <code>LightningModule</code> from PyTorch Lightning.</li>
<li>We start with defining our <code>MultiLayerPerceptron</code> model in pure PyTorch, and then we use it in the <code>LightningModule</code> to get all the extra benefits that PyTorch Lightning provides.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>


<span class="c1"># Regular PyTorch Module</span>
<span class="k">class</span> <span class="nc">MultiLayerPerceptron</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># num_classes is used by the corn loss function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>

        <span class="c1"># Initialize MLP layers</span>
        <span class="n">all_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hidden_unit</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_unit</span><span class="p">)</span>
            <span class="n">all_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="n">all_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">input_size</span> <span class="o">=</span> <span class="n">hidden_unit</span>

        <span class="c1"># CORN output layer -------------------------------------------</span>
        <span class="c1"># Regular classifier would use num_classes instead of </span>
        <span class="c1"># num_classes-1 below</span>
        <span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># -------------------------------------------------------------</span>

        <span class="n">all_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">all_layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<ul>
<li>In our <code>LightningModule</code> we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later.</li>
<li>Given a multilayer perceptron classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes:<ol>
<li>Instead of using <code>num_classes</code> in the output layer, use <code>num_classes-1</code> as shown above</li>
<li>Change the loss from <br />
<code>loss = torch.nn.functional.cross_entropy(logits, y)</code> to<br />
<code>loss = corn_loss(logits, y, num_classes=self.num_classes)</code></li>
<li>To obtain the class/rank labels from the logits, change<br />
<code>predicted_labels = torch.argmax(logits, dim=1)</code> to<br />
<code>predicted_labels = corn_label_from_logits(logits)</code></li>
</ol>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">coral_pytorch.losses</span> <span class="kn">import</span> <span class="n">corn_loss</span>
<span class="kn">from</span> <span class="nn">coral_pytorch.dataset</span> <span class="kn">import</span> <span class="n">corn_label_from_logits</span>

<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">torchmetrics</span>


<span class="c1"># LightningModule that receives a PyTorch model as input</span>
<span class="k">class</span> <span class="nc">LightningMLP</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="c1"># The inherited PyTorch module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="c1"># Save settings and hyperparameters to the log directory</span>
        <span class="c1"># but skip the model parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">])</span>

        <span class="c1"># Set up attributes for computing the MAE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mae</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanAbsoluteError</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_mae</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanAbsoluteError</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_mae</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanAbsoluteError</span><span class="p">()</span>

    <span class="c1"># Defining the forward method is only necessary </span>
    <span class="c1"># if you want to use a Trainer&#39;s .predict() method (optional)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># A common forward step to compute the loss and labels</span>
    <span class="c1"># this is used for training, validation, and testing below</span>
    <span class="k">def</span> <span class="nf">_shared_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">features</span><span class="p">,</span> <span class="n">true_labels</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># Use CORN loss --------------------------------------</span>
        <span class="c1"># A regular classifier uses:</span>
        <span class="c1"># loss = torch.nn.functional.cross_entropy(logits, y)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">corn_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span>
                         <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
        <span class="c1"># ----------------------------------------------------</span>

        <span class="c1"># CORN logits to labels ------------------------------</span>
        <span class="c1"># A regular classifier uses:</span>
        <span class="c1"># predicted_labels = torch.argmax(logits, dim=1)</span>
        <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">corn_label_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="c1"># ----------------------------------------------------</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mae</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_mae&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_mae</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>  <span class="c1"># this is passed to the optimzer for training</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;valid_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_mae</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;valid_mae&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_mae</span><span class="p">,</span>
                 <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_mae</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_mae&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_mae</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>
</code></pre></div>
<h2 id="setting-up-the-dataset">Setting up the dataset</h2>
<ul>
<li>In this section, we are going to set up our dataset.</li>
<li>We start by downloading and taking a look at the Cement dataset:</li>
</ul>
<h3 id="inspecting-the-dataset">Inspecting the dataset</h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/gagolews/&quot;</span>
                      <span class="s2">&quot;ordinal_regression_data/master/cement_strength.csv&quot;</span><span class="p">)</span>
<span class="n">data_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span>  <span class="c1"># labels should start at 0</span>

<span class="n">data_labels</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span>
<span class="n">data_features</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span>
    <span class="s2">&quot;V1&quot;</span><span class="p">,</span> <span class="s2">&quot;V2&quot;</span><span class="p">,</span> <span class="s2">&quot;V3&quot;</span><span class="p">,</span> <span class="s2">&quot;V4&quot;</span><span class="p">,</span> <span class="s2">&quot;V5&quot;</span><span class="p">,</span> <span class="s2">&quot;V6&quot;</span><span class="p">,</span> <span class="s2">&quot;V7&quot;</span><span class="p">,</span> <span class="s2">&quot;V8&quot;</span><span class="p">]]</span>

<span class="n">data_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>response</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4</td>
      <td>540.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>162.0</td>
      <td>2.5</td>
      <td>1040.0</td>
      <td>676.0</td>
      <td>28</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>540.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>162.0</td>
      <td>2.5</td>
      <td>1055.0</td>
      <td>676.0</td>
      <td>28</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>332.5</td>
      <td>142.5</td>
      <td>0.0</td>
      <td>228.0</td>
      <td>0.0</td>
      <td>932.0</td>
      <td>594.0</td>
      <td>270</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>332.5</td>
      <td>142.5</td>
      <td>0.0</td>
      <td>228.0</td>
      <td>0.0</td>
      <td>932.0</td>
      <td>594.0</td>
      <td>365</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>198.6</td>
      <td>132.4</td>
      <td>0.0</td>
      <td>192.0</td>
      <td>0.0</td>
      <td>978.4</td>
      <td>825.5</td>
      <td>360</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of features:&#39;</span><span class="p">,</span> <span class="n">data_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of examples:&#39;</span><span class="p">,</span> <span class="n">data_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Labels:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data_labels</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Label distribution:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">data_labels</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Number of features: 8
Number of examples: 998
Labels: [0 1 2 3 4]
Label distribution: [196 310 244 152  96]
</code></pre></div>
<ul>
<li>Above, we can see that the dataset consists of 8 features, and there are 998 examples in total.</li>
<li>The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). </li>
<li>Notice also that the dataset is quite imbalanced.</li>
</ul>
<h3 id="performance-baseline">Performance baseline</h3>
<ul>
<li>Especially for imbalanced datasets, it's quite useful to compute a performance baseline.</li>
<li>In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that!</li>
<li>Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE).</li>
<li>So, if we use the mean absolute error, <script type="math/tex">\mathrm{MAE}=\frac{1}{N} \sum_{i=1}^{N}\left|y_{i}-\hat{y}_{i}\right|</script>, to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">avg_prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">data_labels</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>  <span class="c1"># median minimizes MAE</span>
<span class="n">baseline_mae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data_labels</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">avg_prediction</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Baseline MAE: </span><span class="si">{</span><span class="n">baseline_mae</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Baseline MAE: 1.03
</code></pre></div>
<ul>
<li>In other words, a model that would always predict the dataset median would achieve a MAE of 1.03. A model that has an MAE of &gt; 1 is certainly a bad model.</li>
</ul>
<h3 id="creating-a-dataset-class">Creating a <code>Dataset</code> class</h3>
<ul>
<li>Next, let us set up a data loading mechanism for our model.</li>
<li>Note that the Cement dataset is a relatively small dataset that fits into memory quite comfortably so this may seem like overkill. However, the following steps are useful as a template since you can use those for arbitrarily-sized datatsets.</li>
<li>First, we define a PyTorch <code>Dataset</code> class that returns the features (inputs) and labels:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>


<span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_array</span><span class="p">,</span> <span class="n">label_array</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">feature_array</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">label_array</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">label</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<h3 id="setting-up-a-datamodule">Setting up a <code>DataModule</code></h3>
<ul>
<li>There are three main ways we can prepare the dataset for Lightning. We can</li>
<li>make the dataset part of the model;</li>
<li>set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection;</li>
<li>create a LightningDataModule.</li>
<li>Here, we are going to use approach 3, which is the most organized approach. The <code>LightningDataModule</code> consists of several self-explanatory methods as we can see below:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>


<span class="k">class</span> <span class="nc">DataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span> <span class="o">=</span> <span class="n">data_path</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
            <span class="s1">&#39;https://raw.githubusercontent.com/gagolews/&#39;</span>
            <span class="s1">&#39;ordinal_regression_data/master/cement_strength.csv&#39;</span><span class="p">)</span>
        <span class="n">data_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">&#39;cement_strength.csv&#39;</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">&#39;cement_strength.csv&#39;</span><span class="p">))</span>
        <span class="n">data_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span>  <span class="c1"># labels should start at 0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_labels</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_features</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span>
            <span class="s2">&quot;V1&quot;</span><span class="p">,</span> <span class="s2">&quot;V2&quot;</span><span class="p">,</span> <span class="s2">&quot;V3&quot;</span><span class="p">,</span> <span class="s2">&quot;V4&quot;</span><span class="p">,</span> <span class="s2">&quot;V5&quot;</span><span class="p">,</span> <span class="s2">&quot;V6&quot;</span><span class="p">,</span> <span class="s2">&quot;V7&quot;</span><span class="p">,</span> <span class="s2">&quot;V8&quot;</span><span class="p">]]</span>

        <span class="c1"># Split into</span>
        <span class="c1"># 70% train, 10% validation, 20% testing</span>

        <span class="n">X_temp</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_features</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_labels</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">stratify</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_labels</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
            <span class="n">X_temp</span><span class="p">,</span>
            <span class="n">y_temp</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">stratify</span><span class="o">=</span><span class="n">y_temp</span><span class="p">)</span>

        <span class="c1"># Standardize features</span>
        <span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">X_train_std</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">X_valid_std</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
        <span class="n">X_test_std</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">X_train_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">X_valid_std</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">X_test_std</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                          <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
                          <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                          <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                          <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>Note that the <code>prepare_data</code> method is usually used for steps that only need to be executed once, for example, downloading the dataset; the <code>setup</code> method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. </li>
<li>Next, lets initialize the <code>DataModule</code>; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code):</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">data_module</span> <span class="o">=</span> <span class="n">DataModule</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="n">DATA_BASEPATH</span><span class="p">)</span>
</code></pre></div>
<h2 id="training-the-model-using-the-pytorch-lightning-trainer-class">Training the model using the PyTorch Lightning Trainer class</h2>
<ul>
<li>Next, we initialize our multilayer perceptron model (here, a 2-layer MLP with 24 units in the first hidden layer, and 16 units in the second hidden layer).</li>
<li>We wrap the model in our <code>LightningMLP</code> so that we can use PyTorch Lightning's powerful <code>Trainer</code> API.</li>
<li>Also, we define a callback so that we can obtain the model with the best validation set performance after training.</li>
<li>Note PyTorch Lightning offers <a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html">many advanced logging services</a> like Weights &amp; Biases. However, here, we will keep things simple and use the <code>CSVLogger</code>:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loggers</span> <span class="kn">import</span> <span class="n">CSVLogger</span>


<span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">MultiLayerPerceptron</span><span class="p">(</span>
    <span class="n">input_size</span><span class="o">=</span><span class="n">data_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">hidden_units</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">data_labels</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">lightning_model</span> <span class="o">=</span> <span class="n">LightningMLP</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">pytorch_model</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>


<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">save_top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;valid_mae&quot;</span><span class="p">)]</span>  <span class="c1"># save top 1 model </span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">CSVLogger</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="s2">&quot;logs/&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mlp-corn-cement&quot;</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>Now it's time to train our model:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">time</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="n">NUM_EPOCHS</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="n">progress_bar_refresh_rate</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>  <span class="c1"># recommended for notebooks</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>  <span class="c1"># Uses GPUs or TPUs if available</span>
    <span class="n">devices</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>  <span class="c1"># Uses all available GPUs/TPUs if applicable</span>
    <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
    <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">lightning_model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">data_module</span><span class="p">)</span>

<span class="n">runtime</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span><span class="o">/</span><span class="mi">60</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training took </span><span class="si">{</span><span class="n">runtime</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> min in total.&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type                 | Params
---------------------------------------------------
0 | model     | MultiLayerPerceptron | 1.3 K 
1 | train_mae | MeanAbsoluteError    | 0     
2 | valid_mae | MeanAbsoluteError    | 0     
3 | test_mae  | MeanAbsoluteError    | 0     
---------------------------------------------------
1.3 K     Trainable params
0         Non-trainable params
1.3 K     Total params
0.005     Total estimated model params size (MB)



Training took 0.47 min in total.
</code></pre></div>
<h2 id="evaluating-the-model">Evaluating the model</h2>
<ul>
<li>After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a <a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html">more advanced logger</a> that does that for you):</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="si">}</span><span class="s2">/metrics.csv&quot;</span><span class="p">)</span>

<span class="n">aggreg_metrics</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">agg_col</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dfg</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">agg_col</span><span class="p">):</span>
    <span class="n">agg</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">dfg</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">agg</span><span class="p">[</span><span class="n">agg_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">aggreg_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agg</span><span class="p">)</span>

<span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">aggreg_metrics</span><span class="p">)</span>
<span class="n">df_metrics</span><span class="p">[[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;valid_loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">df_metrics</span><span class="p">[[</span><span class="s2">&quot;train_mae&quot;</span><span class="p">,</span> <span class="s2">&quot;valid_mae&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>&lt;AxesSubplot:xlabel=&#39;Epoch&#39;, ylabel=&#39;MAE&#39;&gt;
</code></pre></div>
<p><img alt="png" src="../ordinal-corn_cement_files/ordinal-corn_cement_39_1.png" /></p>
<p><img alt="png" src="../ordinal-corn_cement_files/ordinal-corn_cement_39_2.png" /></p>
<ul>
<li>As we can see from the loss plot above, the model starts overfitting pretty quickly; however the validation set MAE keeps improving. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 175.</li>
<li>The <code>trainer</code> saved this model automatically for us, we which we can load from the checkpoint via the <code>ckpt_path='best'</code> argument; below we use the <code>trainer</code> instance to evaluate the best model on the test set:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">lightning_model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">data_module</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Restoring states from the checkpoint path at logs/mlp-corn-cement/version_0/checkpoints/epoch=194-step=974.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at logs/mlp-corn-cement/version_0/checkpoints/epoch=194-step=974.ckpt
/home/jovyan/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(



Testing: 0it [00:00, ?it/s]


--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{&#39;test_mae&#39;: 0.25}
--------------------------------------------------------------------------------





[{&#39;test_mae&#39;: 0.25}]
</code></pre></div>
<ul>
<li>The MAE of our model is quite good, especially compared to the 1.03 MAE baseline earlier.</li>
</ul>
<h2 id="predicting-labels-of-new-data">Predicting labels of new data</h2>
<ul>
<li>You can use the <code>trainer.predict</code> method on a new <code>DataLoader</code> or <code>DataModule</code> to apply the model to new data.</li>
<li>Alternatively, you can also manually load the best model from a checkpoint as shown below:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">path</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">checkpoint_callback</span><span class="o">.</span><span class="n">best_model_path</span>
<span class="nb">print</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>logs/mlp-corn-cement/version_0/checkpoints/epoch=194-step=974.ckpt
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">lightning_model</span> <span class="o">=</span> <span class="n">LightningMLP</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">path</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">pytorch_model</span><span class="p">)</span>
<span class="n">lightning_model</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>
</code></pre></div>
<ul>
<li>Note that our <code>MultilayerPerceptron</code>, which is passed to <code>LightningMLP</code> requires input arguments. However, this is automatically being taken care of since we used <code>self.save_hyperparameters()</code> in <code>LightningMLP</code>'s <code>__init__</code> method.</li>
<li>Now, below is an example applying the model manually. Here, pretend that the <code>test_dataloader</code> is a new data loader.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">data_module</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>

<span class="n">all_predicted_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">lightning_model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">corn_label_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">all_predicted_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">)</span>

<span class="n">all_predicted_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_predicted_labels</span><span class="p">)</span>
<span class="n">all_predicted_labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([0, 3, 1, 2, 1])
</code></pre></div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../ordinal-coral_tripadvisor/" class="md-footer__link md-footer__link--prev" aria-label="Previous: CORAL recurrent neural net for text data (TripAdvisor dataset)" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              CORAL recurrent neural net for text data (TripAdvisor dataset)
            </div>
          </div>
        </a>
      
      
        
        <a href="../ordinal-corn_mnist/" class="md-footer__link md-footer__link--next" aria-label="Next: CORN convolutional neural net for image data (MNIST dataset)" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              CORN convolutional neural net for image data (MNIST dataset)
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020-2022 <a href="http://sebastianraschka.com">Sebastian Raschka</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../../../assets/javascripts/bundle.960e086b.min.js"></script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      
        <script src="../../../mathjaxhelper.js"></script>
      
    
  </body>
</html>