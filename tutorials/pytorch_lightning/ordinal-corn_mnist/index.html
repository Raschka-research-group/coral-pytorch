
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="coral_pytorch is a package implementing the CORAL PyTorch utilities.">
      
      
        <meta name="author" content="Sebastian Raschka">
      
      
        <link rel="canonical" href="http://raschka-research-group.github.io/coral_pytorch/tutorials/pytorch_lightning/ordinal-corn_mnist/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.9">
    
    
      
        <title>CORN convolutional neural net for image data (MNIST dataset) - coral_pytorch</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2b4465f4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#a-convolutional-neural-net-for-ordinal-regression-using-corn-mnist-dataset" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="coral_pytorch" class="md-header__button md-logo" aria-label="coral_pytorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            coral_pytorch
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CORN convolutional neural net for image data (MNIST dataset)
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/raschka-research-group/coral_pytorch/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="coral_pytorch" class="md-nav__button md-logo" aria-label="coral_pytorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    coral_pytorch
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/raschka-research-group/coral_pytorch/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          PyTorch Lightning Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="PyTorch Lightning Examples" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          PyTorch Lightning Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-coral_cement/" class="md-nav__link">
        CORAL multilayer perceptron for tabular data (Cement dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-coral_mnist/" class="md-nav__link">
        CORAL convolutional neural net for image data (MNIST dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-coral_tripadvisor/" class="md-nav__link">
        CORAL recurrent neural net for text data (TripAdvisor dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-corn_cement/" class="md-nav__link">
        CORN multilayer perceptron for tabular data (Cement dataset)
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          CORN convolutional neural net for image data (MNIST dataset)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        CORN convolutional neural net for image data (MNIST dataset)
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#general-settings-and-hyperparameters" class="md-nav__link">
    General settings and hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#converting-a-regular-classifier-into-a-corn-ordinal-regression-model" class="md-nav__link">
    Converting a regular classifier into a CORN ordinal regression model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementing-a-convnet-using-pytorch-lightnings-lightningmodule" class="md-nav__link">
    Implementing a ConvNet using PyTorch Lightning's LightningModule
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setting-up-the-dataset" class="md-nav__link">
    Setting up the dataset
  </a>
  
    <nav class="md-nav" aria-label="Setting up the dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inspecting-the-dataset" class="md-nav__link">
    Inspecting the dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-baseline" class="md-nav__link">
    Performance baseline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setting-up-a-datamodule" class="md-nav__link">
    Setting up a DataModule
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-the-model-using-the-pytorch-lightning-trainer-class" class="md-nav__link">
    Training the model using the PyTorch Lightning Trainer class
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating-the-model" class="md-nav__link">
    Evaluating the model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predicting-labels-of-new-data" class="md-nav__link">
    Predicting labels of new data
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ordinal-corn_tripadvisor/" class="md-nav__link">
        CORN recurrent neural net for text data (TripAdvisor dataset)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          Pure PyTorch Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Pure PyTorch Examples" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          Pure PyTorch Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORAL_mnist/" class="md-nav__link">
        CORAL CNN model for image data (MNIST dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORAL_cement/" class="md-nav__link">
        CORAL MLP model for tabular data (Cement dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORN_mnist/" class="md-nav__link">
        CORN CNN model for image data (MNIST dataset)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../pure_pytorch/CORN_cement/" class="md-nav__link">
        CORN MLP model for tabular data (Cement dataset)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../api_subpackages/coral_pytorch.dataset.md" class="md-nav__link">
        coral_pytorch.dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../api_subpackages/coral_pytorch.layers.md" class="md-nav__link">
        coral_pytorch.layers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../api_subpackages/coral_pytorch.losses.md" class="md-nav__link">
        coral_pytorch.losses
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/" class="md-nav__link">
        Installation
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../CHANGELOG/" class="md-nav__link">
        Changelog
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../citing/" class="md-nav__link">
        Citing
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../license/" class="md-nav__link">
        License
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#general-settings-and-hyperparameters" class="md-nav__link">
    General settings and hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#converting-a-regular-classifier-into-a-corn-ordinal-regression-model" class="md-nav__link">
    Converting a regular classifier into a CORN ordinal regression model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementing-a-convnet-using-pytorch-lightnings-lightningmodule" class="md-nav__link">
    Implementing a ConvNet using PyTorch Lightning's LightningModule
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setting-up-the-dataset" class="md-nav__link">
    Setting up the dataset
  </a>
  
    <nav class="md-nav" aria-label="Setting up the dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inspecting-the-dataset" class="md-nav__link">
    Inspecting the dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-baseline" class="md-nav__link">
    Performance baseline
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setting-up-a-datamodule" class="md-nav__link">
    Setting up a DataModule
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-the-model-using-the-pytorch-lightning-trainer-class" class="md-nav__link">
    Training the model using the PyTorch Lightning Trainer class
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating-the-model" class="md-nav__link">
    Evaluating the model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predicting-labels-of-new-data" class="md-nav__link">
    Predicting labels of new data
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="https://github.com/raschka-research-group/coral_pytorch/edit/master/docs/tutorials/pytorch_lightning/ordinal-corn_mnist.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>


<h1 id="a-convolutional-neural-net-for-ordinal-regression-using-corn-mnist-dataset">A Convolutional Neural Net for Ordinal Regression using CORN -- MNIST Dataset</h1>
<p>In this tutorial, we implement a convolutional neural network for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint:</p>
<ul>
<li>Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint;  <a href="https://arxiv.org/abs/2111.08851">https://arxiv.org/abs/2111.08851</a></li>
</ul>
<p>Please note that <strong>MNIST is not an ordinal dataset</strong>. The reason why we use MNIST in this tutorial is that it is included in the PyTorch's <code>torchvision</code> library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps.</p>
<h2 id="general-settings-and-hyperparameters">General settings and hyperparameters</h2>
<ul>
<li>Here, we specify some general hyperparameter values and general settings</li>
<li>Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch. So, if you have problems with the data loader later, try setting <code>NUM_WORKERS = 0</code> instead.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">DATA_BASEPATH</span> <span class="o">=</span> <span class="s2">&quot;./data&quot;</span>
</code></pre></div>
<h2 id="converting-a-regular-classifier-into-a-corn-ordinal-regression-model">Converting a regular classifier into a CORN ordinal regression model</h2>
<p>Changing a classifier to a CORN model for ordinal regression is actually really simple and only requires a few changes:</p>
<p><strong>1)</strong></p>
<p>Consider the following output layer used by a neural network classifier:</p>
<div class="highlight"><pre><span></span><code><span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">)</span>
</code></pre></div>
<p>In CORN we reduce the number of classes by 1:</p>
<div class="highlight"><pre><span></span><code><span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p><strong>2)</strong> </p>
<p>We swap the cross entropy loss from PyTorch,</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
</code></pre></div>
<p>with the CORN loss (also provided via <code>coral_pytorch</code>):</p>
<div class="highlight"><pre><span></span><code><span class="n">loss</span> <span class="o">=</span> <span class="n">corn_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span>
                 <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
</code></pre></div>
<p>Note that we pass <code>num_classes</code> instead of <code>num_classes-1</code> 
to the <code>corn_loss</code> as it takes care of the rest internally.</p>
<p><strong>3)</strong></p>
<p>In a regular classifier, we usually obtain the predicted class labels as follows:</p>
<div class="highlight"><pre><span></span><code><span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p>In CORN, w replace this with the following code to convert the predicted probabilities into the predicted labels:</p>
<div class="highlight"><pre><span></span><code><span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">corn_label_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</code></pre></div>
<h2 id="implementing-a-convnet-using-pytorch-lightnings-lightningmodule">Implementing a <code>ConvNet</code> using PyTorch Lightning's <code>LightningModule</code></h2>
<ul>
<li>In this section, we set up the main model architecture using the <code>LightningModule</code> from PyTorch Lightning.</li>
<li>We start with defining our convolutional neural network <code>ConvNet</code> model in pure PyTorch, and then we use it in the <code>LightningModule</code> to get all the extra benefits that PyTorch Lightning provides.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>


<span class="c1"># Regular PyTorch Module</span>
<span class="k">class</span> <span class="nc">ConvNet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># num_classes is used by the corn loss function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>

        <span class="c1"># Initialize CNN layers</span>
        <span class="n">all_layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                            <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
                            <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>  <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> 
                            <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
                            <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>  <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">]</span>

        <span class="c1"># CORN output layer --------------------------------------</span>
        <span class="c1"># Regular classifier would use num_classes instead of </span>
        <span class="c1"># num_classes-1 below</span>
        <span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">294</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># ---------------------------------------------------------</span>

        <span class="n">all_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">all_layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<ul>
<li>In our <code>LightningModule</code> we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later.</li>
<li>Given a CNN classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes:<ol>
<li>Instead of using <code>num_classes</code> in the output layer, use <code>num_classes-1</code> as shown above</li>
<li>Change the loss from <br />
<code>loss = torch.nn.functional.cross_entropy(logits, y)</code> to<br />
<code>loss = corn_loss(logits, y, num_classes=self.num_classes)</code></li>
<li>To obtain the class/rank labels from the logits, change<br />
<code>predicted_labels = torch.argmax(logits, dim=1)</code> to<br />
<code>predicted_labels = corn_label_from_logits(logits)</code></li>
</ol>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">coral_pytorch.losses</span> <span class="kn">import</span> <span class="n">corn_loss</span>
<span class="kn">from</span> <span class="nn">coral_pytorch.dataset</span> <span class="kn">import</span> <span class="n">corn_label_from_logits</span>

<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">torchmetrics</span>


<span class="c1"># LightningModule that receives a PyTorch model as input</span>
<span class="k">class</span> <span class="nc">LightningCNN</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="c1"># The inherited PyTorch module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="c1"># Save settings and hyperparameters to the log directory</span>
        <span class="c1"># but skip the model parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">])</span>

        <span class="c1"># Set up attributes for computing the MAE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mae</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanAbsoluteError</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_mae</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanAbsoluteError</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_mae</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanAbsoluteError</span><span class="p">()</span>

    <span class="c1"># Defining the forward method is only necessary </span>
    <span class="c1"># if you want to use a Trainer&#39;s .predict() method (optional)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># A common forward step to compute the loss and labels</span>
    <span class="c1"># this is used for training, validation, and testing below</span>
    <span class="k">def</span> <span class="nf">_shared_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">features</span><span class="p">,</span> <span class="n">true_labels</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># Use CORN loss --------------------------------------</span>
        <span class="c1"># A regular classifier uses:</span>
        <span class="c1"># loss = torch.nn.functional.cross_entropy(logits, y)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">corn_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span>
                         <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
        <span class="c1"># ----------------------------------------------------</span>

        <span class="c1"># CORN logits to labels ------------------------------</span>
        <span class="c1"># A regular classifier uses:</span>
        <span class="c1"># predicted_labels = torch.argmax(logits, dim=1)</span>
        <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">corn_label_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="c1"># ----------------------------------------------------</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_mae</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_mae&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_mae</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>  <span class="c1"># this is passed to the optimzer for training</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;valid_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_mae</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;valid_mae&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_mae</span><span class="p">,</span>
                 <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_mae</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_mae&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_mae</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>
</code></pre></div>
<h2 id="setting-up-the-dataset">Setting up the dataset</h2>
<ul>
<li>In this section, we are going to set up our dataset.</li>
<li>Please note that <strong>MNIST is not an ordinal dataset</strong>. The reason why we use MNIST in this tutorial is that it is included in the PyTorch's <code>torchvision</code> library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps.</li>
</ul>
<h3 id="inspecting-the-dataset">Inspecting the dataset</h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>


<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">DATA_BASEPATH</span><span class="p">,</span> 
                               <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                               <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                               <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> 
                          <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> 
                          <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
                          <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">DATA_BASEPATH</span><span class="p">,</span> 
                              <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span> 
                         <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                         <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
                         <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Checking the dataset</span>
<span class="n">all_train_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_test_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>  
    <span class="n">all_train_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">all_train_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_train_labels</span><span class="p">)</span>

<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>  
    <span class="n">all_test_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">all_test_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_test_labels</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training labels:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">all_train_labels</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training label distribution:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">all_train_labels</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test labels:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">all_test_labels</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test label distribution:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">all_test_labels</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Training labels: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
Training label distribution: tensor([5914, 6731, 5946, 6121, 5834, 5413, 5910, 6254, 5840, 5941])

Test labels: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
Test label distribution: tensor([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009])
</code></pre></div>
<ul>
<li>Above, we can see that the dataset consists of 8 features, and there are 998 examples in total.</li>
<li>The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). </li>
<li>Notice also that the dataset is quite imbalanced.</li>
</ul>
<h3 id="performance-baseline">Performance baseline</h3>
<ul>
<li>Especially for imbalanced datasets, it's quite useful to compute a performance baseline.</li>
<li>In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that!</li>
<li>Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE).</li>
<li>So, if we use the mean absolute error, <script type="math/tex">\mathrm{MAE}=\frac{1}{N} \sum_{i=1}^{N}\left|y_{i}-\hat{y}_{i}\right|</script>, to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">all_test_labels</span> <span class="o">=</span> <span class="n">all_test_labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">avg_prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">all_test_labels</span><span class="p">)</span>  <span class="c1"># median minimizes MAE</span>
<span class="n">baseline_mae</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">all_test_labels</span> <span class="o">-</span> <span class="n">avg_prediction</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Baseline MAE: </span><span class="si">{</span><span class="n">baseline_mae</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Baseline MAE: 2.52
</code></pre></div>
<ul>
<li>In other words, a model that would always predict the dataset median would achieve a MAE of 2.52. A model that has an MAE of &gt; 2.52 is certainly a bad model.</li>
</ul>
<h3 id="setting-up-a-datamodule">Setting up a <code>DataModule</code></h3>
<ul>
<li>There are three main ways we can prepare the dataset for Lightning. We can</li>
<li>make the dataset part of the model;</li>
<li>set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection;</li>
<li>create a LightningDataModule.</li>
<li>Here, we are going to use approach 3, which is the most organized approach. The <code>LightningDataModule</code> consists of several self-explanatory methods as we can see below:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">torch.utils.data.dataset</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>


<span class="k">class</span> <span class="nc">DataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span> <span class="o">=</span> <span class="n">data_path</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span>
                       <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Note transforms.ToTensor() scales input images</span>
        <span class="c1"># to 0-1 range</span>
        <span class="n">train</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> 
                               <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                               <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                               <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> 
                                   <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                   <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                   <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> 
                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> 
                                  <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                  <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">train_loader</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valid</span><span class="p">,</span> 
                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> 
                                  <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                  <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">valid_loader</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> 
                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> 
                                 <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                 <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">test_loader</span>
</code></pre></div>
<ul>
<li>Note that the <code>prepare_data</code> method is usually used for steps that only need to be executed once, for example, downloading the dataset; the <code>setup</code> method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. </li>
<li>Next, lets initialize the <code>DataModule</code>; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code):</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">data_module</span> <span class="o">=</span> <span class="n">DataModule</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="n">DATA_BASEPATH</span><span class="p">)</span>
</code></pre></div>
<h2 id="training-the-model-using-the-pytorch-lightning-trainer-class">Training the model using the PyTorch Lightning Trainer class</h2>
<ul>
<li>Next, we initialize our CNN (<code>ConvNet</code>) model.</li>
<li>Also, we define a call back so that we can obtain the model with the best validation set performance after training.</li>
<li>PyTorch Lightning offers <a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html">many advanced logging services</a> like Weights &amp; Biases. Here, we will keep things simple and use the <code>CSVLogger</code>:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.loggers</span> <span class="kn">import</span> <span class="n">CSVLogger</span>


<span class="n">pytorch_model</span> <span class="o">=</span> <span class="n">ConvNet</span><span class="p">(</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">all_test_labels</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">lightning_model</span> <span class="o">=</span> <span class="n">LightningCNN</span><span class="p">(</span>
    <span class="n">pytorch_model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">save_top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;valid_mae&quot;</span><span class="p">)]</span>  <span class="c1"># save top 1 model </span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">CSVLogger</span><span class="p">(</span><span class="n">save_dir</span><span class="o">=</span><span class="s2">&quot;logs/&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cnn-corn-mnist&quot;</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>Now it's time to train our model:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">time</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="n">NUM_EPOCHS</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="n">progress_bar_refresh_rate</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>  <span class="c1"># recommended for notebooks</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>  <span class="c1"># Uses GPUs or TPUs if available</span>
    <span class="n">devices</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>  <span class="c1"># Uses all available GPUs/TPUs if applicable</span>
    <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
    <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">lightning_model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">data_module</span><span class="p">)</span>

<span class="n">runtime</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span><span class="o">/</span><span class="mi">60</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training took </span><span class="si">{</span><span class="n">runtime</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> min in total.&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type              | Params
------------------------------------------------
0 | model     | ConvNet           | 2.9 K 
1 | train_mae | MeanAbsoluteError | 0     
2 | valid_mae | MeanAbsoluteError | 0     
3 | test_mae  | MeanAbsoluteError | 0     
------------------------------------------------
2.9 K     Trainable params
0         Non-trainable params
2.9 K     Total params
0.011     Total estimated model params size (MB)


Training took 1.67 min in total.
</code></pre></div>
<h2 id="evaluating-the-model">Evaluating the model</h2>
<ul>
<li>After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a <a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html">more advanced logger</a> that does that for you):</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="si">}</span><span class="s2">/metrics.csv&quot;</span><span class="p">)</span>

<span class="n">aggreg_metrics</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">agg_col</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dfg</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">agg_col</span><span class="p">):</span>
    <span class="n">agg</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">dfg</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">agg</span><span class="p">[</span><span class="n">agg_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">aggreg_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">agg</span><span class="p">)</span>

<span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">aggreg_metrics</span><span class="p">)</span>
<span class="n">df_metrics</span><span class="p">[[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;valid_loss&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">df_metrics</span><span class="p">[[</span><span class="s2">&quot;train_mae&quot;</span><span class="p">,</span> <span class="s2">&quot;valid_mae&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>&lt;AxesSubplot:xlabel=&#39;Epoch&#39;, ylabel=&#39;MAE&#39;&gt;
</code></pre></div>
<p><img alt="png" src="../ordinal-corn_mnist_files/ordinal-corn_mnist_36_1.png" /></p>
<p><img alt="png" src="../ordinal-corn_mnist_files/ordinal-corn_mnist_36_2.png" /></p>
<ul>
<li>As we can see from the loss plot above, the model starts overfitting pretty quickly; however the validation set MAE keeps improving. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 16.</li>
<li>The <code>trainer</code> saved this model automatically for us, we which we can load from the checkpoint via the <code>ckpt_path='best'</code> argument; below we use the <code>trainer</code> instance to evaluate the best model on the test set:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">lightning_model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">data_module</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>The MAE of our model is quite good, especially compared to the 2.52 MAE baseline earlier.</li>
</ul>
<h2 id="predicting-labels-of-new-data">Predicting labels of new data</h2>
<ul>
<li>You can use the <code>trainer.predict</code> method on a new <code>DataLoader</code> or <code>DataModule</code> to apply the model to new data.</li>
<li>Alternatively, you can also manually load the best model from a checkpoint as shown below:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">path</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">checkpoint_callback</span><span class="o">.</span><span class="n">best_model_path</span>
<span class="nb">print</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">lightning_model</span> <span class="o">=</span> <span class="n">LightningCNN</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">pytorch_model</span><span class="p">)</span>
<span class="n">lightning_model</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>
</code></pre></div>
<ul>
<li>Note that our <code>ConvNet</code>, which is passed to <code>LightningCNN</code> requires input arguments. However, this is automatically being taken care of since we used <code>self.save_hyperparameters()</code> in <code>LightningCNN</code>'s <code>__init__</code> method.</li>
<li>Now, below is an example applying the model manually. Here, pretend that the <code>test_dataloader</code> is a new data loader.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">data_module</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>

<span class="n">all_predicted_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">lightning_model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">corn_label_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">all_predicted_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_labels</span><span class="p">)</span>

<span class="n">all_predicted_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_predicted_labels</span><span class="p">)</span>
<span class="n">all_predicted_labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</code></pre></div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../ordinal-corn_cement/" class="md-footer__link md-footer__link--prev" aria-label="Previous: CORN multilayer perceptron for tabular data (Cement dataset)" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              CORN multilayer perceptron for tabular data (Cement dataset)
            </div>
          </div>
        </a>
      
      
        
        <a href="../ordinal-corn_tripadvisor/" class="md-footer__link md-footer__link--next" aria-label="Next: CORN recurrent neural net for text data (TripAdvisor dataset)" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              CORN recurrent neural net for text data (TripAdvisor dataset)
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020-2022 <a href="http://sebastianraschka.com">Sebastian Raschka</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../../../assets/javascripts/bundle.960e086b.min.js"></script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      
        <script src="../../../mathjaxhelper.js"></script>
      
    
  </body>
</html>