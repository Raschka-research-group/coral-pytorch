{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CORAL implementation for ordinal regression with deep neural networks. About CORAL (COnsistent RAnk Logits) and CORN (Conditional Ordinal Regression for Neural networks) are methods for ordinal regression with deep neural networks, which address the rank inconsistency issue of other ordinal regression frameworks. Originally, developed this method in the context of age prediction from face images. Our approach was evaluated on several face image datasets for age prediction using ResNet-34, but it is compatible with other state-of-the-art deep neural networks. This repository implements the CORAL and CORN functionality (neural network layer, loss function, and dataset utilities) for convenient use. Examples are provided via the \"Tutorials\" that can be found on the documentation website at https://Raschka-research-group.github.io/coral_pytorch . If you are looking for the orginal implementation, training datasets, and training log files corresponding to the paper, you can find these here: CORAL: https://github.com/Raschka-research-group/coral-cnn . CORN: https://github.com/Raschka-research-group/corn-ordinal-neuralnet References CORAL Wenzhi Cao, Vahid Mirjalili, and Sebastian Raschka (2020). Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation . Pattern Recognition Letters 140, pp. 325-331; https://doi.org/10.1016/j.patrec.2020.11.008 . CORN Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851","title":"Home"},{"location":"#about","text":"CORAL (COnsistent RAnk Logits) and CORN (Conditional Ordinal Regression for Neural networks) are methods for ordinal regression with deep neural networks, which address the rank inconsistency issue of other ordinal regression frameworks. Originally, developed this method in the context of age prediction from face images. Our approach was evaluated on several face image datasets for age prediction using ResNet-34, but it is compatible with other state-of-the-art deep neural networks. This repository implements the CORAL and CORN functionality (neural network layer, loss function, and dataset utilities) for convenient use. Examples are provided via the \"Tutorials\" that can be found on the documentation website at https://Raschka-research-group.github.io/coral_pytorch . If you are looking for the orginal implementation, training datasets, and training log files corresponding to the paper, you can find these here: CORAL: https://github.com/Raschka-research-group/coral-cnn . CORN: https://github.com/Raschka-research-group/corn-ordinal-neuralnet","title":"About"},{"location":"#references","text":"CORAL Wenzhi Cao, Vahid Mirjalili, and Sebastian Raschka (2020). Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation . Pattern Recognition Letters 140, pp. 325-331; https://doi.org/10.1016/j.patrec.2020.11.008 . CORN Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851","title":"References"},{"location":"CHANGELOG/","text":"Release Notes The changelog for the current development version is available at [https://github.com/raschka-research-group/coral_pytorch/blob/main/docs/CHANGELOG.md](https://github.com/raschka-research-group/coral_pytorch/blob/main/docs/CHANGELOG.md. 1.2.0dev (11-17-2021) Downloads Source code (zip) Source code (tar.gz) New Features Add CORN loss corresponding to the manuscript, \" Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities \" Changes Bug Fixes - 1.1.0 (04/08/2021) Downloads Source code (zip) Source code (tar.gz) New Features - Changes By default, bias units are now preinitialized to descending values in [0, 1] range (instead of all zero values), which results in faster training and better generalization performance. (PR #5 ) Bug Fixes - 1.0.0 (11/15/2020) Downloads Source code (zip) Source code (tar.gz) New Features First release. Changes First release. Bug Fixes First release.","title":"Release Notes"},{"location":"CHANGELOG/#release-notes","text":"The changelog for the current development version is available at [https://github.com/raschka-research-group/coral_pytorch/blob/main/docs/CHANGELOG.md](https://github.com/raschka-research-group/coral_pytorch/blob/main/docs/CHANGELOG.md.","title":"Release Notes"},{"location":"CHANGELOG/#120dev-11-17-2021","text":"","title":"1.2.0dev (11-17-2021)"},{"location":"CHANGELOG/#downloads","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features","text":"Add CORN loss corresponding to the manuscript, \" Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities \"","title":"New Features"},{"location":"CHANGELOG/#changes","text":"","title":"Changes"},{"location":"CHANGELOG/#bug-fixes","text":"-","title":"Bug Fixes"},{"location":"CHANGELOG/#110-04082021","text":"","title":"1.1.0 (04/08/2021)"},{"location":"CHANGELOG/#downloads_1","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_1","text":"-","title":"New Features"},{"location":"CHANGELOG/#changes_1","text":"By default, bias units are now preinitialized to descending values in [0, 1] range (instead of all zero values), which results in faster training and better generalization performance. (PR #5 )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_1","text":"-","title":"Bug Fixes"},{"location":"CHANGELOG/#100-11152020","text":"","title":"1.0.0 (11/15/2020)"},{"location":"CHANGELOG/#downloads_2","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_2","text":"First release.","title":"New Features"},{"location":"CHANGELOG/#changes_2","text":"First release.","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_2","text":"First release.","title":"Bug Fixes"},{"location":"citing/","text":"If you use CORAL or CORN as part of your workflow in a scientific publication, please consider citing the corresponding paper: CORAL Wenzhi Cao, Vahid Mirjalili, and Sebastian Raschka (2020). Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation . Pattern Recognition Letters 140, pp. 325-331; https://doi.org/10.1016/j.patrec.2020.11.008 . @article{coral2020, title={Rank consistent ordinal regression for neural networks with application to age estimation}, journal={Pattern Recognition Letters}, volume={140}, pages={325-331}, year={2020}, issn={0167-8655}, doi={https://doi.org/10.1016/j.patrec.2020.11.008}, url={http://www.sciencedirect.com/science/article/pii/S016786552030413X}, author={Wenzhi Cao and Vahid Mirjalili and Sebastian Raschka} } CORN Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851 @misc{shi2021deep, title={Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities}, author={Xintong Shi and Wenzhi Cao and Sebastian Raschka}, year={2021}, eprint={2111.08851}, archivePrefix={arXiv}, primaryClass={cs.LG} }","title":"Citing"},{"location":"installation/","text":"Installing coral_pytorch Requirements Coral-pytorch requires the following software and packages: Python >= 3.6 PyTorch >= 1.5.0 PyPI You can install the latest stable release of coral_pytorch directly from Python's package index via pip by executing the following code from your command line: pip install coral_pytorch Latest GitHub Source Code You want to try out the latest features before they go live on PyPI? Install the coral_pytorch dev-version latest development version from the GitHub repository by executing pip install git+git://github.com/rasbt/coral_pytorch.git Alternatively, you download the package manually from GitHub via the Dowload ZIP button, unzip it, navigate into the package directory, and execute the following command: python setup.py install","title":"Installation"},{"location":"installation/#installing-coral_pytorch","text":"","title":"Installing coral_pytorch"},{"location":"installation/#requirements","text":"Coral-pytorch requires the following software and packages: Python >= 3.6 PyTorch >= 1.5.0","title":"Requirements"},{"location":"installation/#pypi","text":"You can install the latest stable release of coral_pytorch directly from Python's package index via pip by executing the following code from your command line: pip install coral_pytorch","title":"PyPI"},{"location":"installation/#latest-github-source-code","text":"You want to try out the latest features before they go live on PyPI? Install the coral_pytorch dev-version latest development version from the GitHub repository by executing pip install git+git://github.com/rasbt/coral_pytorch.git Alternatively, you download the package manually from GitHub via the Dowload ZIP button, unzip it, navigate into the package directory, and execute the following command: python setup.py install","title":"Latest GitHub Source Code"},{"location":"license/","text":"MIT License Copyright (c) 2020-2022 Sebastian Raschka Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#mit-license","text":"Copyright (c) 2020-2022 Sebastian Raschka Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"api_modules/coral_pytorch.dataset/corn_label_from_logits/","text":"corn_label_from_logits corn_label_from_logits(logits) Returns the predicted rank label from logits for a network trained via the CORN loss. Parameters logits : torch.tensor, shape=(n_examples, n_classes) Torch tensor consisting of logits returned by the neural net. Returns labels : torch.tensor, shape=(n_examples) Integer tensor containing the predicted rank (class) labels Examples >>> # 2 training examples, 5 classes >>> logits = torch.tensor([[14.152, -6.1942, 0.47710, 0.96850], ... [65.667, 0.303, 11.500, -4.524]]) >>> corn_label_from_logits(logits) tensor([1, 3])","title":"Corn label from logits"},{"location":"api_modules/coral_pytorch.dataset/corn_label_from_logits/#corn_label_from_logits","text":"corn_label_from_logits(logits) Returns the predicted rank label from logits for a network trained via the CORN loss. Parameters logits : torch.tensor, shape=(n_examples, n_classes) Torch tensor consisting of logits returned by the neural net. Returns labels : torch.tensor, shape=(n_examples) Integer tensor containing the predicted rank (class) labels Examples >>> # 2 training examples, 5 classes >>> logits = torch.tensor([[14.152, -6.1942, 0.47710, 0.96850], ... [65.667, 0.303, 11.500, -4.524]]) >>> corn_label_from_logits(logits) tensor([1, 3])","title":"corn_label_from_logits"},{"location":"api_modules/coral_pytorch.dataset/label_to_levels/","text":"label_to_levels label_to_levels(label, num_classes, dtype=torch.float32) Converts integer class label to extended binary label vector Parameters label : int Class label to be converted into a extended binary vector. Should be smaller than num_classes-1. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_classes-1,) Extended binary label vector. Type is determined by the dtype parameter. Examples >>> label_to_levels(0, num_classes=5) tensor([0., 0., 0., 0.]) >>> label_to_levels(1, num_classes=5) tensor([1., 0., 0., 0.]) >>> label_to_levels(3, num_classes=5) tensor([1., 1., 1., 0.]) >>> label_to_levels(4, num_classes=5) tensor([1., 1., 1., 1.])","title":"Label to levels"},{"location":"api_modules/coral_pytorch.dataset/label_to_levels/#label_to_levels","text":"label_to_levels(label, num_classes, dtype=torch.float32) Converts integer class label to extended binary label vector Parameters label : int Class label to be converted into a extended binary vector. Should be smaller than num_classes-1. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_classes-1,) Extended binary label vector. Type is determined by the dtype parameter. Examples >>> label_to_levels(0, num_classes=5) tensor([0., 0., 0., 0.]) >>> label_to_levels(1, num_classes=5) tensor([1., 0., 0., 0.]) >>> label_to_levels(3, num_classes=5) tensor([1., 1., 1., 0.]) >>> label_to_levels(4, num_classes=5) tensor([1., 1., 1., 1.])","title":"label_to_levels"},{"location":"api_modules/coral_pytorch.dataset/levels_from_labelbatch/","text":"levels_from_labelbatch levels_from_labelbatch(labels, num_classes, dtype=torch.float32) Converts a list of integer class label to extended binary label vectors Parameters labels : list or 1D orch.tensor, shape=(num_labels,) A list or 1D torch.tensor with integer class labels to be converted into extended binary label vectors. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_labels, num_classes-1) Examples >>> levels_from_labelbatch(labels=[2, 1, 4], num_classes=5) tensor([[1., 1., 0., 0.], [1., 0., 0., 0.], [1., 1., 1., 1.]])","title":"Levels from labelbatch"},{"location":"api_modules/coral_pytorch.dataset/levels_from_labelbatch/#levels_from_labelbatch","text":"levels_from_labelbatch(labels, num_classes, dtype=torch.float32) Converts a list of integer class label to extended binary label vectors Parameters labels : list or 1D orch.tensor, shape=(num_labels,) A list or 1D torch.tensor with integer class labels to be converted into extended binary label vectors. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_labels, num_classes-1) Examples >>> levels_from_labelbatch(labels=[2, 1, 4], num_classes=5) tensor([[1., 1., 0., 0.], [1., 0., 0., 0.], [1., 1., 1., 1.]])","title":"levels_from_labelbatch"},{"location":"api_modules/coral_pytorch.dataset/proba_to_label/","text":"proba_to_label proba_to_label(probas) Converts predicted probabilities from extended binary format to integer class labels Parameters probas : torch.tensor, shape(n_examples, n_labels) Torch tensor consisting of probabilities returned by CORAL model. Examples >>> # 3 training examples, 6 classes >>> probas = torch.tensor([[0.934, 0.861, 0.323, 0.492, 0.295], ... [0.496, 0.485, 0.267, 0.124, 0.058], ... [0.985, 0.967, 0.920, 0.819, 0.506]]) >>> proba_to_label(probas) tensor([2, 0, 5])","title":"Proba to label"},{"location":"api_modules/coral_pytorch.dataset/proba_to_label/#proba_to_label","text":"proba_to_label(probas) Converts predicted probabilities from extended binary format to integer class labels Parameters probas : torch.tensor, shape(n_examples, n_labels) Torch tensor consisting of probabilities returned by CORAL model. Examples >>> # 3 training examples, 6 classes >>> probas = torch.tensor([[0.934, 0.861, 0.323, 0.492, 0.295], ... [0.496, 0.485, 0.267, 0.124, 0.058], ... [0.985, 0.967, 0.920, 0.819, 0.506]]) >>> proba_to_label(probas) tensor([2, 0, 5])","title":"proba_to_label"},{"location":"api_modules/coral_pytorch.layers/CoralLayer/","text":"CoralLayer CoralLayer(size_in, num_classes, preinit_bias=True) Implements CORAL layer described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters size_in : int Number of input features for the inputs to the forward method, which are expected to have shape=(num_examples, num_features). num_classes : int Number of classes in the dataset. preinit_bias : bool (default=True) If true, it will pre-initialize the biases to descending values in [0, 1] range instead of initializing it to all zeros. This pre- initialization scheme results in faster learning and better generalization performance in practice.","title":"CoralLayer"},{"location":"api_modules/coral_pytorch.layers/CoralLayer/#corallayer","text":"CoralLayer(size_in, num_classes, preinit_bias=True) Implements CORAL layer described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters size_in : int Number of input features for the inputs to the forward method, which are expected to have shape=(num_examples, num_features). num_classes : int Number of classes in the dataset. preinit_bias : bool (default=True) If true, it will pre-initialize the biases to descending values in [0, 1] range instead of initializing it to all zeros. This pre- initialization scheme results in faster learning and better generalization performance in practice.","title":"CoralLayer"},{"location":"api_modules/coral_pytorch.losses/coral_loss/","text":"coral_loss coral_loss(logits, levels, importance_weights=None, reduction='mean') Computes the CORAL loss described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters logits : torch.tensor, shape(num_examples, num_classes-1) Outputs of the CORAL layer. levels : torch.tensor, shape(num_examples, num_classes-1) True labels represented as extended binary vectors (via coral_pytorch.dataset.levels_from_labelbatch ). importance_weights : torch.tensor, shape=(num_classes-1,) (default=None) Optional weights for the different labels in levels. A tensor of ones, i.e., torch.ones(num_classes-1, dtype=torch.float32) will result in uniform weights that have the same effect as None. reduction : str or None (default='mean') If 'mean' or 'sum', returns the averaged or summed loss value across all data points (rows) in logits. If None, returns a vector of shape (num_examples,) Returns loss : torch.tensor A torch.tensor containing a single loss value (if reduction='mean' or ' sum' ) or a loss value for each data record (if reduction=None ). Examples >>> import torch >>> levels = torch.tensor( ... [[1., 1., 0., 0.], ... [1., 0., 0., 0.], ... [1., 1., 1., 1.]]) >>> logits = torch.tensor( ... [[2.1, 1.8, -2.1, -1.8], ... [1.9, -1., -1.5, -1.3], ... [1.9, 1.8, 1.7, 1.6]]) >>> coral_loss(logits, levels) tensor(0.6920)","title":"Coral loss"},{"location":"api_modules/coral_pytorch.losses/coral_loss/#coral_loss","text":"coral_loss(logits, levels, importance_weights=None, reduction='mean') Computes the CORAL loss described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters logits : torch.tensor, shape(num_examples, num_classes-1) Outputs of the CORAL layer. levels : torch.tensor, shape(num_examples, num_classes-1) True labels represented as extended binary vectors (via coral_pytorch.dataset.levels_from_labelbatch ). importance_weights : torch.tensor, shape=(num_classes-1,) (default=None) Optional weights for the different labels in levels. A tensor of ones, i.e., torch.ones(num_classes-1, dtype=torch.float32) will result in uniform weights that have the same effect as None. reduction : str or None (default='mean') If 'mean' or 'sum', returns the averaged or summed loss value across all data points (rows) in logits. If None, returns a vector of shape (num_examples,) Returns loss : torch.tensor A torch.tensor containing a single loss value (if reduction='mean' or ' sum' ) or a loss value for each data record (if reduction=None ). Examples >>> import torch >>> levels = torch.tensor( ... [[1., 1., 0., 0.], ... [1., 0., 0., 0.], ... [1., 1., 1., 1.]]) >>> logits = torch.tensor( ... [[2.1, 1.8, -2.1, -1.8], ... [1.9, -1., -1.5, -1.3], ... [1.9, 1.8, 1.7, 1.6]]) >>> coral_loss(logits, levels) tensor(0.6920)","title":"coral_loss"},{"location":"api_modules/coral_pytorch.losses/corn_loss/","text":"corn_loss corn_loss(logits, y_train, num_classes) Computes the CORN loss described in our forthcoming 'Deep Neural Networks for Rank Consistent Ordinal Regression based on Conditional Probabilities' manuscript. Parameters logits : torch.tensor, shape=(num_examples, num_classes-1) Outputs of the CORN layer. y_train : torch.tensor, shape=(num_examples) Torch tensor containing the class labels. num_classes : int Number of unique class labels (class labels should start at 0). Returns loss : torch.tensor A torch.tensor containing a single loss value. Examples >>> import torch >>> # Consider 8 training examples >>> _ = torch.manual_seed(123) >>> X_train = torch.rand(8, 99) >>> y_train = torch.tensor([0, 1, 2, 2, 2, 3, 4, 4]) >>> NUM_CLASSES = 5 >>> # >>> # >>> # def __init__(self): >>> corn_net = torch.nn.Linear(99, NUM_CLASSES-1) >>> # >>> # >>> # def forward(self, X_train): >>> logits = corn_net(X_train) >>> logits.shape torch.Size([8, 4]) >>> corn_loss(logits, y_train, NUM_CLASSES) tensor(3.4210, grad_fn=<DivBackward0>)","title":"Corn loss"},{"location":"api_modules/coral_pytorch.losses/corn_loss/#corn_loss","text":"corn_loss(logits, y_train, num_classes) Computes the CORN loss described in our forthcoming 'Deep Neural Networks for Rank Consistent Ordinal Regression based on Conditional Probabilities' manuscript. Parameters logits : torch.tensor, shape=(num_examples, num_classes-1) Outputs of the CORN layer. y_train : torch.tensor, shape=(num_examples) Torch tensor containing the class labels. num_classes : int Number of unique class labels (class labels should start at 0). Returns loss : torch.tensor A torch.tensor containing a single loss value. Examples >>> import torch >>> # Consider 8 training examples >>> _ = torch.manual_seed(123) >>> X_train = torch.rand(8, 99) >>> y_train = torch.tensor([0, 1, 2, 2, 2, 3, 4, 4]) >>> NUM_CLASSES = 5 >>> # >>> # >>> # def __init__(self): >>> corn_net = torch.nn.Linear(99, NUM_CLASSES-1) >>> # >>> # >>> # def forward(self, X_train): >>> logits = corn_net(X_train) >>> logits.shape torch.Size([8, 4]) >>> corn_loss(logits, y_train, NUM_CLASSES) tensor(3.4210, grad_fn=<DivBackward0>)","title":"corn_loss"},{"location":"api_subpackages/coral_pytorch.dataset/","text":"coral_pytorch version: 1.2.0dev0 label_to_levels label_to_levels(label, num_classes, dtype=torch.float32) Converts integer class label to extended binary label vector Parameters label : int Class label to be converted into a extended binary vector. Should be smaller than num_classes-1. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_classes-1,) Extended binary label vector. Type is determined by the dtype parameter. Examples >>> label_to_levels(0, num_classes=5) tensor([0., 0., 0., 0.]) >>> label_to_levels(1, num_classes=5) tensor([1., 0., 0., 0.]) >>> label_to_levels(3, num_classes=5) tensor([1., 1., 1., 0.]) >>> label_to_levels(4, num_classes=5) tensor([1., 1., 1., 1.]) proba_to_label proba_to_label(probas) Converts predicted probabilities from extended binary format to integer class labels Parameters probas : torch.tensor, shape(n_examples, n_labels) Torch tensor consisting of probabilities returned by CORAL model. Examples >>> # 3 training examples, 6 classes >>> probas = torch.tensor([[0.934, 0.861, 0.323, 0.492, 0.295], ... [0.496, 0.485, 0.267, 0.124, 0.058], ... [0.985, 0.967, 0.920, 0.819, 0.506]]) >>> proba_to_label(probas) tensor([2, 0, 5]) corn_label_from_logits corn_label_from_logits(logits) Returns the predicted rank label from logits for a network trained via the CORN loss. Parameters logits : torch.tensor, shape=(n_examples, n_classes) Torch tensor consisting of logits returned by the neural net. Returns labels : torch.tensor, shape=(n_examples) Integer tensor containing the predicted rank (class) labels Examples >>> # 2 training examples, 5 classes >>> logits = torch.tensor([[14.152, -6.1942, 0.47710, 0.96850], ... [65.667, 0.303, 11.500, -4.524]]) >>> corn_label_from_logits(logits) tensor([1, 3]) levels_from_labelbatch levels_from_labelbatch(labels, num_classes, dtype=torch.float32) Converts a list of integer class label to extended binary label vectors Parameters labels : list or 1D orch.tensor, shape=(num_labels,) A list or 1D torch.tensor with integer class labels to be converted into extended binary label vectors. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_labels, num_classes-1) Examples >>> levels_from_labelbatch(labels=[2, 1, 4], num_classes=5) tensor([[1., 1., 0., 0.], [1., 0., 0., 0.], [1., 1., 1., 1.]])","title":"coral_pytorch.dataset"},{"location":"api_subpackages/coral_pytorch.dataset/#label_to_levels","text":"label_to_levels(label, num_classes, dtype=torch.float32) Converts integer class label to extended binary label vector Parameters label : int Class label to be converted into a extended binary vector. Should be smaller than num_classes-1. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_classes-1,) Extended binary label vector. Type is determined by the dtype parameter. Examples >>> label_to_levels(0, num_classes=5) tensor([0., 0., 0., 0.]) >>> label_to_levels(1, num_classes=5) tensor([1., 0., 0., 0.]) >>> label_to_levels(3, num_classes=5) tensor([1., 1., 1., 0.]) >>> label_to_levels(4, num_classes=5) tensor([1., 1., 1., 1.])","title":"label_to_levels"},{"location":"api_subpackages/coral_pytorch.dataset/#proba_to_label","text":"proba_to_label(probas) Converts predicted probabilities from extended binary format to integer class labels Parameters probas : torch.tensor, shape(n_examples, n_labels) Torch tensor consisting of probabilities returned by CORAL model. Examples >>> # 3 training examples, 6 classes >>> probas = torch.tensor([[0.934, 0.861, 0.323, 0.492, 0.295], ... [0.496, 0.485, 0.267, 0.124, 0.058], ... [0.985, 0.967, 0.920, 0.819, 0.506]]) >>> proba_to_label(probas) tensor([2, 0, 5])","title":"proba_to_label"},{"location":"api_subpackages/coral_pytorch.dataset/#corn_label_from_logits","text":"corn_label_from_logits(logits) Returns the predicted rank label from logits for a network trained via the CORN loss. Parameters logits : torch.tensor, shape=(n_examples, n_classes) Torch tensor consisting of logits returned by the neural net. Returns labels : torch.tensor, shape=(n_examples) Integer tensor containing the predicted rank (class) labels Examples >>> # 2 training examples, 5 classes >>> logits = torch.tensor([[14.152, -6.1942, 0.47710, 0.96850], ... [65.667, 0.303, 11.500, -4.524]]) >>> corn_label_from_logits(logits) tensor([1, 3])","title":"corn_label_from_logits"},{"location":"api_subpackages/coral_pytorch.dataset/#levels_from_labelbatch","text":"levels_from_labelbatch(labels, num_classes, dtype=torch.float32) Converts a list of integer class label to extended binary label vectors Parameters labels : list or 1D orch.tensor, shape=(num_labels,) A list or 1D torch.tensor with integer class labels to be converted into extended binary label vectors. num_classes : int The number of class clabels in the dataset. Assumes class labels start at 0. Determines the size of the output vector. dtype : torch data type (default=torch.float32) Data type of the torch output vector for the extended binary labels. Returns levels : torch.tensor, shape=(num_labels, num_classes-1) Examples >>> levels_from_labelbatch(labels=[2, 1, 4], num_classes=5) tensor([[1., 1., 0., 0.], [1., 0., 0., 0.], [1., 1., 1., 1.]])","title":"levels_from_labelbatch"},{"location":"api_subpackages/coral_pytorch.layers/","text":"coral_pytorch version: 1.2.0dev0 CoralLayer CoralLayer(size_in, num_classes, preinit_bias=True) Implements CORAL layer described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters size_in : int Number of input features for the inputs to the forward method, which are expected to have shape=(num_examples, num_features). num_classes : int Number of classes in the dataset. preinit_bias : bool (default=True) If true, it will pre-initialize the biases to descending values in [0, 1] range instead of initializing it to all zeros. This pre- initialization scheme results in faster learning and better generalization performance in practice.","title":"coral_pytorch.layers"},{"location":"api_subpackages/coral_pytorch.layers/#corallayer","text":"CoralLayer(size_in, num_classes, preinit_bias=True) Implements CORAL layer described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters size_in : int Number of input features for the inputs to the forward method, which are expected to have shape=(num_examples, num_features). num_classes : int Number of classes in the dataset. preinit_bias : bool (default=True) If true, it will pre-initialize the biases to descending values in [0, 1] range instead of initializing it to all zeros. This pre- initialization scheme results in faster learning and better generalization performance in practice.","title":"CoralLayer"},{"location":"api_subpackages/coral_pytorch.losses/","text":"coral_pytorch version: 1.2.0dev0 corn_loss corn_loss(logits, y_train, num_classes) Computes the CORN loss described in our forthcoming 'Deep Neural Networks for Rank Consistent Ordinal Regression based on Conditional Probabilities' manuscript. Parameters logits : torch.tensor, shape=(num_examples, num_classes-1) Outputs of the CORN layer. y_train : torch.tensor, shape=(num_examples) Torch tensor containing the class labels. num_classes : int Number of unique class labels (class labels should start at 0). Returns loss : torch.tensor A torch.tensor containing a single loss value. Examples >>> import torch >>> # Consider 8 training examples >>> _ = torch.manual_seed(123) >>> X_train = torch.rand(8, 99) >>> y_train = torch.tensor([0, 1, 2, 2, 2, 3, 4, 4]) >>> NUM_CLASSES = 5 >>> # >>> # >>> # def __init__(self): >>> corn_net = torch.nn.Linear(99, NUM_CLASSES-1) >>> # >>> # >>> # def forward(self, X_train): >>> logits = corn_net(X_train) >>> logits.shape torch.Size([8, 4]) >>> corn_loss(logits, y_train, NUM_CLASSES) tensor(3.4210, grad_fn=<DivBackward0>) coral_loss coral_loss(logits, levels, importance_weights=None, reduction='mean') Computes the CORAL loss described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters logits : torch.tensor, shape(num_examples, num_classes-1) Outputs of the CORAL layer. levels : torch.tensor, shape(num_examples, num_classes-1) True labels represented as extended binary vectors (via coral_pytorch.dataset.levels_from_labelbatch ). importance_weights : torch.tensor, shape=(num_classes-1,) (default=None) Optional weights for the different labels in levels. A tensor of ones, i.e., torch.ones(num_classes-1, dtype=torch.float32) will result in uniform weights that have the same effect as None. reduction : str or None (default='mean') If 'mean' or 'sum', returns the averaged or summed loss value across all data points (rows) in logits. If None, returns a vector of shape (num_examples,) Returns loss : torch.tensor A torch.tensor containing a single loss value (if reduction='mean' or ' sum' ) or a loss value for each data record (if reduction=None ). Examples >>> import torch >>> levels = torch.tensor( ... [[1., 1., 0., 0.], ... [1., 0., 0., 0.], ... [1., 1., 1., 1.]]) >>> logits = torch.tensor( ... [[2.1, 1.8, -2.1, -1.8], ... [1.9, -1., -1.5, -1.3], ... [1.9, 1.8, 1.7, 1.6]]) >>> coral_loss(logits, levels) tensor(0.6920)","title":"coral_pytorch.losses"},{"location":"api_subpackages/coral_pytorch.losses/#corn_loss","text":"corn_loss(logits, y_train, num_classes) Computes the CORN loss described in our forthcoming 'Deep Neural Networks for Rank Consistent Ordinal Regression based on Conditional Probabilities' manuscript. Parameters logits : torch.tensor, shape=(num_examples, num_classes-1) Outputs of the CORN layer. y_train : torch.tensor, shape=(num_examples) Torch tensor containing the class labels. num_classes : int Number of unique class labels (class labels should start at 0). Returns loss : torch.tensor A torch.tensor containing a single loss value. Examples >>> import torch >>> # Consider 8 training examples >>> _ = torch.manual_seed(123) >>> X_train = torch.rand(8, 99) >>> y_train = torch.tensor([0, 1, 2, 2, 2, 3, 4, 4]) >>> NUM_CLASSES = 5 >>> # >>> # >>> # def __init__(self): >>> corn_net = torch.nn.Linear(99, NUM_CLASSES-1) >>> # >>> # >>> # def forward(self, X_train): >>> logits = corn_net(X_train) >>> logits.shape torch.Size([8, 4]) >>> corn_loss(logits, y_train, NUM_CLASSES) tensor(3.4210, grad_fn=<DivBackward0>)","title":"corn_loss"},{"location":"api_subpackages/coral_pytorch.losses/#coral_loss","text":"coral_loss(logits, levels, importance_weights=None, reduction='mean') Computes the CORAL loss described in Cao, Mirjalili, and Raschka (2020) *Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation* Pattern Recognition Letters, https://doi.org/10.1016/j.patrec.2020.11.008 Parameters logits : torch.tensor, shape(num_examples, num_classes-1) Outputs of the CORAL layer. levels : torch.tensor, shape(num_examples, num_classes-1) True labels represented as extended binary vectors (via coral_pytorch.dataset.levels_from_labelbatch ). importance_weights : torch.tensor, shape=(num_classes-1,) (default=None) Optional weights for the different labels in levels. A tensor of ones, i.e., torch.ones(num_classes-1, dtype=torch.float32) will result in uniform weights that have the same effect as None. reduction : str or None (default='mean') If 'mean' or 'sum', returns the averaged or summed loss value across all data points (rows) in logits. If None, returns a vector of shape (num_examples,) Returns loss : torch.tensor A torch.tensor containing a single loss value (if reduction='mean' or ' sum' ) or a loss value for each data record (if reduction=None ). Examples >>> import torch >>> levels = torch.tensor( ... [[1., 1., 0., 0.], ... [1., 0., 0., 0.], ... [1., 1., 1., 1.]]) >>> logits = torch.tensor( ... [[2.1, 1.8, -2.1, -1.8], ... [1.9, -1., -1.5, -1.3], ... [1.9, 1.8, 1.7, 1.6]]) >>> coral_loss(logits, levels) tensor(0.6920)","title":"coral_loss"},{"location":"tutorials/pure_pytorch/CORAL_cement/","text":"CORAL MLP for predicting cement strength (cement_strength) This tutorial explains how to train a deep neural network (here: multilayer perceptron) with the CORAL layer and loss function for ordinal regression. 0 -- Obtaining and preparing the cement_strength dataset We will be using the cement_strength dataset from https://github.com/gagolews/ordinal_regression_data/blob/master/cement_strength.csv . First, we are going to download and prepare the and save it as CSV files locally. This is a general procedure that is not specific to CORN. This dataset has 5 ordinal labels (1, 2, 3, 4, and 5). Note that CORN requires labels to be starting at 0, which is why we subtract \"1\" from the label column. import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/gagolews/ordinal_regression_data/master/cement_strength.csv\" ) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 data_labels = data_df [ \"response\" ] data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] print ( 'Number of features:' , data_features . shape [ 1 ]) print ( 'Number of examples:' , data_features . shape [ 0 ]) print ( 'Labels:' , np . unique ( data_labels . values )) Number of features: 8 Number of examples: 998 Labels: [0 1 2 3 4] Split into training and test data from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( data_features . values , data_labels . values , test_size = 0.2 , random_state = 1 , stratify = data_labels . values ) Standardize features from sklearn.preprocessing import StandardScaler sc = StandardScaler () X_train_std = sc . fit_transform ( X_train ) X_test_std = sc . transform ( X_test ) 1 -- Setting up the dataset and dataloader In this section, we set up the data set and data loaders using PyTorch utilities. This is a general procedure that is not specific to CORAL. import torch ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.05 num_epochs = 20 batch_size = 128 # Architecture NUM_CLASSES = 10 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) Training on cpu from torch.utils.data import Dataset class MyDataset ( Dataset ): def __init__ ( self , feature_array , label_array , dtype = np . float32 ): self . features = feature_array . astype ( np . float32 ) self . labels = label_array def __getitem__ ( self , index ): inputs = self . features [ index ] label = self . labels [ index ] return inputs , label def __len__ ( self ): return self . labels . shape [ 0 ] import torch from torch.utils.data import DataLoader # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = MyDataset ( X_train_std , y_train ) test_dataset = MyDataset ( X_test_std , y_test ) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , shuffle = True , # want to shuffle the dataset num_workers = 0 ) # number processes/CPUs to use test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , shuffle = False , num_workers = 0 ) # Checking the dataset for inputs , labels in train_loader : print ( 'Input batch dimensions:' , inputs . shape ) print ( 'Input label dimensions:' , labels . shape ) break Input batch dimensions: torch.Size([128, 8]) Input label dimensions: torch.Size([128]) 2 - Equipping MLP with CORAL layer In this section, we are using the CoralLayer implemented in coral_pytorch to outfit a multilayer perceptron for ordinal regression. Note that the CORAL method only requires replacing the last (output) layer, which is typically a fully-connected layer, by the CORAL layer. Also, please use the sigmoid not softmax function (since the CORAL method uses a concept known as extended binary classification as described in the paper). from coral_pytorch.layers import CoralLayer class MLP ( torch . nn . Module ): def __init__ ( self , in_features , num_classes , num_hidden_1 = 300 , num_hidden_2 = 300 ): super () . __init__ () self . my_network = torch . nn . Sequential ( # 1st hidden layer torch . nn . Linear ( in_features , num_hidden_1 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_1 ), # 2nd hidden layer torch . nn . Linear ( num_hidden_1 , num_hidden_2 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_2 ), ) ### Specify CORAL layer self . fc = CoralLayer ( size_in = num_hidden_2 , num_classes = num_classes ) ###--------------------------------------------------------------------### def forward ( self , x ): x = self . my_network ( x ) ##### Use CORAL layer ##### logits = self . fc ( x ) probas = torch . sigmoid ( logits ) ###--------------------------------------------------------------------### return logits , probas torch . manual_seed ( random_seed ) model = MLP ( in_features = 8 , num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters (), lr = learning_rate ) 3 - Using the CORAL loss for model training During training, all you need to do is to 1) convert the integer class labels into the extended binary label format using the levels_from_labelbatch provided via coral_pytorch : levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) 2) Apply the CORAL loss (also provided via coral_pytorch ): loss = coral_loss ( logits , levels ) from coral_pytorch.dataset import levels_from_labelbatch from coral_pytorch.losses import coral_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): ##### Convert class labels for CORAL levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) ###--------------------------------------------------------------------### features = features . to ( DEVICE ) levels = levels . to ( DEVICE ) logits , probas = model ( features ) #### CORAL loss loss = coral_loss ( logits , levels ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Loss: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/020 | Batch 000/007 | Loss: 1.0222 Epoch: 002/020 | Batch 000/007 | Loss: 1.1131 Epoch: 003/020 | Batch 000/007 | Loss: 0.9594 Epoch: 004/020 | Batch 000/007 | Loss: 0.9661 Epoch: 005/020 | Batch 000/007 | Loss: 0.9792 Epoch: 006/020 | Batch 000/007 | Loss: 1.0311 Epoch: 007/020 | Batch 000/007 | Loss: 0.9157 Epoch: 008/020 | Batch 000/007 | Loss: 0.8542 Epoch: 009/020 | Batch 000/007 | Loss: 0.9652 Epoch: 010/020 | Batch 000/007 | Loss: 0.9483 Epoch: 011/020 | Batch 000/007 | Loss: 0.8316 Epoch: 012/020 | Batch 000/007 | Loss: 0.9067 Epoch: 013/020 | Batch 000/007 | Loss: 1.0139 Epoch: 014/020 | Batch 000/007 | Loss: 0.8505 Epoch: 015/020 | Batch 000/007 | Loss: 0.8289 Epoch: 016/020 | Batch 000/007 | Loss: 0.8277 Epoch: 017/020 | Batch 000/007 | Loss: 0.7669 Epoch: 018/020 | Batch 000/007 | Loss: 0.8366 Epoch: 019/020 | Batch 000/007 | Loss: 0.7514 Epoch: 020/020 | Batch 000/007 | Loss: 0.8221 from coral_pytorch.dataset import proba_to_label def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits , probas = model ( features ) predicted_labels = proba_to_label ( probas ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse 4 -- Evaluate model Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the proba_to_label utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import proba_to_label def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits , probas = model ( features ) predicted_labels = proba_to_label ( probas ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 0.27 | 0.34 Mean squared error (train/test): 0.28 | 0.34","title":"CORAL MLP model for tabular data (Cement dataset)"},{"location":"tutorials/pure_pytorch/CORAL_cement/#coral-mlp-for-predicting-cement-strength-cement_strength","text":"This tutorial explains how to train a deep neural network (here: multilayer perceptron) with the CORAL layer and loss function for ordinal regression.","title":"CORAL MLP for predicting cement strength (cement_strength)"},{"location":"tutorials/pure_pytorch/CORAL_cement/#0-obtaining-and-preparing-the-cement_strength-dataset","text":"We will be using the cement_strength dataset from https://github.com/gagolews/ordinal_regression_data/blob/master/cement_strength.csv . First, we are going to download and prepare the and save it as CSV files locally. This is a general procedure that is not specific to CORN. This dataset has 5 ordinal labels (1, 2, 3, 4, and 5). Note that CORN requires labels to be starting at 0, which is why we subtract \"1\" from the label column. import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/gagolews/ordinal_regression_data/master/cement_strength.csv\" ) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 data_labels = data_df [ \"response\" ] data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] print ( 'Number of features:' , data_features . shape [ 1 ]) print ( 'Number of examples:' , data_features . shape [ 0 ]) print ( 'Labels:' , np . unique ( data_labels . values )) Number of features: 8 Number of examples: 998 Labels: [0 1 2 3 4]","title":"0 -- Obtaining and preparing the cement_strength dataset"},{"location":"tutorials/pure_pytorch/CORAL_cement/#split-into-training-and-test-data","text":"from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( data_features . values , data_labels . values , test_size = 0.2 , random_state = 1 , stratify = data_labels . values )","title":"Split into training and test data"},{"location":"tutorials/pure_pytorch/CORAL_cement/#standardize-features","text":"from sklearn.preprocessing import StandardScaler sc = StandardScaler () X_train_std = sc . fit_transform ( X_train ) X_test_std = sc . transform ( X_test )","title":"Standardize features"},{"location":"tutorials/pure_pytorch/CORAL_cement/#1-setting-up-the-dataset-and-dataloader","text":"In this section, we set up the data set and data loaders using PyTorch utilities. This is a general procedure that is not specific to CORAL. import torch ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.05 num_epochs = 20 batch_size = 128 # Architecture NUM_CLASSES = 10 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) Training on cpu from torch.utils.data import Dataset class MyDataset ( Dataset ): def __init__ ( self , feature_array , label_array , dtype = np . float32 ): self . features = feature_array . astype ( np . float32 ) self . labels = label_array def __getitem__ ( self , index ): inputs = self . features [ index ] label = self . labels [ index ] return inputs , label def __len__ ( self ): return self . labels . shape [ 0 ] import torch from torch.utils.data import DataLoader # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = MyDataset ( X_train_std , y_train ) test_dataset = MyDataset ( X_test_std , y_test ) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , shuffle = True , # want to shuffle the dataset num_workers = 0 ) # number processes/CPUs to use test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , shuffle = False , num_workers = 0 ) # Checking the dataset for inputs , labels in train_loader : print ( 'Input batch dimensions:' , inputs . shape ) print ( 'Input label dimensions:' , labels . shape ) break Input batch dimensions: torch.Size([128, 8]) Input label dimensions: torch.Size([128])","title":"1 -- Setting up the dataset and dataloader"},{"location":"tutorials/pure_pytorch/CORAL_cement/#2-equipping-mlp-with-coral-layer","text":"In this section, we are using the CoralLayer implemented in coral_pytorch to outfit a multilayer perceptron for ordinal regression. Note that the CORAL method only requires replacing the last (output) layer, which is typically a fully-connected layer, by the CORAL layer. Also, please use the sigmoid not softmax function (since the CORAL method uses a concept known as extended binary classification as described in the paper). from coral_pytorch.layers import CoralLayer class MLP ( torch . nn . Module ): def __init__ ( self , in_features , num_classes , num_hidden_1 = 300 , num_hidden_2 = 300 ): super () . __init__ () self . my_network = torch . nn . Sequential ( # 1st hidden layer torch . nn . Linear ( in_features , num_hidden_1 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_1 ), # 2nd hidden layer torch . nn . Linear ( num_hidden_1 , num_hidden_2 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_2 ), ) ### Specify CORAL layer self . fc = CoralLayer ( size_in = num_hidden_2 , num_classes = num_classes ) ###--------------------------------------------------------------------### def forward ( self , x ): x = self . my_network ( x ) ##### Use CORAL layer ##### logits = self . fc ( x ) probas = torch . sigmoid ( logits ) ###--------------------------------------------------------------------### return logits , probas torch . manual_seed ( random_seed ) model = MLP ( in_features = 8 , num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters (), lr = learning_rate )","title":"2 - Equipping MLP with CORAL layer"},{"location":"tutorials/pure_pytorch/CORAL_cement/#3-using-the-coral-loss-for-model-training","text":"During training, all you need to do is to 1) convert the integer class labels into the extended binary label format using the levels_from_labelbatch provided via coral_pytorch : levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) 2) Apply the CORAL loss (also provided via coral_pytorch ): loss = coral_loss ( logits , levels ) from coral_pytorch.dataset import levels_from_labelbatch from coral_pytorch.losses import coral_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): ##### Convert class labels for CORAL levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) ###--------------------------------------------------------------------### features = features . to ( DEVICE ) levels = levels . to ( DEVICE ) logits , probas = model ( features ) #### CORAL loss loss = coral_loss ( logits , levels ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Loss: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/020 | Batch 000/007 | Loss: 1.0222 Epoch: 002/020 | Batch 000/007 | Loss: 1.1131 Epoch: 003/020 | Batch 000/007 | Loss: 0.9594 Epoch: 004/020 | Batch 000/007 | Loss: 0.9661 Epoch: 005/020 | Batch 000/007 | Loss: 0.9792 Epoch: 006/020 | Batch 000/007 | Loss: 1.0311 Epoch: 007/020 | Batch 000/007 | Loss: 0.9157 Epoch: 008/020 | Batch 000/007 | Loss: 0.8542 Epoch: 009/020 | Batch 000/007 | Loss: 0.9652 Epoch: 010/020 | Batch 000/007 | Loss: 0.9483 Epoch: 011/020 | Batch 000/007 | Loss: 0.8316 Epoch: 012/020 | Batch 000/007 | Loss: 0.9067 Epoch: 013/020 | Batch 000/007 | Loss: 1.0139 Epoch: 014/020 | Batch 000/007 | Loss: 0.8505 Epoch: 015/020 | Batch 000/007 | Loss: 0.8289 Epoch: 016/020 | Batch 000/007 | Loss: 0.8277 Epoch: 017/020 | Batch 000/007 | Loss: 0.7669 Epoch: 018/020 | Batch 000/007 | Loss: 0.8366 Epoch: 019/020 | Batch 000/007 | Loss: 0.7514 Epoch: 020/020 | Batch 000/007 | Loss: 0.8221 from coral_pytorch.dataset import proba_to_label def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits , probas = model ( features ) predicted_labels = proba_to_label ( probas ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse","title":"3 - Using the CORAL loss for model training"},{"location":"tutorials/pure_pytorch/CORAL_cement/#4-evaluate-model","text":"Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the proba_to_label utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import proba_to_label def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits , probas = model ( features ) predicted_labels = proba_to_label ( probas ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 0.27 | 0.34 Mean squared error (train/test): 0.28 | 0.34","title":"4 -- Evaluate model"},{"location":"tutorials/pure_pytorch/CORAL_mnist/","text":"CORAL CNN for predicting handwritten digits (MNIST) This tutorial explains how to equip a deep neural network with the CORAL layer and loss function for ordinal regression. Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps. 1 -- Setting up the dataset and dataloader In this section, we set up the data set and data loaders. This is a general procedure that is not specific to CORAL. import torch from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.05 num_epochs = 10 batch_size = 128 # Architecture NUM_CLASSES = 10 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) ########################## ### MNIST DATASET ########################## # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = datasets . MNIST ( root = '../data' , train = True , transform = transforms . ToTensor (), download = True ) test_dataset = datasets . MNIST ( root = '../data' , train = False , transform = transforms . ToTensor ()) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , drop_last = True , shuffle = True ) test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , drop_last = True , shuffle = False ) # Checking the dataset for images , labels in train_loader : print ( 'Image batch dimensions:' , images . shape ) print ( 'Image label dimensions:' , labels . shape ) break Training on cpu Image batch dimensions: torch.Size([128, 1, 28, 28]) Image label dimensions: torch.Size([128]) 2 - Equipping CNN with CORAL layer In this section, we are using the CoralLayer implemented in coral_pytorch to outfit a convolutional neural network for ordinal regression. Note that the CORAL method only requires replacing the last (output) layer, which is typically a fully-connected layer, by the CORAL layer. Using the Sequential API, we specify the CORAl layer as self . fc = CoralLayer ( size_in = 294 , num_classes = num_classes ) This is because the convolutional and pooling layers torch . nn . Conv2d ( 1 , 3 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 )), torch . nn . Conv2d ( 3 , 6 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 ))) produce a flattened feature vector of 294 units. Then, when using the CORAL layer in the forward function logits = self . fc ( x ) probas = torch . sigmoid ( logits ) please use the sigmoid not softmax function (since the CORAL method uses a concept known as extended binary classification as described in the paper). from coral_pytorch.layers import CoralLayer class ConvNet ( torch . nn . Module ): def __init__ ( self , num_classes ): super ( ConvNet , self ) . __init__ () self . features = torch . nn . Sequential ( torch . nn . Conv2d ( 1 , 3 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 )), torch . nn . Conv2d ( 3 , 6 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 ))) ### Specify CORAL layer self . fc = CoralLayer ( size_in = 294 , num_classes = num_classes ) ###--------------------------------------------------------------------### def forward ( self , x ): x = self . features ( x ) x = x . view ( x . size ( 0 ), - 1 ) # flatten ##### Use CORAL layer ##### logits = self . fc ( x ) probas = torch . sigmoid ( logits ) ###--------------------------------------------------------------------### return logits , probas torch . manual_seed ( random_seed ) model = ConvNet ( num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters ()) 3 - Using the CORAL loss for model training During training, all you need to do is to 1) convert the integer class labels into the extended binary label format using the levels_from_labelbatch provided via coral_pytorch : levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) 2) Apply the CORAL loss (also provided via coral_pytorch ): loss = coral_loss ( logits , levels ) from coral_pytorch.dataset import levels_from_labelbatch from coral_pytorch.losses import coral_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): ##### Convert class labels for CORAL levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) ###--------------------------------------------------------------------### features = features . to ( DEVICE ) levels = levels . to ( DEVICE ) logits , probas = model ( features ) #### CORAL loss loss = coral_loss ( logits , levels ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Loss: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/010 | Batch 000/468 | Loss: 5.9835 /Users/sebastian/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /tmp/pip-req-build-gqmopi53/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) Epoch: 001/010 | Batch 200/468 | Loss: 4.2022 Epoch: 001/010 | Batch 400/468 | Loss: 3.6785 Epoch: 002/010 | Batch 000/468 | Loss: 3.5811 Epoch: 002/010 | Batch 200/468 | Loss: 3.0574 Epoch: 002/010 | Batch 400/468 | Loss: 3.3966 Epoch: 003/010 | Batch 000/468 | Loss: 2.9386 Epoch: 003/010 | Batch 200/468 | Loss: 2.9354 Epoch: 003/010 | Batch 400/468 | Loss: 3.0238 Epoch: 004/010 | Batch 000/468 | Loss: 2.7420 Epoch: 004/010 | Batch 200/468 | Loss: 2.5817 Epoch: 004/010 | Batch 400/468 | Loss: 2.5847 Epoch: 005/010 | Batch 000/468 | Loss: 2.6086 Epoch: 005/010 | Batch 200/468 | Loss: 2.4370 Epoch: 005/010 | Batch 400/468 | Loss: 2.4903 Epoch: 006/010 | Batch 000/468 | Loss: 2.3428 Epoch: 006/010 | Batch 200/468 | Loss: 2.4846 Epoch: 006/010 | Batch 400/468 | Loss: 2.3392 Epoch: 007/010 | Batch 000/468 | Loss: 2.4983 Epoch: 007/010 | Batch 200/468 | Loss: 2.4828 Epoch: 007/010 | Batch 400/468 | Loss: 2.2048 Epoch: 008/010 | Batch 000/468 | Loss: 2.3902 Epoch: 008/010 | Batch 200/468 | Loss: 2.2189 Epoch: 008/010 | Batch 400/468 | Loss: 2.1895 Epoch: 009/010 | Batch 000/468 | Loss: 2.2189 Epoch: 009/010 | Batch 200/468 | Loss: 2.1120 Epoch: 009/010 | Batch 400/468 | Loss: 2.1923 Epoch: 010/010 | Batch 000/468 | Loss: 2.1188 Epoch: 010/010 | Batch 200/468 | Loss: 2.0416 Epoch: 010/010 | Batch 400/468 | Loss: 1.9729 4 -- Evaluate model Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the proba_to_label utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import proba_to_label def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits , probas = model ( features ) predicted_labels = proba_to_label ( probas ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 3.45 | 3.34 Mean squared error (train/test): 18.00 | 16.91 Note that MNIST is not an ordinal dataset (there is no order between the image categories), so computing the MAE or MSE doesn't really make sense but we use it anyways for demonstration purposes.","title":"CORAL CNN model for image data (MNIST dataset)"},{"location":"tutorials/pure_pytorch/CORAL_mnist/#coral-cnn-for-predicting-handwritten-digits-mnist","text":"This tutorial explains how to equip a deep neural network with the CORAL layer and loss function for ordinal regression. Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps.","title":"CORAL CNN for predicting handwritten digits (MNIST)"},{"location":"tutorials/pure_pytorch/CORAL_mnist/#1-setting-up-the-dataset-and-dataloader","text":"In this section, we set up the data set and data loaders. This is a general procedure that is not specific to CORAL. import torch from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.05 num_epochs = 10 batch_size = 128 # Architecture NUM_CLASSES = 10 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) ########################## ### MNIST DATASET ########################## # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = datasets . MNIST ( root = '../data' , train = True , transform = transforms . ToTensor (), download = True ) test_dataset = datasets . MNIST ( root = '../data' , train = False , transform = transforms . ToTensor ()) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , drop_last = True , shuffle = True ) test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , drop_last = True , shuffle = False ) # Checking the dataset for images , labels in train_loader : print ( 'Image batch dimensions:' , images . shape ) print ( 'Image label dimensions:' , labels . shape ) break Training on cpu Image batch dimensions: torch.Size([128, 1, 28, 28]) Image label dimensions: torch.Size([128])","title":"1 -- Setting up the dataset and dataloader"},{"location":"tutorials/pure_pytorch/CORAL_mnist/#2-equipping-cnn-with-coral-layer","text":"In this section, we are using the CoralLayer implemented in coral_pytorch to outfit a convolutional neural network for ordinal regression. Note that the CORAL method only requires replacing the last (output) layer, which is typically a fully-connected layer, by the CORAL layer. Using the Sequential API, we specify the CORAl layer as self . fc = CoralLayer ( size_in = 294 , num_classes = num_classes ) This is because the convolutional and pooling layers torch . nn . Conv2d ( 1 , 3 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 )), torch . nn . Conv2d ( 3 , 6 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 ))) produce a flattened feature vector of 294 units. Then, when using the CORAL layer in the forward function logits = self . fc ( x ) probas = torch . sigmoid ( logits ) please use the sigmoid not softmax function (since the CORAL method uses a concept known as extended binary classification as described in the paper). from coral_pytorch.layers import CoralLayer class ConvNet ( torch . nn . Module ): def __init__ ( self , num_classes ): super ( ConvNet , self ) . __init__ () self . features = torch . nn . Sequential ( torch . nn . Conv2d ( 1 , 3 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 )), torch . nn . Conv2d ( 3 , 6 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 ))) ### Specify CORAL layer self . fc = CoralLayer ( size_in = 294 , num_classes = num_classes ) ###--------------------------------------------------------------------### def forward ( self , x ): x = self . features ( x ) x = x . view ( x . size ( 0 ), - 1 ) # flatten ##### Use CORAL layer ##### logits = self . fc ( x ) probas = torch . sigmoid ( logits ) ###--------------------------------------------------------------------### return logits , probas torch . manual_seed ( random_seed ) model = ConvNet ( num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters ())","title":"2 - Equipping CNN with CORAL layer"},{"location":"tutorials/pure_pytorch/CORAL_mnist/#3-using-the-coral-loss-for-model-training","text":"During training, all you need to do is to 1) convert the integer class labels into the extended binary label format using the levels_from_labelbatch provided via coral_pytorch : levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) 2) Apply the CORAL loss (also provided via coral_pytorch ): loss = coral_loss ( logits , levels ) from coral_pytorch.dataset import levels_from_labelbatch from coral_pytorch.losses import coral_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): ##### Convert class labels for CORAL levels = levels_from_labelbatch ( class_labels , num_classes = NUM_CLASSES ) ###--------------------------------------------------------------------### features = features . to ( DEVICE ) levels = levels . to ( DEVICE ) logits , probas = model ( features ) #### CORAL loss loss = coral_loss ( logits , levels ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Loss: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/010 | Batch 000/468 | Loss: 5.9835 /Users/sebastian/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /tmp/pip-req-build-gqmopi53/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) Epoch: 001/010 | Batch 200/468 | Loss: 4.2022 Epoch: 001/010 | Batch 400/468 | Loss: 3.6785 Epoch: 002/010 | Batch 000/468 | Loss: 3.5811 Epoch: 002/010 | Batch 200/468 | Loss: 3.0574 Epoch: 002/010 | Batch 400/468 | Loss: 3.3966 Epoch: 003/010 | Batch 000/468 | Loss: 2.9386 Epoch: 003/010 | Batch 200/468 | Loss: 2.9354 Epoch: 003/010 | Batch 400/468 | Loss: 3.0238 Epoch: 004/010 | Batch 000/468 | Loss: 2.7420 Epoch: 004/010 | Batch 200/468 | Loss: 2.5817 Epoch: 004/010 | Batch 400/468 | Loss: 2.5847 Epoch: 005/010 | Batch 000/468 | Loss: 2.6086 Epoch: 005/010 | Batch 200/468 | Loss: 2.4370 Epoch: 005/010 | Batch 400/468 | Loss: 2.4903 Epoch: 006/010 | Batch 000/468 | Loss: 2.3428 Epoch: 006/010 | Batch 200/468 | Loss: 2.4846 Epoch: 006/010 | Batch 400/468 | Loss: 2.3392 Epoch: 007/010 | Batch 000/468 | Loss: 2.4983 Epoch: 007/010 | Batch 200/468 | Loss: 2.4828 Epoch: 007/010 | Batch 400/468 | Loss: 2.2048 Epoch: 008/010 | Batch 000/468 | Loss: 2.3902 Epoch: 008/010 | Batch 200/468 | Loss: 2.2189 Epoch: 008/010 | Batch 400/468 | Loss: 2.1895 Epoch: 009/010 | Batch 000/468 | Loss: 2.2189 Epoch: 009/010 | Batch 200/468 | Loss: 2.1120 Epoch: 009/010 | Batch 400/468 | Loss: 2.1923 Epoch: 010/010 | Batch 000/468 | Loss: 2.1188 Epoch: 010/010 | Batch 200/468 | Loss: 2.0416 Epoch: 010/010 | Batch 400/468 | Loss: 1.9729","title":"3 - Using the CORAL loss for model training"},{"location":"tutorials/pure_pytorch/CORAL_mnist/#4-evaluate-model","text":"Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the proba_to_label utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import proba_to_label def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits , probas = model ( features ) predicted_labels = proba_to_label ( probas ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 3.45 | 3.34 Mean squared error (train/test): 18.00 | 16.91 Note that MNIST is not an ordinal dataset (there is no order between the image categories), so computing the MAE or MSE doesn't really make sense but we use it anyways for demonstration purposes.","title":"4 -- Evaluate model"},{"location":"tutorials/pure_pytorch/CORN_cement/","text":"CORN MLP for predicting cement strength (cement_strength) This tutorial explains how to train a deep neural network (here: multilayer perceptron) with the CORN loss function for ordinal regression. 0 -- Obtaining and preparing the cement_strength dataset We will be using the cement_strength dataset from https://github.com/gagolews/ordinal_regression_data/blob/master/cement_strength.csv . First, we are going to download and prepare the and save it as CSV files locally. This is a general procedure that is not specific to CORN. This dataset has 5 ordinal labels (1, 2, 3, 4, and 5). Note that CORN requires labels to be starting at 0, which is why we subtract \"1\" from the label column. import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/gagolews/ordinal_regression_data/master/cement_strength.csv\" ) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 data_labels = data_df [ \"response\" ] data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] print ( 'Number of features:' , data_features . shape [ 1 ]) print ( 'Number of examples:' , data_features . shape [ 0 ]) print ( 'Labels:' , np . unique ( data_labels . values )) Number of features: 8 Number of examples: 998 Labels: [0 1 2 3 4] Split into training and test data from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( data_features . values , data_labels . values , test_size = 0.2 , random_state = 1 , stratify = data_labels . values ) Standardize features from sklearn.preprocessing import StandardScaler sc = StandardScaler () X_train_std = sc . fit_transform ( X_train ) X_test_std = sc . transform ( X_test ) 1 -- Setting up the dataset and dataloader In this section, we set up the data set and data loaders. This is a general procedure that is not specific to CORN. import torch ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.001 num_epochs = 20 batch_size = 128 # Architecture NUM_CLASSES = 5 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) Training on cpu from torch.utils.data import Dataset class MyDataset ( Dataset ): def __init__ ( self , feature_array , label_array , dtype = np . float32 ): self . features = feature_array . astype ( np . float32 ) self . labels = label_array def __getitem__ ( self , index ): inputs = self . features [ index ] label = self . labels [ index ] return inputs , label def __len__ ( self ): return self . labels . shape [ 0 ] import torch from torch.utils.data import DataLoader # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = MyDataset ( X_train_std , y_train ) test_dataset = MyDataset ( X_test_std , y_test ) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , shuffle = True , # want to shuffle the dataset num_workers = 0 ) # number processes/CPUs to use test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , shuffle = False , num_workers = 0 ) # Checking the dataset for inputs , labels in train_loader : print ( 'Input batch dimensions:' , inputs . shape ) print ( 'Input label dimensions:' , labels . shape ) break Input batch dimensions: torch.Size([128, 8]) Input label dimensions: torch.Size([128]) 2 - Equipping MLP with a CORN layer In this section, we are implementing a simple MLP for ordinal regression with CORN. Note that the only specific modification required is setting the number of output of the last layer (a fully connected layer) to the number of classes - 1 (these correspond to the binary tasks used in the extended binary classification as described in the paper). class MLP ( torch . nn . Module ): def __init__ ( self , in_features , num_classes , num_hidden_1 = 300 , num_hidden_2 = 300 ): super () . __init__ () self . my_network = torch . nn . Sequential ( # 1st hidden layer torch . nn . Linear ( in_features , num_hidden_1 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_1 ), # 2nd hidden layer torch . nn . Linear ( num_hidden_1 , num_hidden_2 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_2 ), ### Specify CORN layer torch . nn . Linear ( num_hidden_2 , ( num_classes - 1 )) ###--------------------------------------------------------------------### ) def forward ( self , x ): logits = self . my_network ( x ) return logits torch . manual_seed ( random_seed ) model = MLP ( in_features = 8 , num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters (), lr = learning_rate ) 3 - Using the CORN loss for model training During training, all you need to do is to use the corn_loss provided via coral_pytorch . The loss function will take care of the conditional training set processing and modeling the conditional probabilities used in the chain rule (aka general product rule). from coral_pytorch.losses import corn_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): features = features . to ( DEVICE ) logits = model ( features ) #### CORN loss loss = corn_loss ( logits , class_labels , NUM_CLASSES ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Cost: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/020 | Batch 000/007 | Cost: 42.3084 Epoch: 002/020 | Batch 000/007 | Cost: 33.4198 Epoch: 003/020 | Batch 000/007 | Cost: 34.3413 Epoch: 004/020 | Batch 000/007 | Cost: 27.4008 Epoch: 005/020 | Batch 000/007 | Cost: 29.5580 Epoch: 006/020 | Batch 000/007 | Cost: 28.3949 Epoch: 007/020 | Batch 000/007 | Cost: 26.0713 Epoch: 008/020 | Batch 000/007 | Cost: 24.0429 Epoch: 009/020 | Batch 000/007 | Cost: 22.1783 Epoch: 010/020 | Batch 000/007 | Cost: 25.2757 Epoch: 011/020 | Batch 000/007 | Cost: 22.2279 Epoch: 012/020 | Batch 000/007 | Cost: 23.1534 Epoch: 013/020 | Batch 000/007 | Cost: 18.5136 Epoch: 014/020 | Batch 000/007 | Cost: 23.8390 Epoch: 015/020 | Batch 000/007 | Cost: 18.9016 Epoch: 016/020 | Batch 000/007 | Cost: 18.0890 Epoch: 017/020 | Batch 000/007 | Cost: 13.8526 Epoch: 018/020 | Batch 000/007 | Cost: 17.3017 Epoch: 019/020 | Batch 000/007 | Cost: 15.3039 Epoch: 020/020 | Batch 000/007 | Cost: 16.0646 4 -- Evaluate model Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the corn_label_from_logits utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import corn_label_from_logits def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits = model ( features ) predicted_labels = corn_label_from_logits ( logits ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 0.27 | 0.38 Mean squared error (train/test): 0.30 | 0.43 Note that MNIST is not an ordinal dataset (there is no order between the image categories), so computing the MAE or MSE doesn't really make sense but we use it anyways for demonstration purposes. 5 -- Rank probabilities from logits To obtain the rank probabilities from the logits, you can use the sigmoid function to get the conditional probabilities for each task and then compute the task probabilities via the chain rule for probabilities. Note that this is also done internally by the corn_label_from_logits we used above. logits = model ( features ) with torch . no_grad (): probas = torch . sigmoid ( logits ) probas = torch . cumprod ( probas , dim = 1 ) print ( probas ) tensor([[9.7585e-01, 9.7536e-01, 9.6610e-01, 2.2675e-01], [9.4921e-01, 1.7135e-01, 9.7073e-03, 3.4552e-04], [2.4214e-02, 4.6617e-04, 3.3125e-05, 2.7729e-05], [9.8303e-01, 5.6925e-01, 3.2523e-01, 5.3245e-02], [9.5153e-01, 5.7437e-01, 1.4063e-01, 1.6096e-02], [1.8260e-02, 7.7530e-06, 5.1410e-06, 5.1152e-06], [9.7835e-01, 9.5596e-01, 3.6877e-01, 1.9158e-02], [9.8692e-01, 9.4746e-01, 3.2161e-01, 4.4179e-02], [3.5250e-01, 6.7358e-03, 2.6506e-03, 2.0687e-03], [9.2053e-01, 3.5487e-01, 1.0667e-01, 5.3238e-02], [1.2923e-01, 2.7282e-03, 3.3910e-04, 2.3258e-04], [9.7515e-01, 8.6582e-01, 2.0421e-01, 4.9532e-02], [9.9591e-01, 4.9053e-01, 3.7695e-02, 1.0938e-02], [1.8391e-01, 5.2724e-03, 5.6778e-04, 3.7333e-04], [8.8100e-01, 7.3442e-01, 5.6249e-01, 1.2397e-01], [6.7335e-01, 5.0340e-02, 8.1046e-03, 5.6927e-03], [9.0837e-01, 2.8030e-01, 3.3884e-02, 7.7040e-03], [8.9811e-01, 2.3693e-01, 2.2545e-02, 3.1750e-03], [9.5224e-01, 7.0664e-01, 1.0633e-01, 5.8928e-02], [7.1353e-01, 1.1418e-02, 4.1087e-04, 2.9408e-04], [4.8610e-04, 3.1541e-05, 2.3382e-05, 2.1088e-05], [9.6261e-01, 7.2110e-01, 7.1777e-01, 1.7590e-01], [9.7763e-01, 2.6866e-01, 4.9495e-02, 2.0072e-02], [9.7093e-01, 9.4531e-01, 9.1623e-02, 4.7309e-02], [8.3720e-01, 7.3658e-02, 1.1421e-02, 7.7481e-03], [9.2363e-01, 9.0403e-01, 5.8055e-01, 7.3952e-03], [9.7614e-01, 9.7225e-01, 6.8393e-01, 2.5626e-02], [9.7249e-01, 4.3916e-01, 2.6588e-01, 1.7958e-01], [9.7547e-01, 9.5796e-01, 8.4703e-01, 7.7577e-01], [9.5975e-01, 9.5148e-01, 4.9699e-01, 6.1305e-02]])","title":"CORN MLP model for tabular data (Cement dataset)"},{"location":"tutorials/pure_pytorch/CORN_cement/#corn-mlp-for-predicting-cement-strength-cement_strength","text":"This tutorial explains how to train a deep neural network (here: multilayer perceptron) with the CORN loss function for ordinal regression.","title":"CORN MLP for predicting cement strength (cement_strength)"},{"location":"tutorials/pure_pytorch/CORN_cement/#0-obtaining-and-preparing-the-cement_strength-dataset","text":"We will be using the cement_strength dataset from https://github.com/gagolews/ordinal_regression_data/blob/master/cement_strength.csv . First, we are going to download and prepare the and save it as CSV files locally. This is a general procedure that is not specific to CORN. This dataset has 5 ordinal labels (1, 2, 3, 4, and 5). Note that CORN requires labels to be starting at 0, which is why we subtract \"1\" from the label column. import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/gagolews/ordinal_regression_data/master/cement_strength.csv\" ) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 data_labels = data_df [ \"response\" ] data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] print ( 'Number of features:' , data_features . shape [ 1 ]) print ( 'Number of examples:' , data_features . shape [ 0 ]) print ( 'Labels:' , np . unique ( data_labels . values )) Number of features: 8 Number of examples: 998 Labels: [0 1 2 3 4]","title":"0 -- Obtaining and preparing the cement_strength dataset"},{"location":"tutorials/pure_pytorch/CORN_cement/#split-into-training-and-test-data","text":"from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( data_features . values , data_labels . values , test_size = 0.2 , random_state = 1 , stratify = data_labels . values )","title":"Split into training and test data"},{"location":"tutorials/pure_pytorch/CORN_cement/#standardize-features","text":"from sklearn.preprocessing import StandardScaler sc = StandardScaler () X_train_std = sc . fit_transform ( X_train ) X_test_std = sc . transform ( X_test )","title":"Standardize features"},{"location":"tutorials/pure_pytorch/CORN_cement/#1-setting-up-the-dataset-and-dataloader","text":"In this section, we set up the data set and data loaders. This is a general procedure that is not specific to CORN. import torch ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.001 num_epochs = 20 batch_size = 128 # Architecture NUM_CLASSES = 5 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) Training on cpu from torch.utils.data import Dataset class MyDataset ( Dataset ): def __init__ ( self , feature_array , label_array , dtype = np . float32 ): self . features = feature_array . astype ( np . float32 ) self . labels = label_array def __getitem__ ( self , index ): inputs = self . features [ index ] label = self . labels [ index ] return inputs , label def __len__ ( self ): return self . labels . shape [ 0 ] import torch from torch.utils.data import DataLoader # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = MyDataset ( X_train_std , y_train ) test_dataset = MyDataset ( X_test_std , y_test ) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , shuffle = True , # want to shuffle the dataset num_workers = 0 ) # number processes/CPUs to use test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , shuffle = False , num_workers = 0 ) # Checking the dataset for inputs , labels in train_loader : print ( 'Input batch dimensions:' , inputs . shape ) print ( 'Input label dimensions:' , labels . shape ) break Input batch dimensions: torch.Size([128, 8]) Input label dimensions: torch.Size([128])","title":"1 -- Setting up the dataset and dataloader"},{"location":"tutorials/pure_pytorch/CORN_cement/#2-equipping-mlp-with-a-corn-layer","text":"In this section, we are implementing a simple MLP for ordinal regression with CORN. Note that the only specific modification required is setting the number of output of the last layer (a fully connected layer) to the number of classes - 1 (these correspond to the binary tasks used in the extended binary classification as described in the paper). class MLP ( torch . nn . Module ): def __init__ ( self , in_features , num_classes , num_hidden_1 = 300 , num_hidden_2 = 300 ): super () . __init__ () self . my_network = torch . nn . Sequential ( # 1st hidden layer torch . nn . Linear ( in_features , num_hidden_1 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_1 ), # 2nd hidden layer torch . nn . Linear ( num_hidden_1 , num_hidden_2 , bias = False ), torch . nn . LeakyReLU (), torch . nn . Dropout ( 0.2 ), torch . nn . BatchNorm1d ( num_hidden_2 ), ### Specify CORN layer torch . nn . Linear ( num_hidden_2 , ( num_classes - 1 )) ###--------------------------------------------------------------------### ) def forward ( self , x ): logits = self . my_network ( x ) return logits torch . manual_seed ( random_seed ) model = MLP ( in_features = 8 , num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters (), lr = learning_rate )","title":"2 - Equipping MLP with a CORN layer"},{"location":"tutorials/pure_pytorch/CORN_cement/#3-using-the-corn-loss-for-model-training","text":"During training, all you need to do is to use the corn_loss provided via coral_pytorch . The loss function will take care of the conditional training set processing and modeling the conditional probabilities used in the chain rule (aka general product rule). from coral_pytorch.losses import corn_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): features = features . to ( DEVICE ) logits = model ( features ) #### CORN loss loss = corn_loss ( logits , class_labels , NUM_CLASSES ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Cost: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/020 | Batch 000/007 | Cost: 42.3084 Epoch: 002/020 | Batch 000/007 | Cost: 33.4198 Epoch: 003/020 | Batch 000/007 | Cost: 34.3413 Epoch: 004/020 | Batch 000/007 | Cost: 27.4008 Epoch: 005/020 | Batch 000/007 | Cost: 29.5580 Epoch: 006/020 | Batch 000/007 | Cost: 28.3949 Epoch: 007/020 | Batch 000/007 | Cost: 26.0713 Epoch: 008/020 | Batch 000/007 | Cost: 24.0429 Epoch: 009/020 | Batch 000/007 | Cost: 22.1783 Epoch: 010/020 | Batch 000/007 | Cost: 25.2757 Epoch: 011/020 | Batch 000/007 | Cost: 22.2279 Epoch: 012/020 | Batch 000/007 | Cost: 23.1534 Epoch: 013/020 | Batch 000/007 | Cost: 18.5136 Epoch: 014/020 | Batch 000/007 | Cost: 23.8390 Epoch: 015/020 | Batch 000/007 | Cost: 18.9016 Epoch: 016/020 | Batch 000/007 | Cost: 18.0890 Epoch: 017/020 | Batch 000/007 | Cost: 13.8526 Epoch: 018/020 | Batch 000/007 | Cost: 17.3017 Epoch: 019/020 | Batch 000/007 | Cost: 15.3039 Epoch: 020/020 | Batch 000/007 | Cost: 16.0646","title":"3 - Using the CORN loss for model training"},{"location":"tutorials/pure_pytorch/CORN_cement/#4-evaluate-model","text":"Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the corn_label_from_logits utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import corn_label_from_logits def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits = model ( features ) predicted_labels = corn_label_from_logits ( logits ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 0.27 | 0.38 Mean squared error (train/test): 0.30 | 0.43 Note that MNIST is not an ordinal dataset (there is no order between the image categories), so computing the MAE or MSE doesn't really make sense but we use it anyways for demonstration purposes.","title":"4 -- Evaluate model"},{"location":"tutorials/pure_pytorch/CORN_cement/#5-rank-probabilities-from-logits","text":"To obtain the rank probabilities from the logits, you can use the sigmoid function to get the conditional probabilities for each task and then compute the task probabilities via the chain rule for probabilities. Note that this is also done internally by the corn_label_from_logits we used above. logits = model ( features ) with torch . no_grad (): probas = torch . sigmoid ( logits ) probas = torch . cumprod ( probas , dim = 1 ) print ( probas ) tensor([[9.7585e-01, 9.7536e-01, 9.6610e-01, 2.2675e-01], [9.4921e-01, 1.7135e-01, 9.7073e-03, 3.4552e-04], [2.4214e-02, 4.6617e-04, 3.3125e-05, 2.7729e-05], [9.8303e-01, 5.6925e-01, 3.2523e-01, 5.3245e-02], [9.5153e-01, 5.7437e-01, 1.4063e-01, 1.6096e-02], [1.8260e-02, 7.7530e-06, 5.1410e-06, 5.1152e-06], [9.7835e-01, 9.5596e-01, 3.6877e-01, 1.9158e-02], [9.8692e-01, 9.4746e-01, 3.2161e-01, 4.4179e-02], [3.5250e-01, 6.7358e-03, 2.6506e-03, 2.0687e-03], [9.2053e-01, 3.5487e-01, 1.0667e-01, 5.3238e-02], [1.2923e-01, 2.7282e-03, 3.3910e-04, 2.3258e-04], [9.7515e-01, 8.6582e-01, 2.0421e-01, 4.9532e-02], [9.9591e-01, 4.9053e-01, 3.7695e-02, 1.0938e-02], [1.8391e-01, 5.2724e-03, 5.6778e-04, 3.7333e-04], [8.8100e-01, 7.3442e-01, 5.6249e-01, 1.2397e-01], [6.7335e-01, 5.0340e-02, 8.1046e-03, 5.6927e-03], [9.0837e-01, 2.8030e-01, 3.3884e-02, 7.7040e-03], [8.9811e-01, 2.3693e-01, 2.2545e-02, 3.1750e-03], [9.5224e-01, 7.0664e-01, 1.0633e-01, 5.8928e-02], [7.1353e-01, 1.1418e-02, 4.1087e-04, 2.9408e-04], [4.8610e-04, 3.1541e-05, 2.3382e-05, 2.1088e-05], [9.6261e-01, 7.2110e-01, 7.1777e-01, 1.7590e-01], [9.7763e-01, 2.6866e-01, 4.9495e-02, 2.0072e-02], [9.7093e-01, 9.4531e-01, 9.1623e-02, 4.7309e-02], [8.3720e-01, 7.3658e-02, 1.1421e-02, 7.7481e-03], [9.2363e-01, 9.0403e-01, 5.8055e-01, 7.3952e-03], [9.7614e-01, 9.7225e-01, 6.8393e-01, 2.5626e-02], [9.7249e-01, 4.3916e-01, 2.6588e-01, 1.7958e-01], [9.7547e-01, 9.5796e-01, 8.4703e-01, 7.7577e-01], [9.5975e-01, 9.5148e-01, 4.9699e-01, 6.1305e-02]])","title":"5 -- Rank probabilities from logits"},{"location":"tutorials/pure_pytorch/CORN_mnist/","text":"CORN CNN for predicting handwritten digits (MNIST) This tutorial explains how to train a deep neural network with the CORN loss function for ordinal regression. Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps. 1 -- Setting up the dataset and dataloader In this section, we set up the data set and data loaders. This is a general procedure that is not specific to CORN. import torch from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.05 num_epochs = 10 batch_size = 128 # Architecture NUM_CLASSES = 10 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) ########################## ### MNIST DATASET ########################## # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = datasets . MNIST ( root = '../data' , train = True , transform = transforms . ToTensor (), download = True ) test_dataset = datasets . MNIST ( root = '../data' , train = False , transform = transforms . ToTensor ()) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , drop_last = True , shuffle = True ) test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , drop_last = True , shuffle = False ) # Checking the dataset for images , labels in train_loader : print ( 'Image batch dimensions:' , images . shape ) print ( 'Image label dimensions:' , labels . shape ) break Training on cpu Image batch dimensions: torch.Size([128, 1, 28, 28]) Image label dimensions: torch.Size([128]) 2 - Equipping CNN with a CORN layer In this section, we are implementing a simple CNN for ordinal regression with CORN. Note that the only specific modification required is setting the number of output of the last layer (a fully connected layer) to the number of classes - 1 (these correspond to the binary tasks used in the extended binary classification as described in the paper). class ConvNet ( torch . nn . Module ): def __init__ ( self , num_classes ): super ( ConvNet , self ) . __init__ () self . features = torch . nn . Sequential ( torch . nn . Conv2d ( 1 , 3 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 )), torch . nn . Conv2d ( 3 , 6 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 ))) ### Specify CORN layer self . output_layer = torch . nn . Linear ( in_features = 294 , out_features = num_classes - 1 ) ###--------------------------------------------------------------------### def forward ( self , x ): x = self . features ( x ) x = x . view ( x . size ( 0 ), - 1 ) # flatten ##### Use CORN layer ##### logits = self . output_layer ( x ) ###--------------------------------------------------------------------### return logits torch . manual_seed ( random_seed ) model = ConvNet ( num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters ()) 3 - Using the CORN loss for model training During training, all you need to do is to use the corn_loss provided via coral_pytorch . The loss function will take care of the conditional training set processing and modeling the conditional probabilities used in the chain rule (aka general product rule). from coral_pytorch.losses import corn_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): features = features . to ( DEVICE ) logits = model ( features ) #### CORN loss loss = corn_loss ( logits , class_labels , NUM_CLASSES ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Cost: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/010 | Batch 000/468 | Cost: 50.5479 /Users/sebastian/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /tmp/pip-req-build-gqmopi53/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) Epoch: 001/010 | Batch 200/468 | Cost: 9.7984 Epoch: 001/010 | Batch 400/468 | Cost: 5.6653 Epoch: 002/010 | Batch 000/468 | Cost: 6.6017 Epoch: 002/010 | Batch 200/468 | Cost: 4.7958 Epoch: 002/010 | Batch 400/468 | Cost: 4.7984 Epoch: 003/010 | Batch 000/468 | Cost: 3.9449 Epoch: 003/010 | Batch 200/468 | Cost: 3.6385 Epoch: 003/010 | Batch 400/468 | Cost: 2.8829 Epoch: 004/010 | Batch 000/468 | Cost: 2.0917 Epoch: 004/010 | Batch 200/468 | Cost: 2.8083 Epoch: 004/010 | Batch 400/468 | Cost: 2.6029 Epoch: 005/010 | Batch 000/468 | Cost: 3.0181 Epoch: 005/010 | Batch 200/468 | Cost: 2.5722 Epoch: 005/010 | Batch 400/468 | Cost: 1.0547 Epoch: 006/010 | Batch 000/468 | Cost: 1.8847 Epoch: 006/010 | Batch 200/468 | Cost: 1.8378 Epoch: 006/010 | Batch 400/468 | Cost: 2.7391 Epoch: 007/010 | Batch 000/468 | Cost: 4.4030 Epoch: 007/010 | Batch 200/468 | Cost: 1.7034 Epoch: 007/010 | Batch 400/468 | Cost: 1.4372 Epoch: 008/010 | Batch 000/468 | Cost: 2.5416 Epoch: 008/010 | Batch 200/468 | Cost: 2.0749 Epoch: 008/010 | Batch 400/468 | Cost: 2.3005 Epoch: 009/010 | Batch 000/468 | Cost: 1.7815 Epoch: 009/010 | Batch 200/468 | Cost: 3.4259 Epoch: 009/010 | Batch 400/468 | Cost: 1.8984 Epoch: 010/010 | Batch 000/468 | Cost: 1.4577 Epoch: 010/010 | Batch 200/468 | Cost: 2.1422 Epoch: 010/010 | Batch 400/468 | Cost: 2.0863 4 -- Evaluate model Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the corn_label_from_logits utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import corn_label_from_logits def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits = model ( features ) predicted_labels = corn_label_from_logits ( logits ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 3.37 | 3.35 Mean squared error (train/test): 17.28 | 16.98 Note that MNIST is not an ordinal dataset (there is no order between the image categories), so computing the MAE or MSE doesn't really make sense but we use it anyways for demonstration purposes. 5 -- Rank probabilities from logits To obtain the rank probabilities from the logits, you can use the sigmoid function to get the conditional probabilities for each task and then compute the task probabilities via the chain rule for probabilities. Note that this is also done internally by the corn_label_from_logits we used above. logits = model ( features ) with torch . no_grad (): probas = torch . sigmoid ( logits ) probas = torch . cumprod ( probas , dim = 1 ) print ( probas ) tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, ..., 9.9987e-01, 9.9947e-01, 2.6341e-08], [1.0000e+00, 1.0000e+00, 9.9275e-01, ..., 9.8443e-01, 9.8443e-01, 9.2676e-08], [9.1224e-01, 9.1224e-01, 9.1224e-01, ..., 8.5583e-01, 8.5442e-01, 1.7306e-03], ..., [9.9801e-01, 9.9800e-01, 9.9800e-01, ..., 9.8942e-01, 9.8922e-01, 4.1247e-03], [9.9977e-01, 9.9977e-01, 9.9977e-01, ..., 1.5548e-02, 1.5543e-02, 2.8278e-04], [7.4167e-07, 7.4167e-07, 7.2308e-07, ..., 7.4769e-08, 7.4750e-08, 5.6809e-13]])","title":"CORN CNN model for image data (MNIST dataset)"},{"location":"tutorials/pure_pytorch/CORN_mnist/#corn-cnn-for-predicting-handwritten-digits-mnist","text":"This tutorial explains how to train a deep neural network with the CORN loss function for ordinal regression. Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps.","title":"CORN CNN for predicting handwritten digits (MNIST)"},{"location":"tutorials/pure_pytorch/CORN_mnist/#1-setting-up-the-dataset-and-dataloader","text":"In this section, we set up the data set and data loaders. This is a general procedure that is not specific to CORN. import torch from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader ########################## ### SETTINGS ########################## # Hyperparameters random_seed = 1 learning_rate = 0.05 num_epochs = 10 batch_size = 128 # Architecture NUM_CLASSES = 10 # Other DEVICE = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) print ( 'Training on' , DEVICE ) ########################## ### MNIST DATASET ########################## # Note transforms.ToTensor() scales input images # to 0-1 range train_dataset = datasets . MNIST ( root = '../data' , train = True , transform = transforms . ToTensor (), download = True ) test_dataset = datasets . MNIST ( root = '../data' , train = False , transform = transforms . ToTensor ()) train_loader = DataLoader ( dataset = train_dataset , batch_size = batch_size , drop_last = True , shuffle = True ) test_loader = DataLoader ( dataset = test_dataset , batch_size = batch_size , drop_last = True , shuffle = False ) # Checking the dataset for images , labels in train_loader : print ( 'Image batch dimensions:' , images . shape ) print ( 'Image label dimensions:' , labels . shape ) break Training on cpu Image batch dimensions: torch.Size([128, 1, 28, 28]) Image label dimensions: torch.Size([128])","title":"1 -- Setting up the dataset and dataloader"},{"location":"tutorials/pure_pytorch/CORN_mnist/#2-equipping-cnn-with-a-corn-layer","text":"In this section, we are implementing a simple CNN for ordinal regression with CORN. Note that the only specific modification required is setting the number of output of the last layer (a fully connected layer) to the number of classes - 1 (these correspond to the binary tasks used in the extended binary classification as described in the paper). class ConvNet ( torch . nn . Module ): def __init__ ( self , num_classes ): super ( ConvNet , self ) . __init__ () self . features = torch . nn . Sequential ( torch . nn . Conv2d ( 1 , 3 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 )), torch . nn . Conv2d ( 3 , 6 , ( 3 , 3 ), ( 1 , 1 ), 1 ), torch . nn . MaxPool2d (( 2 , 2 ), ( 2 , 2 ))) ### Specify CORN layer self . output_layer = torch . nn . Linear ( in_features = 294 , out_features = num_classes - 1 ) ###--------------------------------------------------------------------### def forward ( self , x ): x = self . features ( x ) x = x . view ( x . size ( 0 ), - 1 ) # flatten ##### Use CORN layer ##### logits = self . output_layer ( x ) ###--------------------------------------------------------------------### return logits torch . manual_seed ( random_seed ) model = ConvNet ( num_classes = NUM_CLASSES ) model . to ( DEVICE ) optimizer = torch . optim . Adam ( model . parameters ())","title":"2 - Equipping CNN with a CORN layer"},{"location":"tutorials/pure_pytorch/CORN_mnist/#3-using-the-corn-loss-for-model-training","text":"During training, all you need to do is to use the corn_loss provided via coral_pytorch . The loss function will take care of the conditional training set processing and modeling the conditional probabilities used in the chain rule (aka general product rule). from coral_pytorch.losses import corn_loss for epoch in range ( num_epochs ): model = model . train () for batch_idx , ( features , class_labels ) in enumerate ( train_loader ): features = features . to ( DEVICE ) logits = model ( features ) #### CORN loss loss = corn_loss ( logits , class_labels , NUM_CLASSES ) ###--------------------------------------------------------------------### optimizer . zero_grad () loss . backward () optimizer . step () ### LOGGING if not batch_idx % 200 : print ( 'Epoch: %03d / %03d | Batch %03d / %03d | Cost: %.4f ' % ( epoch + 1 , num_epochs , batch_idx , len ( train_loader ), loss )) Epoch: 001/010 | Batch 000/468 | Cost: 50.5479 /Users/sebastian/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /tmp/pip-req-build-gqmopi53/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) Epoch: 001/010 | Batch 200/468 | Cost: 9.7984 Epoch: 001/010 | Batch 400/468 | Cost: 5.6653 Epoch: 002/010 | Batch 000/468 | Cost: 6.6017 Epoch: 002/010 | Batch 200/468 | Cost: 4.7958 Epoch: 002/010 | Batch 400/468 | Cost: 4.7984 Epoch: 003/010 | Batch 000/468 | Cost: 3.9449 Epoch: 003/010 | Batch 200/468 | Cost: 3.6385 Epoch: 003/010 | Batch 400/468 | Cost: 2.8829 Epoch: 004/010 | Batch 000/468 | Cost: 2.0917 Epoch: 004/010 | Batch 200/468 | Cost: 2.8083 Epoch: 004/010 | Batch 400/468 | Cost: 2.6029 Epoch: 005/010 | Batch 000/468 | Cost: 3.0181 Epoch: 005/010 | Batch 200/468 | Cost: 2.5722 Epoch: 005/010 | Batch 400/468 | Cost: 1.0547 Epoch: 006/010 | Batch 000/468 | Cost: 1.8847 Epoch: 006/010 | Batch 200/468 | Cost: 1.8378 Epoch: 006/010 | Batch 400/468 | Cost: 2.7391 Epoch: 007/010 | Batch 000/468 | Cost: 4.4030 Epoch: 007/010 | Batch 200/468 | Cost: 1.7034 Epoch: 007/010 | Batch 400/468 | Cost: 1.4372 Epoch: 008/010 | Batch 000/468 | Cost: 2.5416 Epoch: 008/010 | Batch 200/468 | Cost: 2.0749 Epoch: 008/010 | Batch 400/468 | Cost: 2.3005 Epoch: 009/010 | Batch 000/468 | Cost: 1.7815 Epoch: 009/010 | Batch 200/468 | Cost: 3.4259 Epoch: 009/010 | Batch 400/468 | Cost: 1.8984 Epoch: 010/010 | Batch 000/468 | Cost: 1.4577 Epoch: 010/010 | Batch 200/468 | Cost: 2.1422 Epoch: 010/010 | Batch 400/468 | Cost: 2.0863","title":"3 - Using the CORN loss for model training"},{"location":"tutorials/pure_pytorch/CORN_mnist/#4-evaluate-model","text":"Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures. For this, we are going to use the corn_label_from_logits utility function from coral_pytorch to convert the probabilities back to the orginal label. from coral_pytorch.dataset import corn_label_from_logits def compute_mae_and_mse ( model , data_loader , device ): with torch . no_grad (): mae , mse , acc , num_examples = 0. , 0. , 0. , 0 for i , ( features , targets ) in enumerate ( data_loader ): features = features . to ( device ) targets = targets . float () . to ( device ) logits = model ( features ) predicted_labels = corn_label_from_logits ( logits ) . float () num_examples += targets . size ( 0 ) mae += torch . sum ( torch . abs ( predicted_labels - targets )) mse += torch . sum (( predicted_labels - targets ) ** 2 ) mae = mae / num_examples mse = mse / num_examples return mae , mse train_mae , train_mse = compute_mae_and_mse ( model , train_loader , DEVICE ) test_mae , test_mse = compute_mae_and_mse ( model , test_loader , DEVICE ) print ( f 'Mean absolute error (train/test): { train_mae : .2f } | { test_mae : .2f } ' ) print ( f 'Mean squared error (train/test): { train_mse : .2f } | { test_mse : .2f } ' ) Mean absolute error (train/test): 3.37 | 3.35 Mean squared error (train/test): 17.28 | 16.98 Note that MNIST is not an ordinal dataset (there is no order between the image categories), so computing the MAE or MSE doesn't really make sense but we use it anyways for demonstration purposes.","title":"4 -- Evaluate model"},{"location":"tutorials/pure_pytorch/CORN_mnist/#5-rank-probabilities-from-logits","text":"To obtain the rank probabilities from the logits, you can use the sigmoid function to get the conditional probabilities for each task and then compute the task probabilities via the chain rule for probabilities. Note that this is also done internally by the corn_label_from_logits we used above. logits = model ( features ) with torch . no_grad (): probas = torch . sigmoid ( logits ) probas = torch . cumprod ( probas , dim = 1 ) print ( probas ) tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, ..., 9.9987e-01, 9.9947e-01, 2.6341e-08], [1.0000e+00, 1.0000e+00, 9.9275e-01, ..., 9.8443e-01, 9.8443e-01, 9.2676e-08], [9.1224e-01, 9.1224e-01, 9.1224e-01, ..., 8.5583e-01, 8.5442e-01, 1.7306e-03], ..., [9.9801e-01, 9.9800e-01, 9.9800e-01, ..., 9.8942e-01, 9.8922e-01, 4.1247e-03], [9.9977e-01, 9.9977e-01, 9.9977e-01, ..., 1.5548e-02, 1.5543e-02, 2.8278e-04], [7.4167e-07, 7.4167e-07, 7.2308e-07, ..., 7.4769e-08, 7.4750e-08, 5.6809e-13]])","title":"5 -- Rank probabilities from logits"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/","text":"A Multilayer Perceptron for Ordinal Regression using CORN -- Cement Dataset In this tutorial, we implement a multilayer perceptron for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint: Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851 General settings and hyperparameters Here, we specify some general hyperparameter values and general settings Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch BATCH_SIZE = 64 NUM_EPOCHS = 200 LEARNING_RATE = 0.005 NUM_WORKERS = 0 Implementing a MultiLayerPerceptron using PyTorch Lightning's LightningModule In this section, we set up the main model architecture using the LightningModule from PyTorch Lightning. We start with defining our MultiLayerPerceptron model in pure PyTorch, and then we use it in the LightningModule to get all the extra benefits that PyTorch Lightning provides. import torch # Regular PyTorch Module class MultiLayerPerceptron ( torch . nn . Module ): def __init__ ( self , input_size , hidden_units , num_classes ): super () . __init__ () # num_classes is used by the corn loss function self . num_classes = num_classes # Initialize MLP layers all_layers = [] for hidden_unit in hidden_units : layer = torch . nn . Linear ( input_size , hidden_unit ) all_layers . append ( layer ) all_layers . append ( torch . nn . ReLU ()) input_size = hidden_unit # Regular classifier would use num_classes instead of # num_classes-1 below output_layer = torch . nn . Linear ( hidden_units [ - 1 ], num_classes - 1 ) all_layers . append ( output_layer ) self . model = torch . nn . Sequential ( * all_layers ) def forward ( self , x ): x = self . model ( x ) return x In our LightningModule we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later. Given a multilayer perceptron classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes: Instead of using num_classes in the output layer, use num_classes-1 as shown above Change the loss from loss = torch.nn.functional.cross_entropy(logits, y) to loss = corn_loss(logits, y, num_classes=self.num_classes) To obtain the class/rank labels from the logits, change predicted_labels = torch.argmax(logits, dim=1) to predicted_labels = corn_label_from_logits(logits) from coral_pytorch.losses import corn_loss from coral_pytorch.dataset import corn_label_from_logits import pytorch_lightning as pl import torchmetrics # LightningModule that receives a PyTorch model as input class LightningMLP ( pl . LightningModule ): def __init__ ( self , model ): super () . __init__ () # the inherited PyTorch module self . model = model # Save hyperparameters to the log directory self . save_hyperparameters () # Set up attributes for computing the MAE self . train_mae = torchmetrics . MeanAbsoluteError () self . valid_mae = torchmetrics . MeanAbsoluteError () self . test_mae = torchmetrics . MeanAbsoluteError () # Defining the forward method is only necessary # if you want to use a Trainer's .predict() method (optional) def forward ( self , x ): return self . model ( x ) # a common forward step to compute the loss and labels # this is used for training, validation, and testing below def _shared_step ( self , x , y ): logits = self ( x ) # A regular classifier uses: # loss = torch.nn.functional.cross_entropy(logits, y) loss = corn_loss ( logits , y , num_classes = self . model . num_classes ) # A regular classifier uses: # predicted_labels = torch.argmax(logits, dim=1) predicted_labels = corn_label_from_logits ( logits ) return loss , predicted_labels def training_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"train_loss\" , loss ) self . train_mae . update ( predicted_labels , y ) self . log ( \"train_mae\" , self . train_mae , on_epoch = True , on_step = False ) return loss def validation_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"valid_loss\" , loss ) self . valid_mae . update ( predicted_labels , y ) self . log ( \"valid_mae\" , self . valid_mae , on_epoch = True , on_step = False , prog_bar = True ) def test_step ( self , batch , batch_idx ): x , y = batch _ , predicted_labels = self . _shared_step ( x , y ) self . test_mae . update ( predicted_labels , y ) self . log ( \"test_mae\" , self . test_mae , on_epoch = True , on_step = False ) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = LEARNING_RATE ) return optimizer Setting up the dataset In this section, we are going to set up our dataset. We start by downloading and taking a look at the Cement dataset: Inspecting the dataset import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/gagolews/\" \"ordinal_regression_data/master/cement_strength.csv\" ) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 data_labels = data_df [ \"response\" ] data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] data_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } response V1 V2 V3 V4 V5 V6 V7 V8 0 4 540.0 0.0 0.0 162.0 2.5 1040.0 676.0 28 1 4 540.0 0.0 0.0 162.0 2.5 1055.0 676.0 28 2 2 332.5 142.5 0.0 228.0 0.0 932.0 594.0 270 3 2 332.5 142.5 0.0 228.0 0.0 932.0 594.0 365 4 2 198.6 132.4 0.0 192.0 0.0 978.4 825.5 360 print ( 'Number of features:' , data_features . shape [ 1 ]) print ( 'Number of examples:' , data_features . shape [ 0 ]) print ( 'Labels:' , np . unique ( data_labels . values )) print ( 'Label distribution:' , np . bincount ( data_labels )) Number of features: 8 Number of examples: 998 Labels: [0 1 2 3 4] Label distribution: [196 310 244 152 96] Above, we can see that the dataset consists of 8 features, and there are 998 examples in total. The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). Notice also that the dataset is quite imbalanced. Performance baseline Especially for imbalanced datasets, it's quite useful to compute a performance baseline. In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that! Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE). So, if we use the mean absolute error, \\mathrm{MAE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| , to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median: avg_prediction = np . median ( data_labels . values ) # median minimizes MAE baseline_mae = np . mean ( np . abs ( data_labels . values - avg_prediction )) print ( f 'Baseline MAE: { baseline_mae : .2f } ' ) Baseline MAE: 1.03 In other words, a model that would always predict the dataset median would achieve a MAE of 1.03. A model that has an MAE of > 1 is certainly a bad model. Creating a Dataset class Next, let us set up a data loading mechanism for our model. Note that the Cement dataset is a relatively small dataset that fits into memory quite comfortably so this may seem like overkill. However, the following steps are useful as a template since you can use those for arbitrarily-sized datatsets. First, we define a PyTorch Dataset class that returns the features (inputs) and labels: from torch.utils.data import Dataset class MyDataset ( Dataset ): def __init__ ( self , feature_array , label_array , dtype = np . float32 ): self . features = feature_array . astype ( dtype ) self . labels = label_array def __getitem__ ( self , index ): inputs = self . features [ index ] label = self . labels [ index ] return inputs , label def __len__ ( self ): return self . features . shape [ 0 ] Setting up a DataModule There are three main ways we can prepare the dataset for Lightning. We can make the dataset part of the model; set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection; create a LightningDataModule. Here, we are going to use approach 3, which is the most organized approach. The LightningDataModule consists of several self-explanatory methods as we can see below: import os from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from torch.utils.data import DataLoader class DataModule ( pl . LightningDataModule ): def __init__ ( self , data_path = './' ): super () . __init__ () self . data_path = data_path def prepare_data ( self ): data_df = pd . read_csv ( 'https://raw.githubusercontent.com/gagolews/' 'ordinal_regression_data/master/cement_strength.csv' ) data_df . to_csv ( os . path . join ( self . data_path , 'cement_strength.csv' ), index = None ) return def setup ( self , stage = None ): data_df = pd . read_csv ( os . path . join ( self . data_path , 'cement_strength.csv' )) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 self . data_labels = data_df [ \"response\" ] self . data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] # Split into # 70% train, 10% validation, 20% testing X_temp , X_test , y_temp , y_test = train_test_split ( self . data_features . values , self . data_labels . values , test_size = 0.2 , random_state = 1 , stratify = self . data_labels . values ) X_train , X_valid , y_train , y_valid = train_test_split ( X_temp , y_temp , test_size = 0.1 , random_state = 1 , stratify = y_temp ) # Standardize features sc = StandardScaler () X_train_std = sc . fit_transform ( X_train ) X_valid_std = sc . transform ( X_valid ) X_test_std = sc . transform ( X_test ) self . train = MyDataset ( X_train_std , y_train ) self . valid = MyDataset ( X_valid_std , y_valid ) self . test = MyDataset ( X_test_std , y_test ) def train_dataloader ( self ): return DataLoader ( self . train , batch_size = 64 , num_workers = NUM_WORKERS , drop_last = True ) def val_dataloader ( self ): return DataLoader ( self . valid , batch_size = 64 , num_workers = NUM_WORKERS ) def test_dataloader ( self ): return DataLoader ( self . test , batch_size = 64 , num_workers = NUM_WORKERS ) Note that the prepare_data method is usually used for steps that only need to be executed once, for example, downloading the dataset; the setup method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. Next, lets initialize the DataModule ; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code): torch . manual_seed ( 1 ) data_module = DataModule ( data_path = '../data' ) Training the model using the PyTorch Lightning Trainer class Next, we initialize our multilayer perceptron model (here, a 2-layer MLP with 24 units in the first hidden layer, and 16 units in the second hidden layer). We wrap the model in our LightningMLP so that we can use PyTorch Lightning's powerful Trainer API. Also, we define a callback so that we can obtain the model with the best validation set performance after training. Note PyTorch Lightning offers many advanced logging services like Weights & Biases. However, here, we will keep things simple and use the CSVLogger : from pytorch_lightning.callbacks import ModelCheckpoint from pytorch_lightning.loggers import CSVLogger pytorch_model = MultiLayerPerceptron ( input_size = data_features . shape [ 1 ], hidden_units = ( 24 , 16 ), num_classes = np . bincount ( data_labels ) . shape [ 0 ]) lightning_model = LightningMLP ( pytorch_model ) callbacks = [ ModelCheckpoint ( save_top_k = 1 , mode = \"min\" , monitor = \"valid_mae\" )] # save top 1 model logger = CSVLogger ( save_dir = \"logs/\" , name = \"mlp-corn-cement\" ) Now it's time to train our model: trainer = pl . Trainer ( max_epochs = NUM_EPOCHS , callbacks = callbacks , accelerator = \"auto\" , # uses CPU by default or a GPU/TPU if avail devices = \"auto\" , # uses all available GPUs/TPUs if applicable logger = logger , log_every_n_steps = 1 ) trainer . fit ( model = lightning_model , datamodule = data_module ) GPU available: False, used: False TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs | Name | Type | Params --------------------------------------------------- 0 | model | MultiLayerPerceptron | 684 1 | train_mae | MeanAbsoluteError | 0 2 | valid_mae | MeanAbsoluteError | 0 3 | test_mae | MeanAbsoluteError | 0 --------------------------------------------------- 684 Trainable params 0 Non-trainable params 684 Total params 0.003 Total estimated model params size (MB) Evaluating the model After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a more advanced logger that does that for you): metrics = pd . read_csv ( f \" { trainer . logger . log_dir } /metrics.csv\" ) aggreg_metrics = [] agg_col = \"epoch\" for i , dfg in metrics . groupby ( agg_col ): agg = dict ( dfg . mean ()) agg [ agg_col ] = i aggreg_metrics . append ( agg ) df_metrics = pd . DataFrame ( aggreg_metrics ) df_metrics [[ \"train_loss\" , \"valid_loss\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'Loss' ) df_metrics [[ \"valid_mae\" , \"train_mae\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'MAE' ) <AxesSubplot:xlabel='Epoch', ylabel='MAE'> As we can see from the loss plot above, the model starts overfitting pretty quickly; however the validation set MAE keeps improving. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 110. The trainer saved this model automatically for us, we which we can load from the checkpoint via the ckpt_path='best' argument; below we use the trainer instance to evaluate the best model on the test set: trainer . test ( model = lightning_model , datamodule = data_module , ckpt_path = 'best' ) Restoring states from the checkpoint path at logs/mlp-corn-cement/version_20/checkpoints/epoch=112-step=1242.ckpt Loaded model weights from checkpoint at logs/mlp-corn-cement/version_20/checkpoints/epoch=112-step=1242.ckpt /Users/sebastian/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance. rank_zero_warn( Testing: 0it [00:00, ?it/s] -------------------------------------------------------------------------------- DATALOADER:0 TEST RESULTS {'test_mae': 0.3050000071525574} -------------------------------------------------------------------------------- [{'test_mae': 0.3050000071525574}] The MAE of our model is quite good, especially compared to the 1.03 MAE baseline earlier. Predicting labels of new data You can use the trainer.predict method on a new DataLoader or DataModule to apply the model to new data. Alternatively, you can also manually load the best model from a checkpoint as shown below: path = f ' { trainer . logger . log_dir } /checkpoints/epoch=112-step=1242.ckpt' lightning_model = LightningMLP . load_from_checkpoint ( path ) Note that our MultilayerPerceptron , which is passed to LightningMLP requires input arguments. However, this is automatically being taken care of since we used self.save_hyperparameters() in LightningMLP 's __init__ method. Now, below is an example applying the model manually. Here, pretend that the test_dataloader is a new data loader. test_dataloader = data_module . test_dataloader () all_predicted_labels = [] for batch in test_dataloader : features , _ = batch logits = lightning_model . model ( features ) predicted_labels = corn_label_from_logits ( logits ) all_predicted_labels . append ( predicted_labels ) all_predicted_labels = torch . cat ( all_predicted_labels ) all_predicted_labels [: 5 ] tensor([0, 4, 1, 2, 0])","title":"CORN multilayer perceptron for tabular data (Cement dataset)"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#a-multilayer-perceptron-for-ordinal-regression-using-corn-cement-dataset","text":"In this tutorial, we implement a multilayer perceptron for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint: Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851","title":"A Multilayer Perceptron for Ordinal Regression using CORN -- Cement Dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#general-settings-and-hyperparameters","text":"Here, we specify some general hyperparameter values and general settings Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch BATCH_SIZE = 64 NUM_EPOCHS = 200 LEARNING_RATE = 0.005 NUM_WORKERS = 0","title":"General settings and hyperparameters"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#implementing-a-multilayerperceptron-using-pytorch-lightnings-lightningmodule","text":"In this section, we set up the main model architecture using the LightningModule from PyTorch Lightning. We start with defining our MultiLayerPerceptron model in pure PyTorch, and then we use it in the LightningModule to get all the extra benefits that PyTorch Lightning provides. import torch # Regular PyTorch Module class MultiLayerPerceptron ( torch . nn . Module ): def __init__ ( self , input_size , hidden_units , num_classes ): super () . __init__ () # num_classes is used by the corn loss function self . num_classes = num_classes # Initialize MLP layers all_layers = [] for hidden_unit in hidden_units : layer = torch . nn . Linear ( input_size , hidden_unit ) all_layers . append ( layer ) all_layers . append ( torch . nn . ReLU ()) input_size = hidden_unit # Regular classifier would use num_classes instead of # num_classes-1 below output_layer = torch . nn . Linear ( hidden_units [ - 1 ], num_classes - 1 ) all_layers . append ( output_layer ) self . model = torch . nn . Sequential ( * all_layers ) def forward ( self , x ): x = self . model ( x ) return x In our LightningModule we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later. Given a multilayer perceptron classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes: Instead of using num_classes in the output layer, use num_classes-1 as shown above Change the loss from loss = torch.nn.functional.cross_entropy(logits, y) to loss = corn_loss(logits, y, num_classes=self.num_classes) To obtain the class/rank labels from the logits, change predicted_labels = torch.argmax(logits, dim=1) to predicted_labels = corn_label_from_logits(logits) from coral_pytorch.losses import corn_loss from coral_pytorch.dataset import corn_label_from_logits import pytorch_lightning as pl import torchmetrics # LightningModule that receives a PyTorch model as input class LightningMLP ( pl . LightningModule ): def __init__ ( self , model ): super () . __init__ () # the inherited PyTorch module self . model = model # Save hyperparameters to the log directory self . save_hyperparameters () # Set up attributes for computing the MAE self . train_mae = torchmetrics . MeanAbsoluteError () self . valid_mae = torchmetrics . MeanAbsoluteError () self . test_mae = torchmetrics . MeanAbsoluteError () # Defining the forward method is only necessary # if you want to use a Trainer's .predict() method (optional) def forward ( self , x ): return self . model ( x ) # a common forward step to compute the loss and labels # this is used for training, validation, and testing below def _shared_step ( self , x , y ): logits = self ( x ) # A regular classifier uses: # loss = torch.nn.functional.cross_entropy(logits, y) loss = corn_loss ( logits , y , num_classes = self . model . num_classes ) # A regular classifier uses: # predicted_labels = torch.argmax(logits, dim=1) predicted_labels = corn_label_from_logits ( logits ) return loss , predicted_labels def training_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"train_loss\" , loss ) self . train_mae . update ( predicted_labels , y ) self . log ( \"train_mae\" , self . train_mae , on_epoch = True , on_step = False ) return loss def validation_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"valid_loss\" , loss ) self . valid_mae . update ( predicted_labels , y ) self . log ( \"valid_mae\" , self . valid_mae , on_epoch = True , on_step = False , prog_bar = True ) def test_step ( self , batch , batch_idx ): x , y = batch _ , predicted_labels = self . _shared_step ( x , y ) self . test_mae . update ( predicted_labels , y ) self . log ( \"test_mae\" , self . test_mae , on_epoch = True , on_step = False ) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = LEARNING_RATE ) return optimizer","title":"Implementing a MultiLayerPerceptron using PyTorch Lightning's LightningModule"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#setting-up-the-dataset","text":"In this section, we are going to set up our dataset. We start by downloading and taking a look at the Cement dataset:","title":"Setting up the dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#inspecting-the-dataset","text":"import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/gagolews/\" \"ordinal_regression_data/master/cement_strength.csv\" ) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 data_labels = data_df [ \"response\" ] data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] data_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } response V1 V2 V3 V4 V5 V6 V7 V8 0 4 540.0 0.0 0.0 162.0 2.5 1040.0 676.0 28 1 4 540.0 0.0 0.0 162.0 2.5 1055.0 676.0 28 2 2 332.5 142.5 0.0 228.0 0.0 932.0 594.0 270 3 2 332.5 142.5 0.0 228.0 0.0 932.0 594.0 365 4 2 198.6 132.4 0.0 192.0 0.0 978.4 825.5 360 print ( 'Number of features:' , data_features . shape [ 1 ]) print ( 'Number of examples:' , data_features . shape [ 0 ]) print ( 'Labels:' , np . unique ( data_labels . values )) print ( 'Label distribution:' , np . bincount ( data_labels )) Number of features: 8 Number of examples: 998 Labels: [0 1 2 3 4] Label distribution: [196 310 244 152 96] Above, we can see that the dataset consists of 8 features, and there are 998 examples in total. The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). Notice also that the dataset is quite imbalanced.","title":"Inspecting the dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#performance-baseline","text":"Especially for imbalanced datasets, it's quite useful to compute a performance baseline. In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that! Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE). So, if we use the mean absolute error, \\mathrm{MAE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| , to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median: avg_prediction = np . median ( data_labels . values ) # median minimizes MAE baseline_mae = np . mean ( np . abs ( data_labels . values - avg_prediction )) print ( f 'Baseline MAE: { baseline_mae : .2f } ' ) Baseline MAE: 1.03 In other words, a model that would always predict the dataset median would achieve a MAE of 1.03. A model that has an MAE of > 1 is certainly a bad model.","title":"Performance baseline"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#creating-a-dataset-class","text":"Next, let us set up a data loading mechanism for our model. Note that the Cement dataset is a relatively small dataset that fits into memory quite comfortably so this may seem like overkill. However, the following steps are useful as a template since you can use those for arbitrarily-sized datatsets. First, we define a PyTorch Dataset class that returns the features (inputs) and labels: from torch.utils.data import Dataset class MyDataset ( Dataset ): def __init__ ( self , feature_array , label_array , dtype = np . float32 ): self . features = feature_array . astype ( dtype ) self . labels = label_array def __getitem__ ( self , index ): inputs = self . features [ index ] label = self . labels [ index ] return inputs , label def __len__ ( self ): return self . features . shape [ 0 ]","title":"Creating a Dataset class"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#setting-up-a-datamodule","text":"There are three main ways we can prepare the dataset for Lightning. We can make the dataset part of the model; set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection; create a LightningDataModule. Here, we are going to use approach 3, which is the most organized approach. The LightningDataModule consists of several self-explanatory methods as we can see below: import os from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from torch.utils.data import DataLoader class DataModule ( pl . LightningDataModule ): def __init__ ( self , data_path = './' ): super () . __init__ () self . data_path = data_path def prepare_data ( self ): data_df = pd . read_csv ( 'https://raw.githubusercontent.com/gagolews/' 'ordinal_regression_data/master/cement_strength.csv' ) data_df . to_csv ( os . path . join ( self . data_path , 'cement_strength.csv' ), index = None ) return def setup ( self , stage = None ): data_df = pd . read_csv ( os . path . join ( self . data_path , 'cement_strength.csv' )) data_df [ \"response\" ] = data_df [ \"response\" ] - 1 # labels should start at 0 self . data_labels = data_df [ \"response\" ] self . data_features = data_df . loc [:, [ \"V1\" , \"V2\" , \"V3\" , \"V4\" , \"V5\" , \"V6\" , \"V7\" , \"V8\" ]] # Split into # 70% train, 10% validation, 20% testing X_temp , X_test , y_temp , y_test = train_test_split ( self . data_features . values , self . data_labels . values , test_size = 0.2 , random_state = 1 , stratify = self . data_labels . values ) X_train , X_valid , y_train , y_valid = train_test_split ( X_temp , y_temp , test_size = 0.1 , random_state = 1 , stratify = y_temp ) # Standardize features sc = StandardScaler () X_train_std = sc . fit_transform ( X_train ) X_valid_std = sc . transform ( X_valid ) X_test_std = sc . transform ( X_test ) self . train = MyDataset ( X_train_std , y_train ) self . valid = MyDataset ( X_valid_std , y_valid ) self . test = MyDataset ( X_test_std , y_test ) def train_dataloader ( self ): return DataLoader ( self . train , batch_size = 64 , num_workers = NUM_WORKERS , drop_last = True ) def val_dataloader ( self ): return DataLoader ( self . valid , batch_size = 64 , num_workers = NUM_WORKERS ) def test_dataloader ( self ): return DataLoader ( self . test , batch_size = 64 , num_workers = NUM_WORKERS ) Note that the prepare_data method is usually used for steps that only need to be executed once, for example, downloading the dataset; the setup method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. Next, lets initialize the DataModule ; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code): torch . manual_seed ( 1 ) data_module = DataModule ( data_path = '../data' )","title":"Setting up a DataModule"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#training-the-model-using-the-pytorch-lightning-trainer-class","text":"Next, we initialize our multilayer perceptron model (here, a 2-layer MLP with 24 units in the first hidden layer, and 16 units in the second hidden layer). We wrap the model in our LightningMLP so that we can use PyTorch Lightning's powerful Trainer API. Also, we define a callback so that we can obtain the model with the best validation set performance after training. Note PyTorch Lightning offers many advanced logging services like Weights & Biases. However, here, we will keep things simple and use the CSVLogger : from pytorch_lightning.callbacks import ModelCheckpoint from pytorch_lightning.loggers import CSVLogger pytorch_model = MultiLayerPerceptron ( input_size = data_features . shape [ 1 ], hidden_units = ( 24 , 16 ), num_classes = np . bincount ( data_labels ) . shape [ 0 ]) lightning_model = LightningMLP ( pytorch_model ) callbacks = [ ModelCheckpoint ( save_top_k = 1 , mode = \"min\" , monitor = \"valid_mae\" )] # save top 1 model logger = CSVLogger ( save_dir = \"logs/\" , name = \"mlp-corn-cement\" ) Now it's time to train our model: trainer = pl . Trainer ( max_epochs = NUM_EPOCHS , callbacks = callbacks , accelerator = \"auto\" , # uses CPU by default or a GPU/TPU if avail devices = \"auto\" , # uses all available GPUs/TPUs if applicable logger = logger , log_every_n_steps = 1 ) trainer . fit ( model = lightning_model , datamodule = data_module ) GPU available: False, used: False TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs | Name | Type | Params --------------------------------------------------- 0 | model | MultiLayerPerceptron | 684 1 | train_mae | MeanAbsoluteError | 0 2 | valid_mae | MeanAbsoluteError | 0 3 | test_mae | MeanAbsoluteError | 0 --------------------------------------------------- 684 Trainable params 0 Non-trainable params 684 Total params 0.003 Total estimated model params size (MB)","title":"Training the model using the PyTorch Lightning Trainer class"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#evaluating-the-model","text":"After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a more advanced logger that does that for you): metrics = pd . read_csv ( f \" { trainer . logger . log_dir } /metrics.csv\" ) aggreg_metrics = [] agg_col = \"epoch\" for i , dfg in metrics . groupby ( agg_col ): agg = dict ( dfg . mean ()) agg [ agg_col ] = i aggreg_metrics . append ( agg ) df_metrics = pd . DataFrame ( aggreg_metrics ) df_metrics [[ \"train_loss\" , \"valid_loss\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'Loss' ) df_metrics [[ \"valid_mae\" , \"train_mae\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'MAE' ) <AxesSubplot:xlabel='Epoch', ylabel='MAE'> As we can see from the loss plot above, the model starts overfitting pretty quickly; however the validation set MAE keeps improving. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 110. The trainer saved this model automatically for us, we which we can load from the checkpoint via the ckpt_path='best' argument; below we use the trainer instance to evaluate the best model on the test set: trainer . test ( model = lightning_model , datamodule = data_module , ckpt_path = 'best' ) Restoring states from the checkpoint path at logs/mlp-corn-cement/version_20/checkpoints/epoch=112-step=1242.ckpt Loaded model weights from checkpoint at logs/mlp-corn-cement/version_20/checkpoints/epoch=112-step=1242.ckpt /Users/sebastian/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance. rank_zero_warn( Testing: 0it [00:00, ?it/s] -------------------------------------------------------------------------------- DATALOADER:0 TEST RESULTS {'test_mae': 0.3050000071525574} -------------------------------------------------------------------------------- [{'test_mae': 0.3050000071525574}] The MAE of our model is quite good, especially compared to the 1.03 MAE baseline earlier.","title":"Evaluating the model"},{"location":"tutorials/pytorch_lightning/ordinal-corn_cement/#predicting-labels-of-new-data","text":"You can use the trainer.predict method on a new DataLoader or DataModule to apply the model to new data. Alternatively, you can also manually load the best model from a checkpoint as shown below: path = f ' { trainer . logger . log_dir } /checkpoints/epoch=112-step=1242.ckpt' lightning_model = LightningMLP . load_from_checkpoint ( path ) Note that our MultilayerPerceptron , which is passed to LightningMLP requires input arguments. However, this is automatically being taken care of since we used self.save_hyperparameters() in LightningMLP 's __init__ method. Now, below is an example applying the model manually. Here, pretend that the test_dataloader is a new data loader. test_dataloader = data_module . test_dataloader () all_predicted_labels = [] for batch in test_dataloader : features , _ = batch logits = lightning_model . model ( features ) predicted_labels = corn_label_from_logits ( logits ) all_predicted_labels . append ( predicted_labels ) all_predicted_labels = torch . cat ( all_predicted_labels ) all_predicted_labels [: 5 ] tensor([0, 4, 1, 2, 0])","title":"Predicting labels of new data"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/","text":"A Convolutional Neural Net for Ordinal Regression using CORN -- MNIST Dataset In this tutorial, we implement a convolutional neural network for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint: Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851 Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps. General settings and hyperparameters Here, we specify some general hyperparameter values and general settings Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch. So, if you have problems with the data loader later, try setting NUM_WORKERS = 0 instead. BATCH_SIZE = 256 NUM_EPOCHS = 20 LEARNING_RATE = 0.005 NUM_WORKERS = 4 Implementing a ConvNet using PyTorch Lightning's LightningModule In this section, we set up the main model architecture using the LightningModule from PyTorch Lightning. We start with defining our convolutional neural network ConvNet model in pure PyTorch, and then we use it in the LightningModule to get all the extra benefits that PyTorch Lightning provides. import torch # Regular PyTorch Module class ConvNet ( torch . nn . Module ): def __init__ ( self , in_channels , num_classes ): super () . __init__ () # num_classes is used by the corn loss function self . num_classes = num_classes # Initialize CNN layers all_layers = [ torch . nn . Conv2d ( in_channels = in_channels , out_channels = 3 , kernel_size = ( 3 , 3 ), stride = ( 1 , 1 ), padding = 1 ), torch . nn . MaxPool2d ( kernel_size = ( 2 , 2 ), stride = ( 2 , 2 )), torch . nn . Conv2d ( in_channels = 3 , out_channels = 6 , kernel_size = ( 3 , 3 ), stride = ( 1 , 1 ), padding = 1 ), torch . nn . MaxPool2d ( kernel_size = ( 2 , 2 ), stride = ( 2 , 2 )), torch . nn . Flatten () ] # Regular classifier would use num_classes instead of # num_classes-1 below output_layer = torch . nn . Linear ( 294 , num_classes - 1 ) all_layers . append ( output_layer ) self . model = torch . nn . Sequential ( * all_layers ) def forward ( self , x ): x = self . model ( x ) return x In our LightningModule we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later. Given a CNN classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes: Instead of using num_classes in the output layer, use num_classes-1 as shown above Change the loss from loss = torch.nn.functional.cross_entropy(logits, y) to loss = corn_loss(logits, y, num_classes=self.num_classes) To obtain the class/rank labels from the logits, change predicted_labels = torch.argmax(logits, dim=1) to predicted_labels = corn_label_from_logits(logits) from coral_pytorch.losses import corn_loss from coral_pytorch.dataset import corn_label_from_logits import pytorch_lightning as pl import torchmetrics # LightningModule that receives a PyTorch model as input class LightningCNN ( pl . LightningModule ): def __init__ ( self , model ): super () . __init__ () # the inherited PyTorch module self . model = model # Save hyperparameters to the log directory self . save_hyperparameters () # Set up attributes for computing the MAE self . train_mae = torchmetrics . MeanAbsoluteError () self . valid_mae = torchmetrics . MeanAbsoluteError () self . test_mae = torchmetrics . MeanAbsoluteError () # Defining the forward method is only necessary # if you want to use a Trainer's .predict() method (optional) def forward ( self , x ): return self . model ( x ) # a common forward step to compute the loss and labels # this is used for training, validation, and testing below def _shared_step ( self , x , y ): logits = self ( x ) # A regular classifier uses: # loss = torch.nn.functional.cross_entropy(logits, y) loss = corn_loss ( logits , y , num_classes = self . model . num_classes ) # A regular classifier uses: # predicted_labels = torch.argmax(logits, dim=1) predicted_labels = corn_label_from_logits ( logits ) return loss , predicted_labels def training_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"train_loss\" , loss ) self . train_mae . update ( predicted_labels , y ) self . log ( \"train_mae\" , self . train_mae , on_epoch = True , on_step = False ) return loss def validation_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"valid_loss\" , loss ) self . valid_mae . update ( predicted_labels , y ) self . log ( \"valid_mae\" , self . valid_mae , on_epoch = True , on_step = False , prog_bar = True ) def test_step ( self , batch , batch_idx ): x , y = batch _ , predicted_labels = self . _shared_step ( x , y ) self . test_mae . update ( predicted_labels , y ) self . log ( \"test_mae\" , self . test_mae , on_epoch = True , on_step = False ) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = LEARNING_RATE ) return optimizer Setting up the dataset In this section, we are going to set up our dataset. Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps. Inspecting the dataset import torch from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader train_dataset = datasets . MNIST ( root = '../data' , train = True , transform = transforms . ToTensor (), download = True ) train_loader = DataLoader ( dataset = train_dataset , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS , drop_last = True , shuffle = True ) test_dataset = datasets . MNIST ( root = '../data' , train = False , transform = transforms . ToTensor ()) test_loader = DataLoader ( dataset = test_dataset , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS , drop_last = False , shuffle = False ) # Checking the dataset all_train_labels = [] all_test_labels = [] for images , labels in train_loader : all_train_labels . append ( labels ) all_train_labels = torch . cat ( all_train_labels ) for images , labels in test_loader : all_test_labels . append ( labels ) all_test_labels = torch . cat ( all_test_labels ) print ( 'Training labels:' , torch . unique ( all_train_labels )) print ( 'Training label distribution:' , torch . bincount ( all_train_labels )) print ( ' \\n Test labels:' , torch . unique ( all_test_labels )) print ( 'Test label distribution:' , torch . bincount ( all_test_labels )) Training labels: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) Training label distribution: tensor([5912, 6734, 5948, 6119, 5833, 5411, 5906, 6258, 5843, 5940]) Test labels: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) Test label distribution: tensor([ 980, 1135, 1032, 1010, 982, 892, 958, 1028, 974, 1009]) Above, we can see that the dataset consists of 8 features, and there are 998 examples in total. The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). Notice also that the dataset is quite imbalanced. Performance baseline Especially for imbalanced datasets, it's quite useful to compute a performance baseline. In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that! Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE). So, if we use the mean absolute error, \\mathrm{MAE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| , to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median: all_test_labels = all_test_labels . float () avg_prediction = torch . median ( all_test_labels ) # median minimizes MAE baseline_mae = torch . mean ( torch . abs ( all_test_labels - avg_prediction )) print ( f 'Baseline MAE: { baseline_mae : .2f } ' ) Baseline MAE: 2.52 In other words, a model that would always predict the dataset median would achieve a MAE of 2.52. A model that has an MAE of > 2.52 is certainly a bad model. Setting up a DataModule There are three main ways we can prepare the dataset for Lightning. We can make the dataset part of the model; set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection; create a LightningDataModule. Here, we are going to use approach 3, which is the most organized approach. The LightningDataModule consists of several self-explanatory methods as we can see below: import os from torch.utils.data.dataset import random_split from torch.utils.data import DataLoader class DataModule ( pl . LightningDataModule ): def __init__ ( self , data_path = './' ): super () . __init__ () self . data_path = data_path def prepare_data ( self ): datasets . MNIST ( root = self . data_path , download = True ) return def setup ( self , stage = None ): # Note transforms.ToTensor() scales input images # to 0-1 range train = datasets . MNIST ( root = self . data_path , train = True , transform = transforms . ToTensor (), download = False ) self . test = datasets . MNIST ( root = self . data_path , train = False , transform = transforms . ToTensor (), download = False ) self . train , self . valid = random_split ( train , lengths = [ 55000 , 5000 ]) def train_dataloader ( self ): train_loader = DataLoader ( dataset = self . train , batch_size = BATCH_SIZE , drop_last = True , shuffle = True , num_workers = NUM_WORKERS ) return train_loader def val_dataloader ( self ): valid_loader = DataLoader ( dataset = self . valid , batch_size = BATCH_SIZE , drop_last = False , shuffle = False , num_workers = NUM_WORKERS ) return valid_loader def test_dataloader ( self ): test_loader = DataLoader ( dataset = self . test , batch_size = BATCH_SIZE , drop_last = False , shuffle = False , num_workers = NUM_WORKERS ) return test_loader Note that the prepare_data method is usually used for steps that only need to be executed once, for example, downloading the dataset; the setup method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. Next, lets initialize the DataModule ; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code): torch . manual_seed ( 1 ) data_module = DataModule ( data_path = '../data' ) Training the model using the PyTorch Lightning Trainer class Next, we initialize our CNN ( ConvNet ) model. Also, we define a call back so that we can obtain the model with the best validation set performance after training. PyTorch Lightning offers many advanced logging services like Weights & Biases. Here, we will keep things simple and use the CSVLogger : from pytorch_lightning.callbacks import ModelCheckpoint from pytorch_lightning.loggers import CSVLogger pytorch_model = ConvNet ( in_channels = 1 , num_classes = torch . unique ( all_test_labels ) . shape [ 0 ]) lightning_model = LightningCNN ( pytorch_model ) callbacks = [ ModelCheckpoint ( save_top_k = 1 , mode = 'min' , monitor = \"valid_mae\" )] # save top 1 model logger = CSVLogger ( save_dir = \"logs/\" , name = \"cnn-corn-mnist\" ) Now it's time to train our model: trainer = pl . Trainer ( max_epochs = NUM_EPOCHS , callbacks = callbacks , accelerator = \"gpu\" , devices = 1 , logger = logger , log_every_n_steps = 1 ) trainer . fit ( model = lightning_model , datamodule = data_module ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] | Name | Type | Params ------------------------------------------------ 0 | model | ConvNet | 2.9 K 1 | train_mae | MeanAbsoluteError | 0 2 | valid_mae | MeanAbsoluteError | 0 3 | test_mae | MeanAbsoluteError | 0 ------------------------------------------------ 2.9 K Trainable params 0 Non-trainable params 2.9 K Total params 0.011 Total estimated model params size (MB) Evaluating the model After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a more advanced logger that does that for you): import pandas as pd metrics = pd . read_csv ( f \" { trainer . logger . log_dir } /metrics.csv\" ) aggreg_metrics = [] agg_col = \"epoch\" for i , dfg in metrics . groupby ( agg_col ): agg = dict ( dfg . mean ()) agg [ agg_col ] = i aggreg_metrics . append ( agg ) df_metrics = pd . DataFrame ( aggreg_metrics ) df_metrics [[ \"train_loss\" , \"valid_loss\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'Loss' ) df_metrics [[ \"valid_mae\" , \"train_mae\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'MAE' ) <AxesSubplot:xlabel='Epoch', ylabel='MAE'> As we can see from the loss plot above, the model starts overfitting pretty quickly; however the validation set MAE keeps improving. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 16. The trainer saved this model automatically for us, we which we can load from the checkpoint via the ckpt_path='best' argument; below we use the trainer instance to evaluate the best model on the test set: trainer . test ( model = lightning_model , datamodule = data_module , ckpt_path = 'best' ) Restoring states from the checkpoint path at logs/cnn-corn-mnist/version_12/checkpoints/epoch=17-step=3851.ckpt LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] Loaded model weights from checkpoint at logs/cnn-corn-mnist/version_12/checkpoints/epoch=17-step=3851.ckpt Testing: 0it [00:00, ?it/s] -------------------------------------------------------------------------------- DATALOADER:0 TEST RESULTS {'test_mae': 0.11819999665021896} -------------------------------------------------------------------------------- [{'test_mae': 0.11819999665021896}] The MAE of our model is quite good, especially compared to the 2.52 MAE baseline earlier. Predicting labels of new data You can use the trainer.predict method on a new DataLoader or DataModule to apply the model to new data. Alternatively, you can also manually load the best model from a checkpoint as shown below: path = f ' { trainer . logger . log_dir } /checkpoints/epoch=17-step=3851.ckpt' lightning_model = LightningCNN . load_from_checkpoint ( path ) Note that our ConvNet , which is passed to LightningCNN requires input arguments. However, this is automatically being taken care of since we used self.save_hyperparameters() in LightningCNN 's __init__ method. Now, below is an example applying the model manually. Here, pretend that the test_dataloader is a new data loader. test_dataloader = data_module . test_dataloader () all_predicted_labels = [] for batch in test_dataloader : features , _ = batch logits = lightning_model . model ( features ) predicted_labels = corn_label_from_logits ( logits ) all_predicted_labels . append ( predicted_labels ) all_predicted_labels = torch . cat ( all_predicted_labels ) all_predicted_labels [: 5 ] tensor([7, 2, 1, 0, 4])","title":"CORN convolutional neural net for image data (MNIST dataset)"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#a-convolutional-neural-net-for-ordinal-regression-using-corn-mnist-dataset","text":"In this tutorial, we implement a convolutional neural network for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint: Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851 Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps.","title":"A Convolutional Neural Net for Ordinal Regression using CORN -- MNIST Dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#general-settings-and-hyperparameters","text":"Here, we specify some general hyperparameter values and general settings Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch. So, if you have problems with the data loader later, try setting NUM_WORKERS = 0 instead. BATCH_SIZE = 256 NUM_EPOCHS = 20 LEARNING_RATE = 0.005 NUM_WORKERS = 4","title":"General settings and hyperparameters"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#implementing-a-convnet-using-pytorch-lightnings-lightningmodule","text":"In this section, we set up the main model architecture using the LightningModule from PyTorch Lightning. We start with defining our convolutional neural network ConvNet model in pure PyTorch, and then we use it in the LightningModule to get all the extra benefits that PyTorch Lightning provides. import torch # Regular PyTorch Module class ConvNet ( torch . nn . Module ): def __init__ ( self , in_channels , num_classes ): super () . __init__ () # num_classes is used by the corn loss function self . num_classes = num_classes # Initialize CNN layers all_layers = [ torch . nn . Conv2d ( in_channels = in_channels , out_channels = 3 , kernel_size = ( 3 , 3 ), stride = ( 1 , 1 ), padding = 1 ), torch . nn . MaxPool2d ( kernel_size = ( 2 , 2 ), stride = ( 2 , 2 )), torch . nn . Conv2d ( in_channels = 3 , out_channels = 6 , kernel_size = ( 3 , 3 ), stride = ( 1 , 1 ), padding = 1 ), torch . nn . MaxPool2d ( kernel_size = ( 2 , 2 ), stride = ( 2 , 2 )), torch . nn . Flatten () ] # Regular classifier would use num_classes instead of # num_classes-1 below output_layer = torch . nn . Linear ( 294 , num_classes - 1 ) all_layers . append ( output_layer ) self . model = torch . nn . Sequential ( * all_layers ) def forward ( self , x ): x = self . model ( x ) return x In our LightningModule we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later. Given a CNN classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes: Instead of using num_classes in the output layer, use num_classes-1 as shown above Change the loss from loss = torch.nn.functional.cross_entropy(logits, y) to loss = corn_loss(logits, y, num_classes=self.num_classes) To obtain the class/rank labels from the logits, change predicted_labels = torch.argmax(logits, dim=1) to predicted_labels = corn_label_from_logits(logits) from coral_pytorch.losses import corn_loss from coral_pytorch.dataset import corn_label_from_logits import pytorch_lightning as pl import torchmetrics # LightningModule that receives a PyTorch model as input class LightningCNN ( pl . LightningModule ): def __init__ ( self , model ): super () . __init__ () # the inherited PyTorch module self . model = model # Save hyperparameters to the log directory self . save_hyperparameters () # Set up attributes for computing the MAE self . train_mae = torchmetrics . MeanAbsoluteError () self . valid_mae = torchmetrics . MeanAbsoluteError () self . test_mae = torchmetrics . MeanAbsoluteError () # Defining the forward method is only necessary # if you want to use a Trainer's .predict() method (optional) def forward ( self , x ): return self . model ( x ) # a common forward step to compute the loss and labels # this is used for training, validation, and testing below def _shared_step ( self , x , y ): logits = self ( x ) # A regular classifier uses: # loss = torch.nn.functional.cross_entropy(logits, y) loss = corn_loss ( logits , y , num_classes = self . model . num_classes ) # A regular classifier uses: # predicted_labels = torch.argmax(logits, dim=1) predicted_labels = corn_label_from_logits ( logits ) return loss , predicted_labels def training_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"train_loss\" , loss ) self . train_mae . update ( predicted_labels , y ) self . log ( \"train_mae\" , self . train_mae , on_epoch = True , on_step = False ) return loss def validation_step ( self , batch , batch_idx ): x , y = batch loss , predicted_labels = self . _shared_step ( x , y ) self . log ( \"valid_loss\" , loss ) self . valid_mae . update ( predicted_labels , y ) self . log ( \"valid_mae\" , self . valid_mae , on_epoch = True , on_step = False , prog_bar = True ) def test_step ( self , batch , batch_idx ): x , y = batch _ , predicted_labels = self . _shared_step ( x , y ) self . test_mae . update ( predicted_labels , y ) self . log ( \"test_mae\" , self . test_mae , on_epoch = True , on_step = False ) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = LEARNING_RATE ) return optimizer","title":"Implementing a ConvNet using PyTorch Lightning's LightningModule"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#setting-up-the-dataset","text":"In this section, we are going to set up our dataset. Please note that MNIST is not an ordinal dataset . The reason why we use MNIST in this tutorial is that it is included in the PyTorch's torchvision library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps.","title":"Setting up the dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#inspecting-the-dataset","text":"import torch from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader train_dataset = datasets . MNIST ( root = '../data' , train = True , transform = transforms . ToTensor (), download = True ) train_loader = DataLoader ( dataset = train_dataset , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS , drop_last = True , shuffle = True ) test_dataset = datasets . MNIST ( root = '../data' , train = False , transform = transforms . ToTensor ()) test_loader = DataLoader ( dataset = test_dataset , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS , drop_last = False , shuffle = False ) # Checking the dataset all_train_labels = [] all_test_labels = [] for images , labels in train_loader : all_train_labels . append ( labels ) all_train_labels = torch . cat ( all_train_labels ) for images , labels in test_loader : all_test_labels . append ( labels ) all_test_labels = torch . cat ( all_test_labels ) print ( 'Training labels:' , torch . unique ( all_train_labels )) print ( 'Training label distribution:' , torch . bincount ( all_train_labels )) print ( ' \\n Test labels:' , torch . unique ( all_test_labels )) print ( 'Test label distribution:' , torch . bincount ( all_test_labels )) Training labels: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) Training label distribution: tensor([5912, 6734, 5948, 6119, 5833, 5411, 5906, 6258, 5843, 5940]) Test labels: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) Test label distribution: tensor([ 980, 1135, 1032, 1010, 982, 892, 958, 1028, 974, 1009]) Above, we can see that the dataset consists of 8 features, and there are 998 examples in total. The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). Notice also that the dataset is quite imbalanced.","title":"Inspecting the dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#performance-baseline","text":"Especially for imbalanced datasets, it's quite useful to compute a performance baseline. In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that! Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE). So, if we use the mean absolute error, \\mathrm{MAE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| , to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median: all_test_labels = all_test_labels . float () avg_prediction = torch . median ( all_test_labels ) # median minimizes MAE baseline_mae = torch . mean ( torch . abs ( all_test_labels - avg_prediction )) print ( f 'Baseline MAE: { baseline_mae : .2f } ' ) Baseline MAE: 2.52 In other words, a model that would always predict the dataset median would achieve a MAE of 2.52. A model that has an MAE of > 2.52 is certainly a bad model.","title":"Performance baseline"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#setting-up-a-datamodule","text":"There are three main ways we can prepare the dataset for Lightning. We can make the dataset part of the model; set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection; create a LightningDataModule. Here, we are going to use approach 3, which is the most organized approach. The LightningDataModule consists of several self-explanatory methods as we can see below: import os from torch.utils.data.dataset import random_split from torch.utils.data import DataLoader class DataModule ( pl . LightningDataModule ): def __init__ ( self , data_path = './' ): super () . __init__ () self . data_path = data_path def prepare_data ( self ): datasets . MNIST ( root = self . data_path , download = True ) return def setup ( self , stage = None ): # Note transforms.ToTensor() scales input images # to 0-1 range train = datasets . MNIST ( root = self . data_path , train = True , transform = transforms . ToTensor (), download = False ) self . test = datasets . MNIST ( root = self . data_path , train = False , transform = transforms . ToTensor (), download = False ) self . train , self . valid = random_split ( train , lengths = [ 55000 , 5000 ]) def train_dataloader ( self ): train_loader = DataLoader ( dataset = self . train , batch_size = BATCH_SIZE , drop_last = True , shuffle = True , num_workers = NUM_WORKERS ) return train_loader def val_dataloader ( self ): valid_loader = DataLoader ( dataset = self . valid , batch_size = BATCH_SIZE , drop_last = False , shuffle = False , num_workers = NUM_WORKERS ) return valid_loader def test_dataloader ( self ): test_loader = DataLoader ( dataset = self . test , batch_size = BATCH_SIZE , drop_last = False , shuffle = False , num_workers = NUM_WORKERS ) return test_loader Note that the prepare_data method is usually used for steps that only need to be executed once, for example, downloading the dataset; the setup method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. Next, lets initialize the DataModule ; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code): torch . manual_seed ( 1 ) data_module = DataModule ( data_path = '../data' )","title":"Setting up a DataModule"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#training-the-model-using-the-pytorch-lightning-trainer-class","text":"Next, we initialize our CNN ( ConvNet ) model. Also, we define a call back so that we can obtain the model with the best validation set performance after training. PyTorch Lightning offers many advanced logging services like Weights & Biases. Here, we will keep things simple and use the CSVLogger : from pytorch_lightning.callbacks import ModelCheckpoint from pytorch_lightning.loggers import CSVLogger pytorch_model = ConvNet ( in_channels = 1 , num_classes = torch . unique ( all_test_labels ) . shape [ 0 ]) lightning_model = LightningCNN ( pytorch_model ) callbacks = [ ModelCheckpoint ( save_top_k = 1 , mode = 'min' , monitor = \"valid_mae\" )] # save top 1 model logger = CSVLogger ( save_dir = \"logs/\" , name = \"cnn-corn-mnist\" ) Now it's time to train our model: trainer = pl . Trainer ( max_epochs = NUM_EPOCHS , callbacks = callbacks , accelerator = \"gpu\" , devices = 1 , logger = logger , log_every_n_steps = 1 ) trainer . fit ( model = lightning_model , datamodule = data_module ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] | Name | Type | Params ------------------------------------------------ 0 | model | ConvNet | 2.9 K 1 | train_mae | MeanAbsoluteError | 0 2 | valid_mae | MeanAbsoluteError | 0 3 | test_mae | MeanAbsoluteError | 0 ------------------------------------------------ 2.9 K Trainable params 0 Non-trainable params 2.9 K Total params 0.011 Total estimated model params size (MB)","title":"Training the model using the PyTorch Lightning Trainer class"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#evaluating-the-model","text":"After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a more advanced logger that does that for you): import pandas as pd metrics = pd . read_csv ( f \" { trainer . logger . log_dir } /metrics.csv\" ) aggreg_metrics = [] agg_col = \"epoch\" for i , dfg in metrics . groupby ( agg_col ): agg = dict ( dfg . mean ()) agg [ agg_col ] = i aggreg_metrics . append ( agg ) df_metrics = pd . DataFrame ( aggreg_metrics ) df_metrics [[ \"train_loss\" , \"valid_loss\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'Loss' ) df_metrics [[ \"valid_mae\" , \"train_mae\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'MAE' ) <AxesSubplot:xlabel='Epoch', ylabel='MAE'> As we can see from the loss plot above, the model starts overfitting pretty quickly; however the validation set MAE keeps improving. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 16. The trainer saved this model automatically for us, we which we can load from the checkpoint via the ckpt_path='best' argument; below we use the trainer instance to evaluate the best model on the test set: trainer . test ( model = lightning_model , datamodule = data_module , ckpt_path = 'best' ) Restoring states from the checkpoint path at logs/cnn-corn-mnist/version_12/checkpoints/epoch=17-step=3851.ckpt LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] Loaded model weights from checkpoint at logs/cnn-corn-mnist/version_12/checkpoints/epoch=17-step=3851.ckpt Testing: 0it [00:00, ?it/s] -------------------------------------------------------------------------------- DATALOADER:0 TEST RESULTS {'test_mae': 0.11819999665021896} -------------------------------------------------------------------------------- [{'test_mae': 0.11819999665021896}] The MAE of our model is quite good, especially compared to the 2.52 MAE baseline earlier.","title":"Evaluating the model"},{"location":"tutorials/pytorch_lightning/ordinal-corn_mnist/#predicting-labels-of-new-data","text":"You can use the trainer.predict method on a new DataLoader or DataModule to apply the model to new data. Alternatively, you can also manually load the best model from a checkpoint as shown below: path = f ' { trainer . logger . log_dir } /checkpoints/epoch=17-step=3851.ckpt' lightning_model = LightningCNN . load_from_checkpoint ( path ) Note that our ConvNet , which is passed to LightningCNN requires input arguments. However, this is automatically being taken care of since we used self.save_hyperparameters() in LightningCNN 's __init__ method. Now, below is an example applying the model manually. Here, pretend that the test_dataloader is a new data loader. test_dataloader = data_module . test_dataloader () all_predicted_labels = [] for batch in test_dataloader : features , _ = batch logits = lightning_model . model ( features ) predicted_labels = corn_label_from_logits ( logits ) all_predicted_labels . append ( predicted_labels ) all_predicted_labels = torch . cat ( all_predicted_labels ) all_predicted_labels [: 5 ] tensor([7, 2, 1, 0, 4])","title":"Predicting labels of new data"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/","text":"A Recurrent Neural Net for Ordinal Regression using CORN -- TripAdvisor Dataset In this tutorial, we implement a recurrent neural network for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint: Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851 We will be using a balanced version of the TripAdvisor Hotel Review dataset (https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews) that we used in the CORN manuscript (https://github.com/Raschka-research-group/corn-ordinal-neuralnet/blob/main/datasets/tripadvisor/tripadvisor_balanced.csv). General settings and hyperparameters Here, we specify some general hyperparameter values and general settings Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch. So, if you have problems with the data loader later, try setting NUM_WORKERS = 0 instead. BATCH_SIZE = 256 NUM_EPOCHS = 20 LEARNING_RATE = 0.005 NUM_WORKERS = 4 RANDOM_SEED = 123 ## Dataset specific: NUM_CLASSES = 5 VOCABULARY_SIZE = 5000 Implementing an RNN using PyTorch Lightning's LightningModule In this section, we set up the main model architecture using the LightningModule from PyTorch Lightning. We start with defining our recurrent neural network ( RNN ) model in pure PyTorch, and then we use it in the LightningModule to get all the extra benefits that PyTorch Lightning provides. import torch # Regular PyTorch Module class RNN ( torch . nn . Module ): def __init__ ( self , input_dim , embedding_dim , hidden_dim , output_dim , num_classes ): super () . __init__ () self . embedding = torch . nn . Embedding ( input_dim , embedding_dim ) #self.rnn = torch.nn.RNN(embedding_dim, # hidden_dim, # nonlinearity='relu') self . rnn = torch . nn . LSTM ( embedding_dim , hidden_dim ) self . output_layer = torch . nn . Linear ( hidden_dim , num_classes - 1 ) self . num_classes = num_classes def forward ( self , text , text_length ): # text dim: [sentence length, batch size] embedded = self . embedding ( text ) # ebedded dim: [sentence length, batch size, embedding dim] packed = torch . nn . utils . rnn . pack_padded_sequence ( embedded , text_length . to ( 'cpu' )) packed_output , ( hidden , cell ) = self . rnn ( embedded ) # output dim: [sentence length, batch size, hidden dim] # hidden dim: [1, batch size, hidden dim] hidden . squeeze_ ( 0 ) # hidden dim: [batch size, hidden dim] output = self . output_layer ( hidden ) logits = output . view ( - 1 , ( self . num_classes - 1 )) #probas = torch.sigmoid(logits) return logits #, probas In our LightningModule we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later. Given an RNN classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes: Instead of using num_classes in the output layer, use num_classes-1 as shown above Change the loss from loss = torch.nn.functional.cross_entropy(logits, y) to loss = corn_loss(logits, y, num_classes=self.num_classes) To obtain the class/rank labels from the logits, change predicted_labels = torch.argmax(logits, dim=1) to predicted_labels = corn_label_from_logits(logits) from coral_pytorch.losses import corn_loss from coral_pytorch.dataset import corn_label_from_logits import pytorch_lightning as pl import torchmetrics # LightningModule that receives a PyTorch model as input class LightningRNN ( pl . LightningModule ): def __init__ ( self , model ): super () . __init__ () # the inherited PyTorch module self . model = model # Save hyperparameters to the log directory self . save_hyperparameters () # Set up attributes for computing the MAE self . train_mae = torchmetrics . MeanAbsoluteError () self . valid_mae = torchmetrics . MeanAbsoluteError () self . test_mae = torchmetrics . MeanAbsoluteError () # (Re)Defining the forward method is only necessary # if you want to use a Trainer's .predict() method (optional) def forward ( self , text , text_length ): return self . model ( text , text_length ) # a common forward step to compute the loss and labels # this is used for training, validation, and testing below def _shared_step ( self , batch , batch_idx ): # These next 3 steps are unique and look a bit tricky due to # how Torchtext's BucketIterator prepares the batches # and how we use an LSTM with packed & padded text # Also, .TEXT_COLUMN_NAME and .LABEL_COLUMN_NAME # depend on the CSV file columns of the data file we load later. features , text_length = batch . TEXT_COLUMN_NAME true_labels = batch . LABEL_COLUMN_NAME logits = self ( features , text_length ) # A regular classifier uses: # loss = torch.nn.functional.cross_entropy(logits, true_labels) loss = corn_loss ( logits , true_labels , num_classes = self . model . num_classes ) # A regular classifier uses: # predicted_labels = torch.argmax(logits, dim=1) predicted_labels = corn_label_from_logits ( logits ) return loss , true_labels , predicted_labels def training_step ( self , batch , batch_idx ): loss , true_labels , predicted_labels = self . _shared_step ( batch , batch_idx ) self . log ( \"train_loss\" , loss , batch_size = true_labels . shape [ 0 ]) self . train_mae . update ( predicted_labels , true_labels ) self . log ( \"train_mae\" , self . train_mae , on_epoch = True , on_step = False , batch_size = true_labels . shape [ 0 ]) return loss def validation_step ( self , batch , batch_idx ): loss , true_labels , predicted_labels = self . _shared_step ( batch , batch_idx ) self . log ( \"valid_loss\" , loss , batch_size = true_labels . shape [ 0 ]) self . valid_mae . update ( predicted_labels , true_labels ) self . log ( \"valid_mae\" , self . valid_mae , on_epoch = True , on_step = False , prog_bar = True , batch_size = true_labels . shape [ 0 ]) def test_step ( self , batch , batch_idx ): _ , true_labels , predicted_labels = self . _shared_step ( batch , batch_idx ) self . test_mae . update ( predicted_labels , true_labels ) self . log ( \"test_mae\" , self . test_mae , on_epoch = True , on_step = False , batch_size = true_labels . shape [ 0 ]) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = LEARNING_RATE ) return optimizer Setting up the dataset In this section, we are going to set up our dataset. Inspecting the dataset import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/Raschka-research-group/\" \"corn-ordinal-neuralnet/main/datasets/tripadvisor/tripadvisor_balanced.csv\" ) data_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TEXT_COLUMN_NAME LABEL_COLUMN_NAME 6995 beautiful hotel, stay punta cana majestic colo... 5 6996 stay, n't stay, stayed week april, weather ama... 5 6997 stay hotel fantastic, great location, looked n... 5 6998 birthday meal havnt stayed hotel staying barce... 5 6999 great hotel great location stayed royal magda ... 5 CSV_PATH = '../data/tripadvisor_balanced.csv' data_df . to_csv ( CSV_PATH , index = None ) import torchtext import random TEXT = torchtext . legacy . data . Field ( tokenize = 'spacy' , # default splits on whitespace tokenizer_language = 'en_core_web_sm' , include_lengths = True ) LABEL = torchtext . legacy . data . LabelField ( dtype = torch . long ) fields = [( 'TEXT_COLUMN_NAME' , TEXT ), ( 'LABEL_COLUMN_NAME' , LABEL )] dataset = torchtext . legacy . data . TabularDataset ( path = CSV_PATH , format = 'csv' , skip_header = True , fields = fields ) train_data , test_data = dataset . split ( split_ratio = [ 0.8 , 0.2 ], random_state = random . seed ( RANDOM_SEED )) train_data , valid_data = train_data . split ( split_ratio = [ 0.85 , 0.15 ], random_state = random . seed ( RANDOM_SEED )) TEXT . build_vocab ( train_data , max_size = VOCABULARY_SIZE ) LABEL . build_vocab ( train_data ) train_loader , valid_loader , test_loader = torchtext . legacy . data . BucketIterator . splits ( ( train_data , valid_data , test_data ), batch_size = BATCH_SIZE , sort_within_batch = True , # necessary for packed_padded_sequence sort_key = lambda x : len ( x . TEXT_COLUMN_NAME ), ) # Checking the dataset all_train_labels = [] all_test_labels = [] for features , labels in train_loader : all_train_labels . append ( labels ) all_train_labels = torch . cat ( all_train_labels ) for features , labels in test_loader : all_test_labels . append ( labels ) all_test_labels = torch . cat ( all_test_labels ) print ( 'Training labels:' , torch . unique ( all_train_labels )) print ( 'Training label distribution:' , torch . bincount ( all_train_labels )) print ( ' \\n Test labels:' , torch . unique ( all_test_labels )) print ( 'Test label distribution:' , torch . bincount ( all_test_labels )) Training labels: tensor([0, 1, 2, 3, 4]) Training label distribution: tensor([964, 963, 954, 953, 926]) Test labels: tensor([0, 1, 2, 3, 4]) Test label distribution: tensor([275, 267, 300, 274, 284]) Above, we can see that the dataset consists of 8 features, and there are 998 examples in total. The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). Notice also that the dataset is quite balanced. Performance baseline Especially for imbalanced datasets, it's quite useful to compute a performance baseline. In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that! Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE). So, if we use the mean absolute error, \\mathrm{MAE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| , to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median: all_test_labels = all_test_labels . float () avg_prediction = torch . median ( all_test_labels ) # median minimizes MAE baseline_mae = torch . mean ( torch . abs ( all_test_labels - avg_prediction )) print ( f 'Baseline MAE: { baseline_mae : .2f } ' ) Baseline MAE: 1.18 In other words, a model that would always predict the dataset median would achieve a MAE of 1.18. A model that has an MAE of > 1.18 is certainly a bad model. Setting up a DataModule There are three main ways we can prepare the dataset for Lightning. We can make the dataset part of the model; set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection; create a LightningDataModule . Usually, approach 3 is the most organized approach. However, since we already defined our data loaders above, we can just work with those directly. Note that the prepare_data method is usually used for steps that only need to be executed once, for example, downloading the dataset; the setup method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. Next, lets initialize the DataModule ; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code): Training the model using the PyTorch Lightning Trainer class Next, we initialize our RNN model. Also, we define a call back so that we can obtain the model with the best validation set performance after training. PyTorch Lightning offers many advanced logging services like Weights & Biases. Here, we will keep things simple and use the CSVLogger : from pytorch_lightning.callbacks import ModelCheckpoint from pytorch_lightning.loggers import CSVLogger pytorch_model = RNN ( input_dim = len ( TEXT . vocab ), embedding_dim = 128 , hidden_dim = 64 , output_dim = 32 , num_classes = NUM_CLASSES ) lightning_model = LightningRNN ( pytorch_model ) callbacks = [ ModelCheckpoint ( save_top_k = 1 , mode = 'min' , monitor = \"valid_mae\" )] # save top 1 model logger = CSVLogger ( save_dir = \"logs/\" , name = \"cnn-corn-mnist\" ) Note that we disable warning as the .log() method of the LightningModule currently warns us that the batch size is inconsistent. This should not happen as we define the batch_size manually in the self.log calls. However, this will be resolved in a future version (https://github.com/PyTorchLightning/pytorch-lightning/pull/10408). Also note that the batch size is not inconsistent, its just that the BucketIterator in torchtext has creates batches where the text length plus padding is the first dimension in a tensor. And the batch size is the second dimension: for features , labels in train_loader : break print ( 'Text length:' , features [ 0 ] . shape [ 0 ]) print ( 'Batch size (from text):' , features [ 0 ] . shape [ 1 ]) print ( 'Batch size (from labels):' , labels . shape [ 0 ]) Text length: 84 Batch size (from text): 256 Batch size (from labels): 256 import warnings warnings . filterwarnings ( 'ignore' ) Now it's time to train our model: trainer = pl . Trainer ( max_epochs = NUM_EPOCHS , callbacks = callbacks , accelerator = \"gpu\" , devices = 1 , logger = logger , log_every_n_steps = 1 ) trainer . fit ( model = lightning_model , train_dataloaders = train_loader , val_dataloaders = valid_loader ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] | Name | Type | Params ------------------------------------------------ 0 | model | RNN | 690 K 1 | train_mae | MeanAbsoluteError | 0 2 | valid_mae | MeanAbsoluteError | 0 3 | test_mae | MeanAbsoluteError | 0 ------------------------------------------------ 690 K Trainable params 0 Non-trainable params 690 K Total params 2.761 Total estimated model params size (MB) Evaluating the model After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a more advanced logger that does that for you): import pandas as pd metrics = pd . read_csv ( f \" { trainer . logger . log_dir } /metrics.csv\" ) aggreg_metrics = [] agg_col = \"epoch\" for i , dfg in metrics . groupby ( agg_col ): agg = dict ( dfg . mean ()) agg [ agg_col ] = i aggreg_metrics . append ( agg ) df_metrics = pd . DataFrame ( aggreg_metrics ) df_metrics [[ \"train_loss\" , \"valid_loss\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'Loss' ) df_metrics [[ \"valid_mae\" , \"train_mae\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'MAE' ) <AxesSubplot:xlabel='Epoch', ylabel='MAE'> As we can see from the loss plot above, the model starts overfitting pretty quickly. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 5. The trainer saved this model automatically for us, we which we can load from the checkpoint via the ckpt_path='best' argument; below we use the trainer instance to evaluate the best model on the test set: trainer . test ( model = lightning_model , dataloaders = test_loader , ckpt_path = 'best' ) Restoring states from the checkpoint path at logs/cnn-corn-mnist/version_24/checkpoints/epoch=5-step=113.ckpt LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] Loaded model weights from checkpoint at logs/cnn-corn-mnist/version_24/checkpoints/epoch=5-step=113.ckpt Testing: 0it [00:00, ?it/s] -------------------------------------------------------------------------------- DATALOADER:0 TEST RESULTS {'test_mae': 0.9242857098579407} -------------------------------------------------------------------------------- [{'test_mae': 0.9242857098579407}] Predicting labels of new data You can use the trainer.predict method on a new DataLoader or DataModule to apply the model to new data. Alternatively, you can also manually load the best model from a checkpoint as shown below: path = f ' { trainer . logger . log_dir } /checkpoints/epoch=5-step=113.ckpt' lightning_model = LightningRNN . load_from_checkpoint ( path ) Note that our RNN , which is passed to LightningRNN requires input arguments. However, this is automatically being taken care of since we used self.save_hyperparameters() in LightningRNN 's __init__ method. Now, below is an example applying the model manually. Here, pretend that the test_dataloader is a new data loader. all_predicted_labels = [] for batch in test_loader : features , text_length = batch . TEXT_COLUMN_NAME logits = lightning_model . model ( features , text_length ) predicted_labels = corn_label_from_logits ( logits ) all_predicted_labels . append ( predicted_labels ) all_predicted_labels = torch . cat ( all_predicted_labels ) all_predicted_labels [: 5 ] tensor([3, 2, 1, 3, 1])","title":"CORN recurrent neural net for text data (TripAdvisor dataset)"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#a-recurrent-neural-net-for-ordinal-regression-using-corn-tripadvisor-dataset","text":"In this tutorial, we implement a recurrent neural network for ordinal regression based on the CORN method. To learn more about CORN, please have a look at our preprint: Xintong Shi, Wenzhi Cao, and Sebastian Raschka (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. Arxiv preprint; https://arxiv.org/abs/2111.08851 We will be using a balanced version of the TripAdvisor Hotel Review dataset (https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews) that we used in the CORN manuscript (https://github.com/Raschka-research-group/corn-ordinal-neuralnet/blob/main/datasets/tripadvisor/tripadvisor_balanced.csv).","title":"A Recurrent Neural Net for Ordinal Regression using CORN -- TripAdvisor Dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#general-settings-and-hyperparameters","text":"Here, we specify some general hyperparameter values and general settings Note that for small datatsets, it is not necessary and better not to use multiple workers as it can sometimes cause issues with too many open files in PyTorch. So, if you have problems with the data loader later, try setting NUM_WORKERS = 0 instead. BATCH_SIZE = 256 NUM_EPOCHS = 20 LEARNING_RATE = 0.005 NUM_WORKERS = 4 RANDOM_SEED = 123 ## Dataset specific: NUM_CLASSES = 5 VOCABULARY_SIZE = 5000","title":"General settings and hyperparameters"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#implementing-an-rnn-using-pytorch-lightnings-lightningmodule","text":"In this section, we set up the main model architecture using the LightningModule from PyTorch Lightning. We start with defining our recurrent neural network ( RNN ) model in pure PyTorch, and then we use it in the LightningModule to get all the extra benefits that PyTorch Lightning provides. import torch # Regular PyTorch Module class RNN ( torch . nn . Module ): def __init__ ( self , input_dim , embedding_dim , hidden_dim , output_dim , num_classes ): super () . __init__ () self . embedding = torch . nn . Embedding ( input_dim , embedding_dim ) #self.rnn = torch.nn.RNN(embedding_dim, # hidden_dim, # nonlinearity='relu') self . rnn = torch . nn . LSTM ( embedding_dim , hidden_dim ) self . output_layer = torch . nn . Linear ( hidden_dim , num_classes - 1 ) self . num_classes = num_classes def forward ( self , text , text_length ): # text dim: [sentence length, batch size] embedded = self . embedding ( text ) # ebedded dim: [sentence length, batch size, embedding dim] packed = torch . nn . utils . rnn . pack_padded_sequence ( embedded , text_length . to ( 'cpu' )) packed_output , ( hidden , cell ) = self . rnn ( embedded ) # output dim: [sentence length, batch size, hidden dim] # hidden dim: [1, batch size, hidden dim] hidden . squeeze_ ( 0 ) # hidden dim: [batch size, hidden dim] output = self . output_layer ( hidden ) logits = output . view ( - 1 , ( self . num_classes - 1 )) #probas = torch.sigmoid(logits) return logits #, probas In our LightningModule we use loggers to track mean absolute errors for both the training and validation set during training; this allows us to select the best model based on validation set performance later. Given an RNN classifier with cross-entropy loss, it is very easy to change this classifier into a ordinal regression model using CORN. In essence, it only requires three changes: Instead of using num_classes in the output layer, use num_classes-1 as shown above Change the loss from loss = torch.nn.functional.cross_entropy(logits, y) to loss = corn_loss(logits, y, num_classes=self.num_classes) To obtain the class/rank labels from the logits, change predicted_labels = torch.argmax(logits, dim=1) to predicted_labels = corn_label_from_logits(logits) from coral_pytorch.losses import corn_loss from coral_pytorch.dataset import corn_label_from_logits import pytorch_lightning as pl import torchmetrics # LightningModule that receives a PyTorch model as input class LightningRNN ( pl . LightningModule ): def __init__ ( self , model ): super () . __init__ () # the inherited PyTorch module self . model = model # Save hyperparameters to the log directory self . save_hyperparameters () # Set up attributes for computing the MAE self . train_mae = torchmetrics . MeanAbsoluteError () self . valid_mae = torchmetrics . MeanAbsoluteError () self . test_mae = torchmetrics . MeanAbsoluteError () # (Re)Defining the forward method is only necessary # if you want to use a Trainer's .predict() method (optional) def forward ( self , text , text_length ): return self . model ( text , text_length ) # a common forward step to compute the loss and labels # this is used for training, validation, and testing below def _shared_step ( self , batch , batch_idx ): # These next 3 steps are unique and look a bit tricky due to # how Torchtext's BucketIterator prepares the batches # and how we use an LSTM with packed & padded text # Also, .TEXT_COLUMN_NAME and .LABEL_COLUMN_NAME # depend on the CSV file columns of the data file we load later. features , text_length = batch . TEXT_COLUMN_NAME true_labels = batch . LABEL_COLUMN_NAME logits = self ( features , text_length ) # A regular classifier uses: # loss = torch.nn.functional.cross_entropy(logits, true_labels) loss = corn_loss ( logits , true_labels , num_classes = self . model . num_classes ) # A regular classifier uses: # predicted_labels = torch.argmax(logits, dim=1) predicted_labels = corn_label_from_logits ( logits ) return loss , true_labels , predicted_labels def training_step ( self , batch , batch_idx ): loss , true_labels , predicted_labels = self . _shared_step ( batch , batch_idx ) self . log ( \"train_loss\" , loss , batch_size = true_labels . shape [ 0 ]) self . train_mae . update ( predicted_labels , true_labels ) self . log ( \"train_mae\" , self . train_mae , on_epoch = True , on_step = False , batch_size = true_labels . shape [ 0 ]) return loss def validation_step ( self , batch , batch_idx ): loss , true_labels , predicted_labels = self . _shared_step ( batch , batch_idx ) self . log ( \"valid_loss\" , loss , batch_size = true_labels . shape [ 0 ]) self . valid_mae . update ( predicted_labels , true_labels ) self . log ( \"valid_mae\" , self . valid_mae , on_epoch = True , on_step = False , prog_bar = True , batch_size = true_labels . shape [ 0 ]) def test_step ( self , batch , batch_idx ): _ , true_labels , predicted_labels = self . _shared_step ( batch , batch_idx ) self . test_mae . update ( predicted_labels , true_labels ) self . log ( \"test_mae\" , self . test_mae , on_epoch = True , on_step = False , batch_size = true_labels . shape [ 0 ]) def configure_optimizers ( self ): optimizer = torch . optim . Adam ( self . parameters (), lr = LEARNING_RATE ) return optimizer","title":"Implementing an RNN using PyTorch Lightning's LightningModule"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#setting-up-the-dataset","text":"In this section, we are going to set up our dataset.","title":"Setting up the dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#inspecting-the-dataset","text":"import pandas as pd import numpy as np data_df = pd . read_csv ( \"https://raw.githubusercontent.com/Raschka-research-group/\" \"corn-ordinal-neuralnet/main/datasets/tripadvisor/tripadvisor_balanced.csv\" ) data_df . tail () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TEXT_COLUMN_NAME LABEL_COLUMN_NAME 6995 beautiful hotel, stay punta cana majestic colo... 5 6996 stay, n't stay, stayed week april, weather ama... 5 6997 stay hotel fantastic, great location, looked n... 5 6998 birthday meal havnt stayed hotel staying barce... 5 6999 great hotel great location stayed royal magda ... 5 CSV_PATH = '../data/tripadvisor_balanced.csv' data_df . to_csv ( CSV_PATH , index = None ) import torchtext import random TEXT = torchtext . legacy . data . Field ( tokenize = 'spacy' , # default splits on whitespace tokenizer_language = 'en_core_web_sm' , include_lengths = True ) LABEL = torchtext . legacy . data . LabelField ( dtype = torch . long ) fields = [( 'TEXT_COLUMN_NAME' , TEXT ), ( 'LABEL_COLUMN_NAME' , LABEL )] dataset = torchtext . legacy . data . TabularDataset ( path = CSV_PATH , format = 'csv' , skip_header = True , fields = fields ) train_data , test_data = dataset . split ( split_ratio = [ 0.8 , 0.2 ], random_state = random . seed ( RANDOM_SEED )) train_data , valid_data = train_data . split ( split_ratio = [ 0.85 , 0.15 ], random_state = random . seed ( RANDOM_SEED )) TEXT . build_vocab ( train_data , max_size = VOCABULARY_SIZE ) LABEL . build_vocab ( train_data ) train_loader , valid_loader , test_loader = torchtext . legacy . data . BucketIterator . splits ( ( train_data , valid_data , test_data ), batch_size = BATCH_SIZE , sort_within_batch = True , # necessary for packed_padded_sequence sort_key = lambda x : len ( x . TEXT_COLUMN_NAME ), ) # Checking the dataset all_train_labels = [] all_test_labels = [] for features , labels in train_loader : all_train_labels . append ( labels ) all_train_labels = torch . cat ( all_train_labels ) for features , labels in test_loader : all_test_labels . append ( labels ) all_test_labels = torch . cat ( all_test_labels ) print ( 'Training labels:' , torch . unique ( all_train_labels )) print ( 'Training label distribution:' , torch . bincount ( all_train_labels )) print ( ' \\n Test labels:' , torch . unique ( all_test_labels )) print ( 'Test label distribution:' , torch . bincount ( all_test_labels )) Training labels: tensor([0, 1, 2, 3, 4]) Training label distribution: tensor([964, 963, 954, 953, 926]) Test labels: tensor([0, 1, 2, 3, 4]) Test label distribution: tensor([275, 267, 300, 274, 284]) Above, we can see that the dataset consists of 8 features, and there are 998 examples in total. The labels are in range from 1 (weakest) to 5 (strongest), and we normalize them to start at zero (hence, the normalized labels are in the range 0 to 4). Notice also that the dataset is quite balanced.","title":"Inspecting the dataset"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#performance-baseline","text":"Especially for imbalanced datasets, it's quite useful to compute a performance baseline. In classification contexts, a useful baseline is to compute the accuracy for a scenario where the model always predicts the majority class -- you want your model to be better than that! Note that if you are intersted in a single number that minimized the dataset mean squared error (MSE), that's the mean; similary, the median is a number that minimzes the mean absolute error (MAE). So, if we use the mean absolute error, \\mathrm{MAE}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| , to evaluate the model, it is useful to compute the MAE pretending the predicted label is always the median: all_test_labels = all_test_labels . float () avg_prediction = torch . median ( all_test_labels ) # median minimizes MAE baseline_mae = torch . mean ( torch . abs ( all_test_labels - avg_prediction )) print ( f 'Baseline MAE: { baseline_mae : .2f } ' ) Baseline MAE: 1.18 In other words, a model that would always predict the dataset median would achieve a MAE of 1.18. A model that has an MAE of > 1.18 is certainly a bad model.","title":"Performance baseline"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#setting-up-a-datamodule","text":"There are three main ways we can prepare the dataset for Lightning. We can make the dataset part of the model; set up the data loaders as usual and feed them to the fit method of a Lightning Trainer -- the Trainer is introduced in the next subsection; create a LightningDataModule . Usually, approach 3 is the most organized approach. However, since we already defined our data loaders above, we can just work with those directly. Note that the prepare_data method is usually used for steps that only need to be executed once, for example, downloading the dataset; the setup method defines the the dataset loading -- if you run your code in a distributed setting, this will be called on each node / GPU. Next, lets initialize the DataModule ; we use a random seed for reproducibility (so that the data set is shuffled the same way when we re-execute this code):","title":"Setting up a DataModule"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#training-the-model-using-the-pytorch-lightning-trainer-class","text":"Next, we initialize our RNN model. Also, we define a call back so that we can obtain the model with the best validation set performance after training. PyTorch Lightning offers many advanced logging services like Weights & Biases. Here, we will keep things simple and use the CSVLogger : from pytorch_lightning.callbacks import ModelCheckpoint from pytorch_lightning.loggers import CSVLogger pytorch_model = RNN ( input_dim = len ( TEXT . vocab ), embedding_dim = 128 , hidden_dim = 64 , output_dim = 32 , num_classes = NUM_CLASSES ) lightning_model = LightningRNN ( pytorch_model ) callbacks = [ ModelCheckpoint ( save_top_k = 1 , mode = 'min' , monitor = \"valid_mae\" )] # save top 1 model logger = CSVLogger ( save_dir = \"logs/\" , name = \"cnn-corn-mnist\" ) Note that we disable warning as the .log() method of the LightningModule currently warns us that the batch size is inconsistent. This should not happen as we define the batch_size manually in the self.log calls. However, this will be resolved in a future version (https://github.com/PyTorchLightning/pytorch-lightning/pull/10408). Also note that the batch size is not inconsistent, its just that the BucketIterator in torchtext has creates batches where the text length plus padding is the first dimension in a tensor. And the batch size is the second dimension: for features , labels in train_loader : break print ( 'Text length:' , features [ 0 ] . shape [ 0 ]) print ( 'Batch size (from text):' , features [ 0 ] . shape [ 1 ]) print ( 'Batch size (from labels):' , labels . shape [ 0 ]) Text length: 84 Batch size (from text): 256 Batch size (from labels): 256 import warnings warnings . filterwarnings ( 'ignore' ) Now it's time to train our model: trainer = pl . Trainer ( max_epochs = NUM_EPOCHS , callbacks = callbacks , accelerator = \"gpu\" , devices = 1 , logger = logger , log_every_n_steps = 1 ) trainer . fit ( model = lightning_model , train_dataloaders = train_loader , val_dataloaders = valid_loader ) GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] | Name | Type | Params ------------------------------------------------ 0 | model | RNN | 690 K 1 | train_mae | MeanAbsoluteError | 0 2 | valid_mae | MeanAbsoluteError | 0 3 | test_mae | MeanAbsoluteError | 0 ------------------------------------------------ 690 K Trainable params 0 Non-trainable params 690 K Total params 2.761 Total estimated model params size (MB)","title":"Training the model using the PyTorch Lightning Trainer class"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#evaluating-the-model","text":"After training, let's plot our training MAE and validation MAE using pandas, which, in turn, uses matplotlib for plotting (you may want to consider a more advanced logger that does that for you): import pandas as pd metrics = pd . read_csv ( f \" { trainer . logger . log_dir } /metrics.csv\" ) aggreg_metrics = [] agg_col = \"epoch\" for i , dfg in metrics . groupby ( agg_col ): agg = dict ( dfg . mean ()) agg [ agg_col ] = i aggreg_metrics . append ( agg ) df_metrics = pd . DataFrame ( aggreg_metrics ) df_metrics [[ \"train_loss\" , \"valid_loss\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'Loss' ) df_metrics [[ \"valid_mae\" , \"train_mae\" ]] . plot ( grid = True , legend = True , xlabel = 'Epoch' , ylabel = 'MAE' ) <AxesSubplot:xlabel='Epoch', ylabel='MAE'> As we can see from the loss plot above, the model starts overfitting pretty quickly. Based on the MAE plot, we can see that the best model, based on the validation set MAE, may be around epoch 5. The trainer saved this model automatically for us, we which we can load from the checkpoint via the ckpt_path='best' argument; below we use the trainer instance to evaluate the best model on the test set: trainer . test ( model = lightning_model , dataloaders = test_loader , ckpt_path = 'best' ) Restoring states from the checkpoint path at logs/cnn-corn-mnist/version_24/checkpoints/epoch=5-step=113.ckpt LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3] Loaded model weights from checkpoint at logs/cnn-corn-mnist/version_24/checkpoints/epoch=5-step=113.ckpt Testing: 0it [00:00, ?it/s] -------------------------------------------------------------------------------- DATALOADER:0 TEST RESULTS {'test_mae': 0.9242857098579407} -------------------------------------------------------------------------------- [{'test_mae': 0.9242857098579407}]","title":"Evaluating the model"},{"location":"tutorials/pytorch_lightning/ordinal-corn_tripadvisor/#predicting-labels-of-new-data","text":"You can use the trainer.predict method on a new DataLoader or DataModule to apply the model to new data. Alternatively, you can also manually load the best model from a checkpoint as shown below: path = f ' { trainer . logger . log_dir } /checkpoints/epoch=5-step=113.ckpt' lightning_model = LightningRNN . load_from_checkpoint ( path ) Note that our RNN , which is passed to LightningRNN requires input arguments. However, this is automatically being taken care of since we used self.save_hyperparameters() in LightningRNN 's __init__ method. Now, below is an example applying the model manually. Here, pretend that the test_dataloader is a new data loader. all_predicted_labels = [] for batch in test_loader : features , text_length = batch . TEXT_COLUMN_NAME logits = lightning_model . model ( features , text_length ) predicted_labels = corn_label_from_logits ( logits ) all_predicted_labels . append ( predicted_labels ) all_predicted_labels = torch . cat ( all_predicted_labels ) all_predicted_labels [: 5 ] tensor([3, 2, 1, 3, 1])","title":"Predicting labels of new data"}]}